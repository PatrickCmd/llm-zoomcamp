{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5724b36c-8c5c-4323-af1c-1a2ec3b94e5f",
   "metadata": {},
   "source": [
    "# Running LLMs Locally using Ollama\n",
    "Learn how to utilize Ollama in your Python, LangChain, and LlamaIndex applications\n",
    "\n",
    "- https://ai.gopubby.com/running-llms-locally-using-ollama-f17197f60450"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439175c-2979-43d9-9693-352829095376",
   "metadata": {},
   "source": [
    "## Ollama Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f02d35-2938-456e-90b3-ae22dec77064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cleaning up old version at /usr/local/lib/ollama\n",
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading Linux amd64 bundle\n",
      "######################################################################## 100.0%\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec75c89-68e6-4d07-951f-1af90cb92b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['nohup', 'ollama', 'serve']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the command as a background process\n",
    "subprocess.Popen([\"nohup\", \"ollama\", \"serve\"], stdout=open(\"nohup.out\", \"w\"), stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048b617b-aa79-4f57-8395-126407671238",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37ace11-3e83-42ab-b552-3222a61cad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6457742f-bf35-4f67-9d43-29f6fddf5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-r1  llama3.2\n"
     ]
    }
   ],
   "source": [
    "!ls /root/.ollama/models/manifests/registry.ollama.ai/library/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afccea9-264c-4ef1-a5b9-3805181d664a",
   "metadata": {},
   "source": [
    "## Using Ollama as a Chatbot\n",
    "You can use Ollama to generate a response by using the generate() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1349cf9f-1cc0-49aa-89e5-2ec5ee0d0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs (1955-2011) was a visionary entrepreneur, inventor, and designer who co-founded Apple Inc. and Pixar Animation Studios. He is widely recognized as one of the most innovative and successful business leaders of all time.\n",
      "\n",
      "Early Life and Education:\n",
      "\n",
      "Jobs was born in San Francisco, California, to two University of Wisconsin graduate students, Joanne Schieble and Abdulfattah \"John\" Jandali. He was adopted by Paul and Clara Jobs, a machinist and an accountant, respectively, who raised him in Mountain View, California.\n",
      "\n",
      "Jobs showed an early interest in electronics and design, attending lectures at Hewlett-Packard (HP) while still in high school. After dropping out of Reed College in Portland, Oregon, he attended meetings of calligraphy classes for students without paying, which sparked his interest in the subject.\n",
      "\n",
      "Career:\n",
      "\n",
      "1. Apple Inc. (1976-1985): Jobs co-founded Apple with Steve Wozniak and Ronald Wayne. The company's first product was the Apple I computer, followed by the Apple II, which revolutionized the personal computer industry.\n",
      "2. Pixar Animation Studios (1986-2006): After a power struggle at Apple, Jobs acquired Pixar from Lucasfilm for $5 million in 1986. He played a crucial role in revamping the studio's animation software and producing blockbuster films like Toy Story and Finding Nemo.\n",
      "3. Return to Apple Inc. (1997-2011): In 1997, Jobs returned to Apple as interim CEO after serving on the company's board of directors. Under his leadership, Apple revolutionized the technology industry with innovative products like the iMac, iPod, iPhone, and iPad.\n",
      "\n",
      "Notable Contributions:\n",
      "\n",
      "* Revitalizing the personal computer industry\n",
      "* Revolutionizing the music industry with the iPod\n",
      "* Popularizing smartphones with the iPhone\n",
      "* Transforming the tablet computing market with the iPad\n",
      "* Pioneering user-friendly design principles\n",
      "\n",
      "Awards and Legacy:\n",
      "\n",
      "Jobs received numerous awards for his contributions to technology, design, and entrepreneurship. He was a pioneer of innovation and design thinking, inspiring generations of entrepreneurs, designers, and inventors.\n",
      "\n",
      "In 2011, Steve Jobs passed away after a long battle with pancreatic cancer. His legacy continues to shape the world of technology, design, and entertainment, leaving behind a lasting impact on humanity.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.generate(\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=\"Who is Steve Jobs?\"\n",
    ")\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0617fac9-5be0-4315-a4cd-e3c127d024ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Steve Jobs (1955-2011) was a visionary entrepreneur, inventor, and designer who co-founded Apple Inc. and Pixar Animation Studios. He is widely recognized as one of the most innovative and successful business leaders of all time.\n",
       "\n",
       "Early Life and Education:\n",
       "\n",
       "Jobs was born in San Francisco, California, to two University of Wisconsin graduate students, Joanne Schieble and Abdulfattah \"John\" Jandali. He was adopted by Paul and Clara Jobs, a machinist and an accountant, respectively, who raised him in Mountain View, California.\n",
       "\n",
       "Jobs showed an early interest in electronics and design, attending lectures at Hewlett-Packard (HP) while still in high school. After dropping out of Reed College in Portland, Oregon, he attended meetings of calligraphy classes for students without paying, which sparked his interest in the subject.\n",
       "\n",
       "Career:\n",
       "\n",
       "1. Apple Inc. (1976-1985): Jobs co-founded Apple with Steve Wozniak and Ronald Wayne. The company's first product was the Apple I computer, followed by the Apple II, which revolutionized the personal computer industry.\n",
       "2. Pixar Animation Studios (1986-2006): After a power struggle at Apple, Jobs acquired Pixar from Lucasfilm for $5 million in 1986. He played a crucial role in revamping the studio's animation software and producing blockbuster films like Toy Story and Finding Nemo.\n",
       "3. Return to Apple Inc. (1997-2011): In 1997, Jobs returned to Apple as interim CEO after serving on the company's board of directors. Under his leadership, Apple revolutionized the technology industry with innovative products like the iMac, iPod, iPhone, and iPad.\n",
       "\n",
       "Notable Contributions:\n",
       "\n",
       "* Revitalizing the personal computer industry\n",
       "* Revolutionizing the music industry with the iPod\n",
       "* Popularizing smartphones with the iPhone\n",
       "* Transforming the tablet computing market with the iPad\n",
       "* Pioneering user-friendly design principles\n",
       "\n",
       "Awards and Legacy:\n",
       "\n",
       "Jobs received numerous awards for his contributions to technology, design, and entrepreneurship. He was a pioneer of innovation and design thinking, inspiring generations of entrepreneurs, designers, and inventors.\n",
       "\n",
       "In 2011, Steve Jobs passed away after a long battle with pancreatic cancer. His legacy continues to shape the world of technology, design, and entertainment, leaving behind a lasting impact on humanity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response[\"response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4039578c-5590-4fd1-bd8d-5599089c9ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are definitions for each of the requested terms:\n",
       "\n",
       "1. **LLMs (Large Language Models)**: A type of artificial intelligence (AI) model that uses natural language processing (NLP) to understand and generate human-like text. LLMs are typically trained on vast amounts of text data, which enables them to learn patterns and relationships within language. They can be used for a variety of tasks such as language translation, question answering, text summarization, and more.\n",
       "\n",
       "2. **RAG (Retrieval Augmented Generation)**: A technique used in Natural Language Processing (NLP) that leverages Large Language Models (LLMs) to improve the performance of various NLP tasks. RAG involves using an LLM as a retriever to search for relevant information from a large corpus, and then generating text based on the retrieved information. This approach can significantly improve the accuracy and efficiency of tasks such as question answering, text classification, and more.\n",
       "\n",
       "3. **LLM Agents**: An emerging concept in Artificial Intelligence (AI) that involves using Large Language Models (LLMs) to create autonomous agents capable of interacting with humans and their environment. LLM agents are designed to learn from their interactions and adapt to new situations, enabling them to perform complex tasks such as conversation management, decision-making, and more.\n",
       "\n",
       "In essence, LLM agents are a type of AI system that uses LLMs to enable intelligent behavior, such as:\n",
       "\n",
       "* Understanding natural language input\n",
       "* Generating human-like responses\n",
       "* Learning from user interactions\n",
       "* Adapting to new situations\n",
       "\n",
       "The use of RAG techniques can further enhance the capabilities of these LLM agents by improving their ability to retrieve and generate relevant information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ollama.generate(\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=\"Define LLMs, RAG (Retrieval Augmented Generation), and LLM Agents\"\n",
    ")\n",
    "display(Markdown(response[\"response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7708f1e2-714b-4797-ae96-032dc51c776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  What is the capital city of France?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital city of France is Paris.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  When was it founded and give a brief history about it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the confirmation, Ollama!\n",
      "\n",
      "Paris, the capital city of France, has a rich history dating back to the 3rd century BC. Here's a brief overview:\n",
      "\n",
      "* Ancient times: The area now known as Paris was inhabited by the Celtic tribe known as the Parisii.\n",
      "* Roman era (52 BC): The Romans conquered the area and founded the city of Lutetia Parisiorum, which they named after their leader, Lutetia. This was an important center for trade and commerce.\n",
      "* Middle Ages (5th-15th centuries): After the fall of the Roman Empire, Paris became a strategic location for various European powers, including the Franks and the Carolingians. The city was an important center of learning and culture during this period.\n",
      "* Renaissance and Enlightenment (16th-18th centuries): During the Renaissance, Paris became a hub for art, literature, and music, with famous figures like Leonardo da Vinci, Michelangelo, and Voltaire calling the city home. The Enlightenment also had a significant impact on Paris, with thinkers like Rousseau and Diderot contributing to the development of modern philosophy.\n",
      "* French Revolution (1789-1799): The French Revolution transformed Paris into the heart of the revolution, with key figures like Maximilien Robespierre and Napoleon Bonaparte playing important roles. The city was also the site of many iconic landmarks, including the National Assembly and the Palace of Luxembourg.\n",
      "* Modern era (19th-20th centuries): In the 19th century, Paris underwent significant urban development, with the construction of new buildings, boulevards, and infrastructure. The city became a major hub for art, fashion, and culture, attracting visitors from around the world.\n",
      "\n",
      "Today, Paris is one of the most visited cities in the world, known for its stunning architecture, vibrant cultural scene, and romantic atmosphere.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  quit\n"
     ]
    }
   ],
   "source": [
    "messages = ''\n",
    "\n",
    "while True:\n",
    "    question = input(\"Ask a question: \")\n",
    "    if question.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    # Add user input to the messages history\n",
    "    messages += f'You: {question}\\n'\n",
    "\n",
    "    response = ollama.generate(model = 'llama3.2:latest',\n",
    "                               prompt = messages)    \n",
    "    print(response['response'])\n",
    "\n",
    "    # Add Ollama's response to the messages history\n",
    "    messages += f'Ollama: {response[\"response\"]}\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71433814-1013-4744-a1af-9b2fc0af8be9",
   "metadata": {},
   "source": [
    "Ollama also provides another method that allows you to have a conversation with the model — **chat()**. While the **generate()** method is primarily designed for single queries or isolated prompts, the **chat()** method is designed for ongoing conversations with the model. Maintaining conversations is similar to what you have just seen —but instead of saving the previous conversations in a string, you now save it in a list, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b8f0632-17ce-4634-96eb-ee9cd5fb9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  State Netwon's Laws of Motion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: Sir Isaac Newton formulated three fundamental laws of motion, which describe the relationship between a body and the forces acting upon it. Here are Newton's Laws of Motion:\n",
      "\n",
      "**Newton's First Law of Motion (Law of Inertia)**\n",
      "\n",
      "* An object at rest will remain at rest, unless acted upon by an external force.\n",
      "* An object in motion will continue to move with a constant velocity, unless acted upon by an external force.\n",
      "\n",
      "In other words, an object will maintain its state of motion unless a force is applied to it. If no forces are acting on the object, it will remain at rest or continue moving at a constant speed.\n",
      "\n",
      "**Newton's Second Law of Motion (Law of Acceleration)**\n",
      "\n",
      "* The acceleration of an object is directly proportional to the net force acting upon it.\n",
      "* F = ma, where:\n",
      " + F is the net force applied to the object\n",
      " + m is the mass of the object\n",
      " + a is the acceleration produced in the object\n",
      "\n",
      "In simpler terms, the more massive an object is, the less it will accelerate when a given force is applied. The greater the force applied to an object, the greater its acceleration.\n",
      "\n",
      "**Newton's Third Law of Motion (Law of Action and Reaction)**\n",
      "\n",
      "* For every action, there is an equal and opposite reaction.\n",
      "* When two objects interact, they apply forces to one another that are equal in magnitude and opposite in direction.\n",
      "\n",
      "In other words, when object A exerts a force on object B, object B will exert an equal and opposite force on object A. This law explains why, when you push on a wall, the wall pushes back on you with the same force.\n",
      "\n",
      "These three laws of motion are fundamental to understanding how objects move and respond to forces in our universe.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  How is the third law applied in jet enginees?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: The Third Law of Motion (Law of Action and Reaction) plays a crucial role in the design and operation of jet engines.\n",
      "\n",
      "**The Principle of Jet Engine Operation**\n",
      "\n",
      "In a jet engine, hot gases are expelled out of the back of the engine at high velocity, which produces a forward thrust. The basic principle is based on Newton's Third Law:\n",
      "\n",
      "* The exhaust gases (object B) push against the engine's nozzle (object A)\n",
      "* The engine's nozzle pushes back against the exhaust gases with an equal and opposite force\n",
      "\n",
      "**How it Works**\n",
      "\n",
      "Here's a simplified explanation of how this works:\n",
      "\n",
      "1. **Fuel is burned**: Fuel is injected into the combustion chamber, where it is ignited by a spark or flame.\n",
      "2. **Hot gases are produced**: The fuel burns rapidly, producing hot gases that expand and push against the engine's walls.\n",
      "3. **Nozzle expansion**: These hot gases expand through a nozzle, which accelerates them to high velocities (up to 500 m/s).\n",
      "4. **Exhaust gases exit**: The exhaust gases exit the back of the engine at these high velocities, producing a forward thrust.\n",
      "\n",
      "**Action and Reaction**\n",
      "\n",
      "According to Newton's Third Law, the exhaust gases push against the engine's nozzle, causing it to accelerate in the opposite direction (backward). This backward acceleration is what ultimately propels the aircraft forward.\n",
      "\n",
      "In summary, the Third Law of Motion explains how the hot gases expelled from a jet engine produce a forward thrust by pushing against the engine's nozzle with an equal and opposite force.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question:  quit\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "while True:\n",
    "    question = input(\"Ask a question: \")\n",
    "    if question.lower() == \"quit\":\n",
    "        break\n",
    "    \n",
    "    # add user input to the messages history\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    # use the ollama.chat() function to maintain conversation context\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2:latest',\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    # print Ollama's response\n",
    "    print(f\"Ollama: {response['message']['content']}\\n\")\n",
    "\n",
    "    # add assistant's response to the messages history\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response['message']['content']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdc97f-9802-40c8-86cf-849038c0cfb6",
   "metadata": {},
   "source": [
    "## Using Ollama in LangChain\n",
    "Ollama can also be used in a LangChain application.\n",
    "\n",
    "> **LangChain** is a framework designed for developing applications powered by language models (LLMs). It provides a comprehensive set of tools and abstractions that facilitate the integration of LLMs into various applications, enabling developers to build complex, multi-functional systems that leverage natural language understanding and generation capabilities.\n",
    "\n",
    "To use Ollama in a LangChain app, use `pip` to install the following library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd870651-8517-486c-a806-0a0214af7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e28b4e-261f-4fd0-8c88-aef8d3065070",
   "metadata": {},
   "source": [
    "You can now ask a question using the `invoke()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "234b2f5e-a1aa-43ad-be99-bb026f9c3921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2954/2096228702.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2:latest\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Steve Jobs (1955-2011) was a visionary entrepreneur, inventor, and designer who co-founded Apple Inc. He is widely recognized as one of the most innovative and successful business leaders of the last century.\n",
       "\n",
       "Early Life and Education:\n",
       "\n",
       "Steve Jobs was born on February 24, 1955, in San Francisco, California, to two University of Wisconsin graduate students, Joanne Schieble and Abdulfattah \"John\" Jandali. He was adopted by Paul and Clara Jobs, a machinist and an accountant, respectively, who raised him in Mountain View, California.\n",
       "\n",
       "Jobs showed an early interest in electronics and design, attending lectures at Hewlett-Packard (HP) while still in high school. After graduating from Homestead High School in 1972, he attended Reed College in Portland, Oregon, but dropped out after one semester due to the financial burden on his parents.\n",
       "\n",
       "Career:\n",
       "\n",
       "In 1974, Jobs met Steve Wozniak, a fellow electronics enthusiast and engineer at Hewlett-Packard (HP). The two began designing and building personal computers together, including the Apple I and Apple II. In April 1976, they founded Apple Computer in Jobs' parents' garage.\n",
       "\n",
       "Under Jobs' leadership, Apple introduced the Macintosh computer in 1984, which popularized the graphical user interface (GUI) and revolutionized personal computing. The company also released the iPod (2001), iPhone (2007), and iPad (2010), all of which became incredibly successful products that transformed the music, phone, and tablet industries.\n",
       "\n",
       "In 1985, Jobs left Apple after a power struggle with John Sculley, who had been appointed CEO by the board. During his absence from Apple, Jobs acquired Pixar Animation Studios from Lucasfilm for $5 million and served as its CEO until it was acquired by Disney in 2006 for $7.4 billion.\n",
       "\n",
       "Return to Apple:\n",
       "\n",
       "In 1997, Apple acquired NeXT, a company co-founded by Jobs after he left Apple. As part of the acquisition, Jobs returned to Apple as an advisor and eventually took over as interim CEO in August 1997. Under his leadership, Apple introduced the iMac (1998), iPod (2001), and iPhone (2007), which revitalized the company's fortunes.\n",
       "\n",
       "Legacy:\n",
       "\n",
       "Steve Jobs is widely regarded as a visionary and innovative leader who transformed the way people interact with technology. His focus on design, simplicity, and user experience has influenced countless products and companies around the world.\n",
       "\n",
       "Some of his most notable achievements include:\n",
       "\n",
       "1. Revolutionizing personal computing with the Macintosh computer.\n",
       "2. Popularizing the music industry with the iPod.\n",
       "3. Redefining the smartphone market with the iPhone.\n",
       "4. Pioneering tablet computers with the iPad.\n",
       "5. Building Pixar Animation Studios into a successful and innovative film studio.\n",
       "\n",
       "Awards and Recognition:\n",
       "\n",
       "Jobs received numerous awards and recognition for his contributions to technology, design, and innovation, including:\n",
       "\n",
       "1. National Medal of Technology (1985)\n",
       "2. National Academy of Engineering (1990)\n",
       "3. Inducted into the California Hall of Fame (2007)\n",
       "4. Time Magazine's Person of the Year (2007)\n",
       "\n",
       "Personal Life:\n",
       "\n",
       "Steve Jobs was married twice: first to Chrisann Brennan, with whom he had a daughter, Lisa, in 1978; and then to Laurene Powell Jobs, whom he married in 1991.\n",
       "\n",
       "Health Issues and Death:\n",
       "\n",
       "In 2003, Jobs was diagnosed with pancreatic cancer. He underwent surgery and was placed on a diet of pureed foods for six months, but the cancer returned in 2009. After undergoing liver transplant surgery, Jobs resigned as CEO of Apple in August 2011 due to his failing health.\n",
       "\n",
       "Steve Jobs passed away on October 5, 2011, at the age of 56, surrounded by his family and loved ones.\n",
       "\n",
       "His legacy continues to inspire innovation, design, and entrepreneurship around the world."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "\n",
    "# print(llm.invoke(\"Who is Steve Jobs\"))\n",
    "display(Markdown(llm.invoke(\"Who is Steve Jobs\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d331fb1-c81e-4f97-805a-d9e1c43eb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "299264eb-cc0a-46e0-86a4-bff9bc7075c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Steve Jobs (1955-2011) was a visionary entrepreneur, inventor, and designer who co-founded Apple Inc. and Pixar Animation Studios. He is widely recognized as one of the most innovative and successful business leaders of all time.\n",
       "\n",
       "Early Life and Education:\n",
       "\n",
       "Jobs was born in San Francisco, California, to two University of Wisconsin graduate students. His biological parents were Joan Baez's adoptive parents, Paul and Clara Jobs, but he had a half-sister, Mona Simpson, who is also an author. When Steve was 12 years old, his father died from complications related to a liver transplant.\n",
       "\n",
       "In 1972, Jobs met Steve Wozniak, with whom he would later co-found Apple Computer. Jobs attended Reed College in Portland, Oregon, but dropped out after one semester due to the financial burden on his parents.\n",
       "\n",
       "Career:\n",
       "\n",
       "1. **Apple Computer (1976-1985)**: With Wozniak, Jobs founded Apple in 1976 and introduced the Apple I, one of the first personal computers on the market.\n",
       "2. **Pixar Animation Studios (1986-2006)**: Jobs acquired Pixar Animation Studios from Lucasfilm in 1986 for $5 million. Under his leadership, Pixar produced some of its most iconic films, including Toy Story (1995) and Finding Nemo (2003).\n",
       "3. **Return to Apple (1997-2011)**: After a falling out with then-CEO John Sculley, Jobs returned to Apple in 1997 as interim CEO. He led the company's resurgence with innovative products like the iMac, iPod, iPhone, and iPad.\n",
       "\n",
       "Innovations and Legacy:\n",
       "\n",
       "Jobs was known for his passion for design, simplicity, and user experience. His innovations include:\n",
       "\n",
       "1. **The Macintosh computer**: Introduced the graphical user interface (GUI) to the masses.\n",
       "2. **iPod**: Revolutionized the portable music player market.\n",
       "3. **iPhone**: Popularized the multi-touch smartphone concept.\n",
       "4. **iPad**: Popularized the tablet computer market.\n",
       "\n",
       "Personal Life and Death:\n",
       "\n",
       "Jobs was known for his intense focus on work and personal struggles with pancreatic cancer. He passed away on October 5, 2011, at the age of 56.\n",
       "\n",
       "Awards and Recognition:\n",
       "\n",
       "* National Medal of Technology (1985)\n",
       "* Inducted into the California Hall of Fame (2007)\n",
       "* Inducted into the Museum of Modern Art's (MoMA) Design Collection (2008)\n",
       "\n",
       "Steve Jobs' legacy continues to shape the tech industry, inspiring future generations of innovators and entrepreneurs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:latest\")\n",
    "\n",
    "# print(llm.invoke(\"Who is Steve Jobs\"))\n",
    "display(Markdown(llm.invoke(\"Who is Steve Jobs\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48102e05-c353-41b0-ab2f-5ca54149da2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76d74f3c-44a9-4ddc-843b-164acb654279",
   "metadata": {},
   "source": [
    "Of course, in a LangChain application you can always chain together various components, such as **PromptTemplate**, **LLM**, and **StrOutputParser**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0523e878-f92b-4160-8c56-ffc41a3625b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befo' flight a-gwaan, ya get di flight nuh. (Note: This is a common way to phrase it in Jamaican Patois.)\n",
      "\n",
      "Alternatively, you could say:\n",
      "\n",
      "\"Flight a-go change\" or \"Flight a-go shift\"\n",
      "\n",
      "However, the most informal and colloquial way would be:\n",
      "\n",
      "\"Befo' flight a-gwaan, ya get di new date yah.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "template = '''\n",
    "Translate the following English sentence to Jamaican Patois:\n",
    "English: {text}\n",
    "Jamaican Patois:\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = ['text']\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:latest\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"text\": \"The flight has been rescheduled\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34c4c384-9f44-4010-b61f-bcf51e4920bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can help you with a translation, but please note that Jamaican Patois is a complex and nuanced language, and my translation might not be perfect. Here's an attempt at translating the sentence:\n",
      "\n",
      "\"Flight nuh go happen like dat; di flight get rescheduled.\"\n",
      "\n",
      "Breakdown:\n",
      "\n",
      "* \"Nuh\" means \"not\" or \"no\"\n",
      "* \"go\" is used to express negation\n",
      "* \"dat\" means \"that\" (this is a colloquial usage)\n",
      "* \"flight\" remains the same, as it's a loanword from English\n",
      "* \"get\" is used instead of \"has been\"\n",
      "* \"rescheduled\" remains the same, but \"nuh\" could be added to make it sound more like Patois\n",
      "\n",
      "Keep in mind that Patois has many variations and dialects, so this translation might not be universally accepted.\n"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "Translate the following English sentence to Jamaican Patwah:\n",
    "English: {text}\n",
    "Jamaican Patwah:\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = ['text']\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:latest\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"text\": \"The flight has been rescheduled\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42eb01-e706-4314-944f-2ccf2e16d306",
   "metadata": {},
   "source": [
    "## Using Ollama with LlamaIndex\n",
    "Apart from using Ollama as a standalone model or as a LLM component in LangChain, you can also use Ollama with LlamaIndex.\n",
    "\n",
    "> **LlamaIndex** is a framework designed to facilitate the integration of language models (LLMs) with various types of data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5eef838-58a6-4acf-ac7b-d92a0efb46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index-llms-ollama\n",
    "!pip install llama_index\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7029b-2509-48f2-be95-20494dede93e",
   "metadata": {},
   "source": [
    "See previous article using LLammaindex with Hugging Face models locally\n",
    "\n",
    "- [Article](https://ai.gopubby.com/retrieval-augmented-generation-rag-for-document-based-question-answering-c3f5f939f886?source=post_page-----f17197f60450--------------------------------)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efde75-6c77-4cdc-95c2-be2c484f6289",
   "metadata": {},
   "source": [
    "### Preparing the Documents\n",
    "\n",
    "#### Loading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cccb975c-3d2a-4004-b13a-b3a788ec1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir=\"./documents\",\n",
    "    recursive=True,\n",
    "    required_exts=[\".pdf\"],\n",
    ")\n",
    "\n",
    "# loads the documents\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f23281b6-98bb-4129-9041-ca8e42f441d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750001f0-5dc2-472d-998d-c0d95d12c824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Provided proper attribution is provided, Google hereby grants permission to\n",
       "reproduce the tables and figures in this paper solely for use in journalistic or\n",
       "scholarly works.\n",
       "Attention Is All You Need\n",
       "Ashish Vaswani∗\n",
       "Google Brain\n",
       "avaswani@google.com\n",
       "Noam Shazeer∗\n",
       "Google Brain\n",
       "noam@google.com\n",
       "Niki Parmar∗\n",
       "Google Research\n",
       "nikip@google.com\n",
       "Jakob Uszkoreit∗\n",
       "Google Research\n",
       "usz@google.com\n",
       "Llion Jones∗\n",
       "Google Research\n",
       "llion@google.com\n",
       "Aidan N. Gomez∗ †\n",
       "University of Toronto\n",
       "aidan@cs.toronto.edu\n",
       "Łukasz Kaiser∗\n",
       "Google Brain\n",
       "lukaszkaiser@google.com\n",
       "Illia Polosukhin∗ ‡\n",
       "illia.polosukhin@gmail.com\n",
       "Abstract\n",
       "The dominant sequence transduction models are based on complex recurrent or\n",
       "convolutional neural networks that include an encoder and a decoder. The best\n",
       "performing models also connect the encoder and decoder through an attention\n",
       "mechanism. We propose a new simple network architecture, the Transformer,\n",
       "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
       "entirely. Experiments on two machine translation tasks show these models to\n",
       "be superior in quality while being more parallelizable and requiring significantly\n",
       "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
       "to-German translation task, improving over the existing best results, including\n",
       "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
       "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
       "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
       "best models from the literature. We show that the Transformer generalizes well to\n",
       "other tasks by applying it successfully to English constituency parsing both with\n",
       "large and limited training data.\n",
       "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
       "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
       "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
       "attention and the parameter-free position representation and became the other person involved in nearly every\n",
       "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
       "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
       "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
       "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
       "our research.\n",
       "†Work performed while at Google Brain.\n",
       "‡Work performed while at Google Research.\n",
       "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
       "arXiv:1706.03762v7  [cs.CL]  2 Aug 2023"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(documents[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4688b-131d-4cac-8e91-e34a7906e659",
   "metadata": {},
   "source": [
    "### Using an Embedding Model\n",
    "Once the documents are loaded, the next step is to perform embedding to convert the text data into vector representations. This allows for more efficient querying, similarity search, and further processing of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed38e476-c2e8-4241-b353-5e9b633e03cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dede29b4c0641678e3a26a4625ec045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb78b639f1644cbb9cd17f5d5e025a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cbdaf632f349969ed5f1a44020afbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fc5eb405984269a3d103f41065eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e176a01f66f444885e2a26bc0224db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cfa51021d6456882b3752b8accf868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173ba47a700f41c9ae9abd2a9c2be4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06bfa8fd6b244b2b6e14cb7c9084896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99fa822720c44a1b1dd7ce4ed98b1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ac8614e688457c9f30f685e9e2f9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee586929c353437ebfc5af429f0a45e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ea325-dac8-4369-a4c9-91f8504e26b6",
   "metadata": {},
   "source": [
    "### Indexing the Document\n",
    "You can now start to index the document using the embedding model via the VectorStoreIndex class, which you will use to create an index and then save the vector embeddings on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a30d773-e077-49cb-a11a-b9c82e167b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model = embedding_model,\n",
    ")\n",
    "\n",
    "# save the index in the current directory\n",
    "index.storage_context.persist(persist_dir=\"./vectore_docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f25d1a-8cb5-4e1b-863c-926717cb3560",
   "metadata": {},
   "source": [
    "### Loading the Index\n",
    "Once the index is persisted to disk, you can load it into memory using the StorageContext class and the `load_index_from_storage()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42d7bbbd-3a9b-48c1-a84b-edc7d888e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./vectore_docs\")\n",
    "index = load_index_from_storage(storage_context,\n",
    "                                embed_model = embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c783a004-ba07-4d5f-af6e-b2679ca3e6c0",
   "metadata": {},
   "source": [
    "### Using an LLM for Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e173f382-0ee6-4d17-b4f0-2364a8411e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "import torch\n",
    "\n",
    "# determine the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# use ollama as the LLM\n",
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613b88d-caad-4baf-8a35-b91448426c79",
   "metadata": {},
   "source": [
    "You can now ask questions about the documents using Ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e943bd7-5338-471f-b0b7-a56331198e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  Define Transformers and Attention Mechanism\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Transformers are a type of neural network architecture that primarily consists of stacked self-attention mechanisms and point-wise, fully connected layers for both the encoder and decoder.\n",
       "\n",
       "The attention mechanism is a function that maps a query and a set of key-value pairs to an output. It computes a weighted sum of the values based on the similarity between the query and keys. This similarity is determined by the dot product of the query and keys, which are then normalized and applied to a softmax function to produce weights for each value. These weights are then used to compute the final output as a weighted sum of the values.\n",
       "\n",
       "In simpler terms, attention allows the model to focus on specific parts of the input data that are relevant to the task at hand, while ignoring less important information. This is particularly useful in situations where the relationships between different parts of the input data are long-range and need to be modeled."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  Give the model variants of DeepSeek-R1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The model variants of DeepSeek-R1 are:\n",
       "\n",
       "DeepSeek-R1-Zero\n",
       "DeepSeek-R1\n",
       "DeepSeek-R1-Distill-Qwen-1.5B\n",
       "DeepSeek-R1-Distill-Qwen-7B\n",
       "DeepSeek-R1-Distill-Qwen-14B\n",
       "DeepSeek-R1-Distill-Qwen-32B\n",
       "DeepSeek-R1-Distill-Llama-8B\n",
       "DeepSeek-R1-Distill-Llama-70B"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  Give a summary about the DeepSeek-R1 paper\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "DeepSeek-R1 is an AI model that has shown significant improvements in accuracy, particularly in STEM-related questions and long-context-dependent QA tasks. It excels in document analysis and fact-based queries, outperforming its predecessor DeepSeek-V3 on certain benchmarks. The model's strengths are attributed to large-scale reinforcement learning training, which enhances its reasoning capabilities. The paper also highlights the importance of instruction-following data and human priors in designing the cold-start data for the model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  Define LLMs, RAG, and LLM Agents\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Language Models (LLMs) are a type of artificial intelligence designed to capture vast amounts of knowledge about the world. They enable models to answer questions without accessing external sources, by leveraging their vast knowledge base.\n",
       "\n",
       "Retrieval Augmented Generation (RAG) is a framework that provides an integration with both llama-index and Langchain, enabling developers to easily integrate RAG into their standard workflow. It is designed for settings where reference answers may not be available, and aims to estimate different proxies for correctness beyond the usefulness of retrieved passages.\n",
       "\n",
       "LLM Agents are LLMs that use retrieval augmented strategies in combination with other models, or are only available through APIs. They often require significant tuning, as the overall performance will be affected by various factors such as the retrieval model, considered corpus, LM, or prompt formulation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question.lower() == \"quit\": break\n",
    "    # print(query_engine.query(question).response)\n",
    "    display(Markdown(query_engine.query(question).response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c747645-9a21-4377-9b0a-a6ff91104f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680d34c-012f-486b-ab53-11ebf97cb9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c51d91-3766-4ec5-97e6-a712a2b5d6dd",
   "metadata": {},
   "source": [
    "## PDF Summarization with LLamaIndex and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b021af12-4803-4cbf-9aea-613edf16c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bff2d-8ec9-4ac5-a96e-706256fbed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import ollama\n",
    "from llama_index.core import SimpleDirectoryReader, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "@dataclass\n",
    "class SummaryResult:\n",
    "    \"\"\"Data class to store summary results for a single document\"\"\"\n",
    "    filename: str\n",
    "    stuff_summary: Optional[str] = None\n",
    "    map_reduce_summary: Optional[str] = None\n",
    "    refine_summary: Optional[str] = None\n",
    "\n",
    "class PDFSummarizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = \"llama3.2:latest\", \n",
    "        embedding_model_name: str = \"BAAI/bge-small-en-v1.5\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the PDF Summarizer with Ollama LLM and HuggingFace embeddings\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the Ollama language model to use\n",
    "            embedding_model_name (str): Name of the HuggingFace embedding model to use\n",
    "        \"\"\"\n",
    "        # Configure Ollama Language Model\n",
    "        self.llm = Ollama(\n",
    "            model=model_name,\n",
    "            request_timeout=300.0\n",
    "        )\n",
    "        \n",
    "        # Configure HuggingFace Embedding\n",
    "        self.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=embedding_model_name\n",
    "        )\n",
    "        \n",
    "        # Update global settings\n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "        Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=128)\n",
    "\n",
    "    def load_single_pdf(self, pdf_path: str) -> Document:\n",
    "        \"\"\"\n",
    "        Load a single PDF document\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            Document: Loaded document\n",
    "        \"\"\"\n",
    "        reader = SimpleDirectoryReader(\n",
    "            input_files=[pdf_path]\n",
    "        )\n",
    "        documents = reader.load_data()\n",
    "        return documents[0]\n",
    "\n",
    "    def summarize_stuff(self, document: Document, prompt: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Summarize a single document using the Stuff method\n",
    "        \n",
    "        Args:\n",
    "            document (Document): Document to summarize\n",
    "            prompt (str, optional): Custom summarization prompt\n",
    "            \n",
    "        Returns:\n",
    "            str: Summary of the document\n",
    "        \"\"\"\n",
    "        from llama_index.core import get_response_synthesizer\n",
    "        \n",
    "        default_prompt = (\n",
    "            \"Please provide a comprehensive summary of this document. \"\n",
    "            \"Focus on the main points, key findings, and essential information. \"\n",
    "            \"The summary should be well-structured and easy to understand.\"\n",
    "        )\n",
    "        \n",
    "        summarization_prompt = prompt or default_prompt\n",
    "        \n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"stuff\",\n",
    "            text_qa_template=summarization_prompt\n",
    "        )\n",
    "        \n",
    "        response = response_synthesizer.synthesize([document])\n",
    "        return str(response)\n",
    "\n",
    "    def summarize_map_reduce(self, document: Document, prompt: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Summarize a single document using the MapReduce method\n",
    "        \n",
    "        Args:\n",
    "            document (Document): Document to summarize\n",
    "            prompt (str, optional): Custom summarization prompt\n",
    "            \n",
    "        Returns:\n",
    "            str: Summary of the document\n",
    "        \"\"\"\n",
    "        from llama_index.core import get_response_synthesizer\n",
    "        \n",
    "        default_prompt = (\n",
    "            \"Analyze this section of the document and provide a clear summary. \"\n",
    "            \"Highlight the key points and maintain the context.\"\n",
    "        )\n",
    "        \n",
    "        summarization_prompt = prompt or default_prompt\n",
    "        \n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"compact\",\n",
    "            text_qa_template=summarization_prompt\n",
    "        )\n",
    "        \n",
    "        response = response_synthesizer.synthesize([document])\n",
    "        return str(response)\n",
    "\n",
    "    def summarize_refine(self, document: Document, prompt: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Summarize a single document using the Refine method\n",
    "        \n",
    "        Args:\n",
    "            document (Document): Document to summarize\n",
    "            prompt (str, optional): Custom summarization prompt\n",
    "            \n",
    "        Returns:\n",
    "            str: Summary of the document\n",
    "        \"\"\"\n",
    "        from llama_index.core import get_response_synthesizer\n",
    "        \n",
    "        default_prompt = (\n",
    "            \"Read through this document and create a refined summary. \"\n",
    "            \"Start with the main points and progressively add important details.\"\n",
    "        )\n",
    "        \n",
    "        summarization_prompt = prompt or default_prompt\n",
    "        \n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"refine\",\n",
    "            text_qa_template=summarization_prompt\n",
    "        )\n",
    "        \n",
    "        response = response_synthesizer.synthesize([document])\n",
    "        return str(response)\n",
    "\n",
    "    def summarize_pdf(self, pdf_path: str, methods: List[str] = None) -> SummaryResult:\n",
    "        \"\"\"\n",
    "        Summarize a single PDF using specified methods\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            methods (List[str], optional): List of summarization methods to use\n",
    "                                        ('stuff', 'map_reduce', 'refine')\n",
    "                                        \n",
    "        Returns:\n",
    "            SummaryResult: Object containing summaries for the document\n",
    "        \"\"\"\n",
    "        if methods is None:\n",
    "            methods = ['stuff', 'map_reduce', 'refine']\n",
    "            \n",
    "        document = self.load_single_pdf(pdf_path)\n",
    "        filename = Path(pdf_path).name\n",
    "        \n",
    "        result = SummaryResult(filename=filename)\n",
    "        \n",
    "        if 'stuff' in methods:\n",
    "            result.stuff_summary = self.summarize_stuff(document)\n",
    "        if 'map_reduce' in methods:\n",
    "            result.map_reduce_summary = self.summarize_map_reduce(document)\n",
    "        if 'refine' in methods:\n",
    "            result.refine_summary = self.summarize_refine(document)\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def summarize_directory(self, \n",
    "                          pdf_directory: str, \n",
    "                          methods: List[str] = None) -> Dict[str, SummaryResult]:\n",
    "        \"\"\"\n",
    "        Summarize all PDFs in a directory individually\n",
    "        \n",
    "        Args:\n",
    "            pdf_directory (str): Directory containing PDF files\n",
    "            methods (List[str], optional): List of summarization methods to use\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, SummaryResult]: Dictionary mapping filenames to their summaries\n",
    "        \"\"\"\n",
    "        pdf_files = [f for f in Path(pdf_directory).glob(\"*.pdf\")]\n",
    "        results = {}\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            try:\n",
    "                result = self.summarize_pdf(str(pdf_file), methods)\n",
    "                results[result.filename] = result\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "                \n",
    "        return results\n",
    "\n",
    "def save_summaries(results: Dict[str, SummaryResult], output_dir: str):\n",
    "    \"\"\"\n",
    "    Save summaries to text files in the specified directory\n",
    "    \n",
    "    Args:\n",
    "        results (Dict[str, SummaryResult]): Dictionary of summary results\n",
    "        output_dir (str): Directory to save the summaries\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for filename, result in results.items():\n",
    "        base_name = Path(filename).stem\n",
    "        \n",
    "        if result.stuff_summary:\n",
    "            with open(output_path / f\"{base_name}_stuff.txt\", 'w') as f:\n",
    "                f.write(result.stuff_summary)\n",
    "                \n",
    "        if result.map_reduce_summary:\n",
    "            with open(output_path / f\"{base_name}_map_reduce.txt\", 'w') as f:\n",
    "                f.write(result.map_reduce_summary)\n",
    "                \n",
    "        if result.refine_summary:\n",
    "            with open(output_path / f\"{base_name}_refine.txt\", 'w') as f:\n",
    "                f.write(result.refine_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32bd544-9866-4761-be6f-9f24aac9aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage\n",
    "    pdf_directory = \"./documents\"  # Directory containing PDF files\n",
    "    output_directory = \"./summaries\"  # Directory to save summaries\n",
    "    \n",
    "    # Create summarizer instance with HuggingFace embeddings\n",
    "    summarizer = PDFSummarizer(\n",
    "        model_name=\"llama3.2:latest\",\n",
    "        embedding_model_name=\"BAAI/bge-small-en-v1.5\"  # HuggingFace embedding model\n",
    "    )\n",
    "    \n",
    "    # Specify which methods to use\n",
    "    methods = ['stuff', 'map_reduce', 'refine']\n",
    "    \n",
    "    # Process all PDFs in the directory\n",
    "    results = summarizer.summarize_directory(pdf_directory, methods)\n",
    "    \n",
    "    # Save summaries to files\n",
    "    save_summaries(results, output_directory)\n",
    "    \n",
    "    # Print summaries to console\n",
    "    for filename, result in results.items():\n",
    "        print(f\"\\n=== Summaries for {filename} ===\")\n",
    "        \n",
    "        if result.stuff_summary:\n",
    "            print(\"\\n--- Stuff Method Summary ---\")\n",
    "            print(result.stuff_summary)\n",
    "            \n",
    "        if result.map_reduce_summary:\n",
    "            print(\"\\n--- MapReduce Method Summary ---\")\n",
    "            print(result.map_reduce_summary)\n",
    "            \n",
    "        if result.refine_summary:\n",
    "            print(\"\\n--- Refine Method Summary ---\")\n",
    "            print(result.refine_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
