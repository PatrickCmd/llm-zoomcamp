{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66828cb1-f3c2-4d37-a20e-ed22501f557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf02132-e1af-4492-8fbd-93f3b49d9b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4ea5ac-266b-4cd3-a01b-ccdef04cc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 2 (Indexing)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c5b359-5120-4613-a0ab-0c2402462dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')\n",
    "VECTORSTORE_PATH = DATA_PATH / 'vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee3446-d8cc-4fb6-851e-c27b9806aded",
   "metadata": {},
   "source": [
    "# Part 2: Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c8db7-7b68-4c57-aac3-df18f4cf5e41",
   "metadata": {},
   "source": [
    "![](images/02-indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321cec8-1e53-4e81-9751-72aecd8b6c57",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb815c5-6de0-40e6-a698-6a5e31b3102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c9f25d-589f-4aab-852d-370a6a90f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_model_name = \"text-embedding-3-small\"\n",
    "embeddings = OpenAIEmbeddings(model=embeddings_model_name)\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae5556-a40c-4059-8144-1cf9164fb857",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b5f058-7604-4101-9fba-0c10e225ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c432b82-b767-4fd8-b75b-ef108726a41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51ac995-833e-4670-aa5d-84d75b6c479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e6b41-544d-4c0e-be1d-0737617b8316",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027b5bbd-04ac-4922-888a-f2cbbcc33ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81aa6281-08a7-401a-9277-2fab14cd4946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857e737-7d88-4804-a8c4-96cd162f0821",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d510ea37-14e6-4f18-99ca-d092197cd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0218b5-2b6a-40fc-986e-023808e8ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_size(vectorstore):\n",
    "    try:\n",
    "        collection_size = len(vectorstore.get()[\"ids\"])\n",
    "    except Exception as _:\n",
    "        collection_size = 0\n",
    "\n",
    "    return collection_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81904bc1-cf89-4ebf-a6da-eb8112121896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name=\"embeddings\"\n",
    "\n",
    "vectorstore_settings = Settings(anonymized_telemetry=False)\n",
    "client = chromadb.PersistentClient(\n",
    "    path=str(VECTORSTORE_PATH), settings=vectorstore_settings\n",
    ")\n",
    "\n",
    "Chroma(collection_name=collection_name, client=client).delete_collection()\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=collection_name, embedding_function=embeddings, client=client\n",
    ")\n",
    "\n",
    "get_collection_size(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ef079a-b68c-45e5-b727-5b855e0ad3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(splits)\n",
    "get_collection_size(vectorstore)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bcb5d79-c382-4166-96dd-e28cc434053e",
   "metadata": {},
   "source": [
    "**Tokenization**\n",
    "- [OpenAI tokenizer](https://platform.openai.com/tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252fe61e-f27d-45fb-b6dd-bf599036a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357d2986-13d3-40ba-b6c9-921d85880582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e136e704-ecc5-4373-a86a-1af5adc16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae17be41-bbe9-4be9-818f-21a3d504f231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cl100k_base'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_encoding_name = tiktoken.encoding_for_model(embeddings_model_name).name\n",
    "openai_encoding_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd11a8bc-fea6-43a1-80e5-c3d3304df479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(query, openai_encoding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88df3809-be58-444e-ac4f-88325dec10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(document, openai_encoding_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390af5d-98b7-444e-b22c-ee0179c622af",
   "metadata": {},
   "source": [
    "**Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e39b7f41-bb30-4120-b11c-14549b283a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = embeddings.embed_query(query)\n",
    "document_embeddings = embeddings.embed_documents([document])[0]\n",
    "\n",
    "len(query_embeddings), len(document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac15fad-1c5b-4039-a70a-e66b1dbc7e4d",
   "metadata": {},
   "source": [
    "**Cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ddb065-77d3-43dd-a0a5-973dd940fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15569e34-6421-47b6-8b01-797e9c106a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90a29dcc-6f34-479f-b6a3-cd8b8f6eb340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.546556128332727\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(query_embeddings, document_embeddings)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b48c94b-b16c-484b-9e61-19d6ae8aafc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.09272330847288396\n"
     ]
    }
   ],
   "source": [
    "non_relevant_document = \"The weather is fine.\"\n",
    "non_relevant_document_embeddings = embeddings.embed_documents([non_relevant_document])[0]\n",
    "\n",
    "similarity = cosine_similarity(query_embeddings, non_relevant_document_embeddings)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5b821b-69d2-46e9-a0f0-69206421fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(query_embeddings, query_embeddings)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
