{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2222b39-36bc-455d-9481-17dff33d1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88aa43f2-87b0-4a14-9ac5-1d9990eefd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4feed8-73e7-4e61-b347-2c533c328067",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 4 (Generation)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81745de-f05c-4932-aa6a-8f831c7be818",
   "metadata": {},
   "source": [
    "# Part 4: Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e873c-4aa8-4dba-81ba-a2867ae0ea44",
   "metadata": {},
   "source": [
    "![](images/04-generation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea63908-393a-4e50-a6f5-ec20d44cfb78",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96846295-9082-4621-9ed3-9cd59edf9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8dc990-b297-4a3a-b557-5e3de1bed1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BKMy6qbrYoxK6zMiJLaZTEzfSpRYm', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6ba3a93-e962-4ab8-99f0-2f7e12dba1f7-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6376dac-68e3-46eb-a194-7092bbd4900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3aa3f-710d-4739-b6ca-6ac7b872fc48",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ff55a8-698c-492d-9c93-21f3c7657c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab74214f-0da5-4138-a4c3-a4afa7217117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06adbbe9-1f63-41ce-aa2a-c886a6929ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3bd8e-ef35-49d7-9664-7b78a6e4f737",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e6ece55-1a50-46c0-a144-85b4d05e9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee62a6c7-96b1-4600-acd4-2bf63424a64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614dcd8-038f-4458-a47f-59ca9ad67906",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89e293b-056f-4959-bb13-9965f3ba4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d965814f-df36-453c-a72d-8c6cd410aeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9000ce-2d3e-4b68-9492-96e4be835e40",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef37641-1c8f-44a7-8eaa-e36cfd3a601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, START, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c6f90e-3026-4c08-8523-98c913cee2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46786277-5341-4198-8ace-27248cbbe875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0510a92d-cba5-41ed-b4e0-78c1ea6f2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f0c6d3-e01c-4630-8826-8bbdb9b2fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7ffbad81bd50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vectorstore.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        question=state[\"question\"],\n",
    "        context=docs_content\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "604eb61d-b44a-4f6f-b713-583cb59c1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. This can be achieved through various methods, including prompting a language model, using task-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to tackle each component systematically.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "883b9c38-cc57-483d-a896-d62bc416ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. This can be achieved through various methods, including prompting a language model, using task-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to tackle each component systematically."
     ]
    }
   ],
   "source": [
    "# \"messages\": This streams LLM tokens and metadata for the graph node where LLM is invoked.\n",
    "\n",
    "for message, metadata in graph.stream({\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"):\n",
    "    print(message.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ad56af-e6b1-4985-9230-fb0aa1455326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd3910ec-d746-4ac2-8fc5-6338a6680220'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human inputs.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'16861ca7-7003-48df-9bbc-4fc704de093f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'0c8ac67e-64c0-4b76-b9e7-37e5c80d0627'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">field denotes the id of the previous task which generates a new resource that the current task relies on. A special</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this chat history, you can find the path of the user-mentioned resources for your task planning.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'25d35097-35a6-40ea-a9c1-87136f4ae0a9'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'dd3910ec-d746-4ac2-8fc5-6338a6680220'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning \u001b[0m\n",
       "\u001b[32mpossibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple \u001b[0m\n",
       "\u001b[32mthoughts per step, creating a tree structure. The search process can be BFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbreadth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or DFS \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mdepth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with each state evaluated by a classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvia a prompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or majority vote.\\nTask decomposition\u001b[0m\n",
       "\u001b[32mcan be done \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving \u001b[0m\n",
       "\u001b[32mXYZ?\", \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[32mhuman inputs.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'16861ca7-7003-48df-9bbc-4fc704de093f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'0c8ac67e-64c0-4b76-b9e7-37e5c80d0627'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'The AI assistant can parse user input to several tasks: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"task\": task, \"id\", \u001b[0m\n",
       "\u001b[32mtask_id, \"dep\": dependency_task_ids, \"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. The \"dep\" \u001b[0m\n",
       "\u001b[32mfield denotes the id of the previous task which generates a new resource that the current task relies on. A special\u001b[0m\n",
       "\u001b[32mtag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The \u001b[0m\n",
       "\u001b[32mtask MUST be selected from the following options: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Available Task List \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. There is a logical relationship \u001b[0m\n",
       "\u001b[32mbetween tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are \u001b[0m\n",
       "\u001b[32mseveral cases for your reference: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Demonstrations \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. The chat history is recorded as \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Chat History \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. From \u001b[0m\n",
       "\u001b[32mthis chat history, you can find the path of the user-mentioned resources for your task planning.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'25d35097-35a6-40ea-a9c1-87136f4ae0a9'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe \u001b[0m\n",
       "\u001b[32msystem comprises of 4 stages:\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task planning: LLM works as the brain and parses the user requests into multiple\u001b[0m\n",
       "\u001b[32mtasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use \u001b[0m\n",
       "\u001b[32mfew-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition is the process of breaking down a complex task into smaller, manageable steps</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or subgoals. This can be achieved through various methods, including prompting a language model, using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tackle each component systematically.\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'answer'\u001b[0m: \u001b[32m\"Task decomposition is the process of breaking down a complex task into smaller, manageable steps\u001b[0m\n",
       "\u001b[32mor subgoals. This can be achieved through various methods, including prompting a language model, using \u001b[0m\n",
       "\u001b[32mtask-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to \u001b[0m\n",
       "\u001b[32mtackle each component systematically.\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \"updates\": This streams the updates to the state after each step of the graph. If multiple updates are made in the same step (e.g. multiple nodes are run) then those updates are streamed separately.\n",
    "\n",
    "for event in graph.stream({\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"):\n",
    "    rprint(event)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56d1e178-b12c-4a3f-890a-82914f23e57d",
   "metadata": {},
   "source": [
    "# \"values\": This streams the full value of the state after each step of the graph\n",
    "\n",
    "for event in graph.stream({\"question\": \"What is Task Decomposition?\"}, stream_mode=\"values\"):\n",
    "    rprint(event)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e6838dd-adb4-444f-b078-deeeabc52f4f",
   "metadata": {},
   "source": [
    "# \"debug\": This streams as much information as possible throughout the execution of the graph.\n",
    "\n",
    "for event in graph.stream({\"question\": \"What is Task Decomposition?\"}, stream_mode=\"debug\"):\n",
    "    rprint(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a197d9-a013-42fa-b0e6-17d7a3961c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd3910ec-d746-4ac2-8fc5-6338a6680220'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human inputs.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'16861ca7-7003-48df-9bbc-4fc704de093f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'0c8ac67e-64c0-4b76-b9e7-37e5c80d0627'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">field denotes the id of the previous task which generates a new resource that the current task relies on. A special</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this chat history, you can find the path of the user-mentioned resources for your task planning.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'25d35097-35a6-40ea-a9c1-87136f4ae0a9'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'dd3910ec-d746-4ac2-8fc5-6338a6680220'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning \u001b[0m\n",
       "\u001b[32mpossibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple \u001b[0m\n",
       "\u001b[32mthoughts per step, creating a tree structure. The search process can be BFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbreadth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or DFS \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mdepth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with each state evaluated by a classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvia a prompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or majority vote.\\nTask decomposition\u001b[0m\n",
       "\u001b[32mcan be done \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving \u001b[0m\n",
       "\u001b[32mXYZ?\", \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[32mhuman inputs.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'16861ca7-7003-48df-9bbc-4fc704de093f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'0c8ac67e-64c0-4b76-b9e7-37e5c80d0627'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'The AI assistant can parse user input to several tasks: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"task\": task, \"id\", \u001b[0m\n",
       "\u001b[32mtask_id, \"dep\": dependency_task_ids, \"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. The \"dep\" \u001b[0m\n",
       "\u001b[32mfield denotes the id of the previous task which generates a new resource that the current task relies on. A special\u001b[0m\n",
       "\u001b[32mtag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The \u001b[0m\n",
       "\u001b[32mtask MUST be selected from the following options: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Available Task List \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. There is a logical relationship \u001b[0m\n",
       "\u001b[32mbetween tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are \u001b[0m\n",
       "\u001b[32mseveral cases for your reference: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Demonstrations \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. The chat history is recorded as \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Chat History \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. From \u001b[0m\n",
       "\u001b[32mthis chat history, you can find the path of the user-mentioned resources for your task planning.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'25d35097-35a6-40ea-a9c1-87136f4ae0a9'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe \u001b[0m\n",
       "\u001b[32msystem comprises of 4 stages:\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task planning: LLM works as the brain and parses the user requests into multiple\u001b[0m\n",
       "\u001b[32mtasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use \u001b[0m\n",
       "\u001b[32mfew-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. This can be achieved through various methods, including prompting a language model, using task-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to tackle each component systematically."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition is the process of breaking down a complex task into smaller, manageable steps</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or subgoals. This can be achieved through various methods, including prompting a language model, using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tackle each component systematically.\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'answer'\u001b[0m: \u001b[32m\"Task decomposition is the process of breaking down a complex task into smaller, manageable steps\u001b[0m\n",
       "\u001b[32mor subgoals. This can be achieved through various methods, including prompting a language model, using \u001b[0m\n",
       "\u001b[32mtask-specific instructions, or incorporating human inputs. It enhances the model's performance by allowing it to \u001b[0m\n",
       "\u001b[32mtackle each component systematically.\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for stream_mode, event in graph.stream({\"question\": \"What is Task Decomposition?\"}, stream_mode=[\"messages\", \"updates\"]):\n",
    "    match stream_mode:\n",
    "        case \"messages\":\n",
    "            message, metadata = event\n",
    "            print(message.content, end=\"\", flush=True)\n",
    "        case \"updates\":\n",
    "            rprint(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
