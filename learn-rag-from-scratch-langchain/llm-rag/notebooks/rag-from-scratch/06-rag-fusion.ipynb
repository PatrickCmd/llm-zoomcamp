{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a417e1-53d5-499a-aa6a-1705af508ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af26db2a-d46d-4824-9ebc-399362768694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0bde02-2d6b-43cd-b6ae-32b2dd5a61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 6 (Query Translation - RAG-Fusion)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9645807-7209-4c18-9d33-293ccf5c3c65",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b67d1a-266c-4c82-aa7c-3c596c4d4541",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fd680-9d6d-4149-b301-057011be009e",
   "metadata": {},
   "source": [
    "![](images/query-translation-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b1c74-633d-4c6a-9e21-848404e15938",
   "metadata": {},
   "source": [
    "# Part 6: RAG-Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfa48e-4c6f-4c56-bc38-beed22b3dcbf",
   "metadata": {},
   "source": [
    "![](images/06-rag-fusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0577a2-02e7-40c4-9bbb-e0c4b867fec9",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeacceb9-ca2f-4a6d-9ef4-7d336eb24c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aabe3b1-a293-4a11-9223-9b244c3318f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BKNDWQ6BEgCgTcxCiZtPj3mRq8gLt', 'finish_reason': 'stop', 'logprobs': None}, id='run-df5c0736-2b02-40df-a334-87f4a43f9e7d-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9005cc-1373-490d-ae93-6c2a63ae1e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d0057-f947-4fce-8c1d-15ca3ee2f314",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec75c34-7b75-445f-b8aa-e6a5530364cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe983d1-0ecd-4dbe-86b1-21b87c7b2d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ae07ef-ef25-4cc4-ae60-2e23c0978e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87460646-96d5-45af-9e8e-ff694eebab8e",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e2b315-8e3a-47f1-8a8c-cd3156d7e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6225e318-c420-41b7-b7f6-4fb2ea9b948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50011489-d342-45ba-80ac-684276daee5f",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b2a91d-1e40-4831-bb44-e9818f817519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a900ad25-1a29-4764-9225-c5cfc3a431ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04329c-1551-481e-a34d-26357457ce41",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18cdb06-cac4-46af-949f-57f5acc224c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.load import dumps, loads\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5370ea-b1c3-4ce7-8edf-3eecf7ee8481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on this context:\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17361868-dbe4-469a-afbf-e1af486254f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list[Document]], k: int = 60) -> list[tuple[Document, float]]:\n",
    "    fused_scores = defaultdict(int)\n",
    "\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs, start=1):\n",
    "            fused_scores[dumps(doc)] += 1 / (k + rank)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c4d4c2-aa71-4a0d-8f9b-bd49ba4ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]) -> list[str]:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01db724f-376b-44c5-88b1-7e658bf40164",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition for LLM agents?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b35c588c-1ace-4571-9d08-70b8869798b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    generated_questions: list[str]\n",
    "    retrieved_docs: Annotated[\n",
    "        list[list[Document]], operator.add\n",
    "    ]\n",
    "    context: list[Document]\n",
    "    context_scores: list[float]\n",
    "    answer: str\n",
    "\n",
    "class RetrieverState(TypedDict):\n",
    "    generated_question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b79c08c-970e-4e0c-813e-a0bb593e58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(state: State, config: RunnableConfig):\n",
    "    generated_questions_count = config['configurable'].get(\"generated_questions_count\", 5)\n",
    "    include_original_question = config['configurable'].get(\"include_original_question\", True)\n",
    "\n",
    "    questions = []\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    if include_original_question:\n",
    "        questions.append(query)\n",
    "        \n",
    "    class MultiQueryGenerator(BaseModel):\n",
    "        questions: list[str] = Field(\n",
    "            ..., \n",
    "            description=\"List of questions generated multiple perspectives based on user query\", \n",
    "            min_items=generated_questions_count, \n",
    "            max_items=generated_questions_count\n",
    "        )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(MultiQueryGenerator, method=\"function_calling\")\n",
    "    response = structured_llm.invoke([\n",
    "        HumanMessage(content=query)\n",
    "    ])\n",
    "    questions.extend(response.questions)\n",
    "    \n",
    "    return {\"generated_questions\": questions}\n",
    "\n",
    "\n",
    "def assign_queries(state: State):\n",
    "    return [Send(\"retrieve_docs\", {\"generated_question\": question}) for question in state[\"generated_questions\"]]\n",
    "\n",
    "\n",
    "def retrieve_docs(state: RetrieverState):\n",
    "    retrieved_docs = vectorstore.similarity_search(state[\"generated_question\"])\n",
    "    return {\"retrieved_docs\": [retrieved_docs]}\n",
    "\n",
    "\n",
    "def aggregate_docs(state: State):\n",
    "    retrieved_docs = state[\"retrieved_docs\"]\n",
    "    reranked_results = reciprocal_rank_fusion(retrieved_docs)\n",
    "    docs, scores = list(zip(*((doc, score) for doc, score in reranked_results)))\n",
    "    return {\"context\": docs, \"context_scores\": scores}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        question=state[\"question\"], context=docs_content\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fe93cf4-d6ee-4ec7-8312-cb09b833ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAAITCAIAAAD3jHt/AAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcE+fjx5/kskjC3mHvqaDgxLrr3uKeda+6cI/WvXHhwlFxU7WotbZ11roXioKy9x4BQiZJLvn9cf4o9QsBa+ITeO796qsvcs/d4ye5d567yz33PBS1Wg1IEIYKOwAJZEgDUIc0AHVIA1CHNAB1SANQhwY7QANIRcryYoWkSikR4rhSrVQ0gWtXpgGVzqCyjTC2IWblwIIdpwH01ABhpSLtjSgjQSwV4mxDjG1EYxtiXFMaaAICAJUSFBZIJVU4w4CamyRx8ee4tuC4+HNh56obir79IqRUqJ5c51eWyM1sma7+HJ6bAexEX4RUjGcmiAvSpYWZso4Dzd1a6p0H+mVAwpPKh1f4HQeaB3Q2gZ1Fy1SWyp9c56tU6l4TbBhMPTr90iMD7l4oNjSlt+1jBjuIDinJk12JyB80i2froi9tm74Y8PtPhc5+HN92RrCDfA0u78vrPtrKzJoBOwjQFwMu78vzDzHyDkZi9xNc3pcX1NPUxY8DO4ge/B5w/1KJV7AhUrsfABC6wP7vy6XCCgXsILANSHxRxTbEWoQYw40BhbErHO5Gl8BOAduA+5dKW/cwhZsBFgwmZuvMenGzHG4MmAY8/4Mf1NOURod/JIJFu77msXcqlAoVxAzQPn2FXFWYJWvbuzlf+zWGLqEWr+9VQAwAzYDMeLEBF4P1r+sPDp7sD8+EEANAMyAjQezq/7WvhZYvX379+vX/sGHPnj0LCgp0kAgYmtJZHGppXrUuKm8McAxQq9UCvsL1q/9InpiY+B+2Kioqqqys1EGcj3gFG+Yki3VXv2bgGCCqVEqFOIZRdFT/1atXR44cGRIS0qNHj6VLlxYXFwMAgoODCwoK1q9f37VrVwAAjuNHjhwZMmRIx44d+/btu23bNqlUSmzes2fP8+fPz58/v0OHDg8fPhwwYAAAYNCgQWFhYbpIyzGileXLdVFzo1DDoChb+nN4jo4qf/36dVBQUExMTG5ubnx8/LRp0yZPnqxWq4uLi4OCgqKjoysrK9Vq9enTp9u1a3fz5s3s7OynT5/26dNn586dRA29e/cePnz4vn373r59K5VKb926FRQUlJiYKBKJdBE4L1USE5Gni5obA5z+AZIqnG2kq9PA9PR0JpM5cOBAGo1mb2+/bdu2wsJCAICxsTEAgM1mE3/07du3Q4cO7u7uAABHR8devXo9fvyYqIFCobBYrPnz5xMvORwOAMDIyIj4Q+uwjTBxlVIXNTcGOAaoVGoGS1cHoODgYAqFMm3atMGDB7dr147H45mbm//vaiYmJjdu3Ni0aVNJSYlSqZRIJGw2u6a0ZcuWOor3v2A0QGfo6oDYIHDOA9iGWBVfV9Y7OzufPHnS3t4+IiJi0KBBkydPTkhI+N/Vdu7cefz48ZEjRx47duz8+fNDhw6tXcrlfr2zVLEAx+D9LAbJACOaRJftnoeHx6ZNm27fvh0ZGYlh2MKFC+Xyf51q4Th+7dq1SZMm9evXz87OzsLCQiQS6S6PZsRVOEdnx8QGgWMA1wgzNNfVASghIeHdu3cAAAzDgoKCZs+eXVlZyefziVLibrhKpcJxnDghAACIxeIHDx5ovlGuu9vociluacfUUeUNAscAjE7FMGp2ok4ugp88ebJ48eK7d+/m5eUlJydHR0fb2tra2NgwmUwmk/n69evk5GQKheLl5fXbb7/l5eWlpqYuXLgwJCSkqqoqKytLqfy0cTIyMgIAPHr0KCMjQxeBk14JbV2hdRmC1lfY1Z+TkSB28tH+2fWUKVMUCsXevXtLS0u5XG5AQMD+/fspFAoAYPLkyadOnXr48OHVq1d/+OGHDRs2jBw5ksfjzZ4929/f/+3btxMnToyOjv6kQh8fn44dO+7ZsycwMPDIkSPaTVstxcvy5Xbu0AyA1kdIJFD+dbFk4HQelH9df0h7KyzOloUMsoQVANopKNeYxjWmJTwRwAqgJzy+xm/RCWbHaJhPjHQcaH5qQ7Z/x7o7CCmVyp49e9ZZJJfLGYy6u1m6uLicPHlSqzH/ISoqKioqqs4iLpdb39VEQEDAvn376ixKeCxw9GEbmdG1GvPzgNxT9PXdcjqr3l5iQmHdt02rq6sZDAZxaP8EKpWqo1/uiH/3k6vKGhQKBZ1e947EMKz2b021uXYkv/dEaxYb5vcQfl/ha4fzW3U3dfSq+zNqxlw5mN+ml6m9B+Q3Dr+H1uDZdrfPFutDr9mvye1zRS7+HOi7Xy/aAOI2wbmtOb3GW1s76fuTtlrhzvli1xYc1xZ68QyhXhhAcHFPbkBnY6+g5vzggFKhunIw36edkX8Hfekgr0cGAAAe/1qWlyYNGWiuD82j1nn2Oz/rg7hrqJWNsx41dfplAACgJEf2+Drf2IJu68Jy8eew2E2+N2lxtiw3VfLiz/I2vcyCe5pSqNBuBNeJ3hlAkJMsSYkVZiaIbV1YhqZ0jjHGNqJxDGm4Sh/TfgKFAoTlCpFASQEg8YWQa0pzD+AGdDbBaPq17wn01IAaCtIlZYVysQCXVCkpVIpUhGuxcpFIlJeX5+3trcU6AQCGJjQ1AFxjmqEZZufO5hjp6UAtBPpugE6Ji4uLiIg4ceIE7CAwgf97AAlcSANQB2kDMAyzs7ODnQIySBuA43h+fj7sFJBB2gCd3khsKiBtgEqlEouhPbCnJyBtAJVKNTVFdASTGpA2QKVSVVTAHL1BH0DaAAzDHB0dYaeADNIG4Diek5MDOwVkkDaABHUDqFQq8TwQyiBtgEqlqqqqgp0CMkgbQLYBqBtAtgGoG0CCugEYhtna2sJOARmkDcBxnBhkCmWQNoAEdQMwDLO3t4edAjJIG4DjeF5eHuwUkEHaABLUDSDvDaJuAHlvEHUDSFA3gOwtjroBZG9x1A0gQd0A8nkB1A0gnxdA3QDy3iDqBpD3BlE3gAR1AygUCvnUGNIGqNVq8qkxpA2gUqkODg6wU0AGaQNUKlVubi7sFJBB2gDy7jDqBpB3h1E3gEqlWlhYwE4BGRRHlBw1apREIqFQKDKZTCqVmpiYUCgUqVR6+/Zt2NEgoNcDnuqIHj16HD16tOYlMek8sicEKB4Fxo4d+8lFIIVC6dWrF7xEMEHRAC6X269fPwz7Z9x6e3v70aNHQw0FDRQNIJqB2s+K9O7d28QE5qR/EEHUAA6HM2jQIKIZsLe3HzFiBOxE0EDUAADA0KFDibOBPn36mJubw44DjYavBRTVKn6hXKLVqR30A6xvl8kPqQ87Bg7NSGhuPYWoVGBmzTAyb3g20wZ+D3gQU5oWJ+IY0wy4KF43Nl24prScJLGpJT34WzPNE5trMuCPk4Wmtiy/DqjfQW+6VMvw26fzu43QNLtZvQbcPldsYs30boPoGXJz4uqB7AHTbE2t656ru+4zweJcmUyqInd/86D9QKuXt+vtCFO3AeWFchod3cuEZoaxBT0nSVJfad27WVylNLGou9EgaXIYcGgcI1q1TFVnad0GqHCAK5G7Z9iMqeLLqZS657skm3rUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQB3SANQhDYDM4KE9Tp85DjFAMzdg3frlf968DjuFJubMWtS+fSeIAZq5ASkpibAjNEDv3gM8PbwhBtBa/8+ystLwPZvfvHnJ5RqGDh8rFosePLx36uRlAIBSqTx77sS9v24VFxdaWlqPCB03eFAoACA7O3PylBG7w4/8EnMhPj6OSqV26/rt3DlhRDf+ysqKQ0f2vH0bKxBUurp6TJ82r1VgMADgytWLp88cW7J4za7dm3p923/2rIUVFeWHI/e+fv1CKKyytLQeNmTUsGGjAQDdegQDALbvWH/wUPj1a/cBAHfv3bx06Wx2TqaBAbt7t97Tps5lsertQEdQWlqya/emuLhXhoZGA/oPUyjkDx7eO3MqBgDQt3+nyZNmjho5gVhz566NaWnJkUfOagifmZk+ZdqozRt3Hz0eYcAyOHzo9OChPYYPGzNxwjQNWymVymPHD9z/+3ZFRbmJiWmXzj1nTP+eTm+4H3Bj0JoBu3ZvSktL3rgh3MzU/PhPB3NyshiMj31MjkTuu/H7lYXzV/j5B8TGPj9wcBeNRuvfbwhGowEADh4KX7Rg5aYN4bGvXyxZOqdFi1bdun6rUqmWr/heJBYtX7bO3Mzi2q+XVqycf/jgaVdXdzqdLpNJY65EL1+2ztHRGQCwY9eG3Jystau3mJmZxyfEhe/ebGVt0ymk68Xo30eO7vf9vKU9evQBADx6dH/T5tVjx0xes2ZLXl7O7j2bBVWVq1du1Py+tm77IS8/Z+uWfeZmFleu/vzo8X1DwwYmqdQcHgBw6vTRUSMneHn6NnKr8xeibt2+sWrlRh7PPjcna9fuTQwGY/q0eV+804DWjgLl5fwXL56MHze1TXB7NzePNas2VwkqiSKRSHTt10ujRk7o3XuAvZ3D4EGhvXsNOH8hqmbbLp17+vm1BAAEtW7Ls7VLTv4AAHgV+zwlNWlJ2JrWrdo4ObnMm7vE2to25ko08ZSnTCYLHT62fbsQnq0dAGDunLAdOw4GBLR2cHDq13ewu5vnq1fPAABGRsYAADabbWxkDAA4Hx0VENB6+rR59nYO7duFTJ/2/Z07f5SUFGt4X6WlJW/iXo0d8x0RY8H85SxmA22G5vCAQgEABAYG9+0zyNXVvZFbZWamubq4twlub8ezb9++0+5dR/r0Hvjf99a/0Y4B+fm5arXa3y+AeMnhcIKC2hF/p6enKJXK4KD2NSsHBAQVFORJJB97rrm5etQUcbmGIpEQAJCYmECn0wMDgj6mpFJbtmiVlpZcs6avb4uavw1YBr/EXJg6fXToyD7DQntlZKZVVQk+SahSqVJSEmvHICrPyEjV8L6yczIBAO5unsRLCoXi7ePf4KfxWeEbs1XHDp1fv3m5YePK+3/fqRJWOTo6Ozg4NRijkWjnKCAQVAIADNjsmiXE9w8AIJGIAQCLwmZS/r+XEtE/vbyCT7xkMJm1qyJKJRKxQqHo3bdjzXIcx83M/nm2i8PhEn8olcplK+bhOD5v7hJHB2cMw9b8EPa/CWUyGY7jUaciT585Vns5v7xMw/uSSiUAADb7n9GnOeyGR6JufPhGbvXtt/3YbM61Xy9t3fYDjuMhHbssXLDC1NSswSSNQTsGEHuxWiarWSIUfpzPl3i3q1dtcnX5V6NnZWldUlpvC8zhcBkMxrHI87UXUql1tFiJiQkZGWn79hxr2bIVsURQWWFrw/tkNRaLRaPRhg0d3b/fkNrLTTR+jiyWAQCgurqO90U0CbVXlsurPzd8bTRvFRLSJSSki1Qqffb80cFD4TvDN27ZtEdzhY1EOwbY2TkAAJKS3xPHNrFYHBv73NzCEgDg6upBp9MrKsoduzgTK1dWVlAolJrzxDrx9vaTy+U4jru4uBFLiooKTUzqeHqpWl5du8l5//5dYVGBl9c/J1lEo0KlUj08vIuLC4mTRwCAQqEoKS020nha52DvBABISU3y8fEnvpTvP7yraRLYbA5xzCJIz0il0+ifFb6Rb/nRo/tu7p62NjwDA4NuXb/Nykq/deuG5toaj3bOA+x49p4e3ufO/fT+/bucnKyt238w/f9Gj8vlDhgwLOpU5L2/bhUU5r+Je7Vk2ZxtO9ZprjCodVsPd68tW9fGxcUWFhXcufvnjJljr/166X/XdHfzZDAYMVei+fyyl6+e7Y/Y0Sa4fW5edkVFOZPJZDKZb9+9Tk1LViqVo0dNfPDw3vkLUbm52alpyVu2rp2/YKrm0eVtbGz9/FqePXfi+YsnKalJ27b/WLvU09Pn0eP7AkGlQqE4d/5kzclH48M38i3/EnNhw8aVb9++Jj7A+3/fCQgM0lxb49Ha1eCa1Zt3hm9cFDbTwtxy3Lgp5mYWSUnviaI5sxYZcg2PHtvP55eZmZl37NB56pS5mmvDMGz7tojDkXt/XL9MJpPa2PAmTJg2InTc/65pYmK6bOmPx48fuHX7hqenz/Jl60rLSjZuWrl4yayTJy6OGT05+udTT58+PHvmaudvuq9aufFCdNTJqCMcDtffP2BPeGSDM0ysXrVp166Na38I43C4gwYO53IN497Gfnxfsxfv2Ll+9NgBhoZG/foO6d1rwMuXTz8rfCPf8g9rtx46vPvH9cvEYpG5uUX7dp2mTdXOpWC9zw2+uFkul4GArp9xriGTyRRKhSHXkHi5OGyWkZHxuh+3ayuonrBv//a4t7EnT1yEHeTzOL8lfcoGVzqzjkcGtNYGrFq9sLyCH7Zotamp2dNnD9/Evdq6ea+2KifRHdo8Chw6vHvtj0uqq2U8nv2KZevg3vBoPAMHd62vaMWy9SEhXb5unK+N1o4CTZfCooL6ikxNzBq8cdAk+BpHgabL//54gBTN/O4wSYOQBqAOaQDqkAagDmkA6pAGoA5pAOqQBqAOaQDq1P2bIIuNqfC6Bx8jaYqY2zEpWN1FdbcBxha0wiypbkORfC0qSqqrJSoa7XNGk7P3YMulzW84eUQpyZF5tqqjbypB3QZgNEq7Pma3TufrMhjJ1yAnSZQeV9Wmd723eTWNLp+fLr15uiiwi5mJNZNtSN5FbGLwC2XCckX2B9HIRfYUat2HgIZnmBBVKl/fqyjKkkmEzfCgoFKplEql5l7LTRQLHgsAtaO3QctvGhggHsU5R2uIi4uLiIg4ceIE7CAwQdqA8vLyxMTEkJAQ2EFggrQBJKj/JpiTk3PhwgXYKSCDtAHl5eV37tyBnQIySB8FpFJpcXGxs7Mz7CAwQdoAEtSPAjk5OcePwxzJTR9A2oDy8vKnT5/CTgEZpI8CIpEoJyfH19e3Ees2W5A2gAT1o0BmZub+/fthp4AM0gYIBIK3b9/CTgEZpI8CAoEgIyOjVatWsIPABGkDSFA/CqSnp4eHh8NOARmkDRAKhR8+fICdAjJIHwXI3wNQN4AE9aNARkbG3r2oD3iGtAFVVVXx8fGwU0AG6aNAZWVlWlpacHAw7CAwQdoAEtSPArm5uWQ/QaQN4PP5ZD9BpA2wtbUdOnQo7BSQIc8DUAfpNoDP59+/fx92CsggbUBubu6ZM2dgp4AM0gaYm5sj/tAgeR5AgnYbQJ4HoG4AeR6AugE8Hi80NBR2CsiQ5wGog3QbUFBQcPFiE5s3TusgbUBJScnNmzdhp4AM0gaQ5wHkeQAJ2m1AYWHh5cuXYaeADNIGFBcX//HHH7BTQAbFo8DUqVPlcjmFQpFIJDKZzNTUlEKhiESimJgY2NEggOJowW5ubr/88guF8nGo3aKiIgCApaUl7FxwQPEoMHnyZHt7+9pL1Go1sjcJUTSAx+N17ty59uHPyspqwoQJUENBA0UDAABjxozh8f6ZcLp9+/ZOTk5QE0EDUQN4PF6XLl2IZsDW1nbSpEmwE0EDUQOIZsDOzg4A0LFjR5SHFdX+tUAVX6FhRgv9wYht3blj78ePHw8dOFZYoYQdp1FQMcAx0vIu09rvAcU5stg7FZkJYp6rgYCv0EqdJJ9gbEGvKJF7tzHsOMBCW3Vqx4C8VOmDK6WdhlobWzCoTaEBaLpIhMr8VHHam6rQBfZUTAsftRYMyEuTPrxSOmCG45enIWkkeani+AflIxc7fHlVWjgTfH2vouc4XiNWJNEa9h4cO0/O+6eCL6/qSw2QCJUlOdUsDoq/LsOFbUgryJB9eT1fakBlqcLBi/3lOUg+F3NbJq7UwjnclxqgVoOmcinVzMBxUFmqhWsudH8RIiEgDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1GnCBvy4blnYktkQAwgEld16BN//u2mPS6vvBgwZ1rOwqKDOogEDhoUOH/vVEzU39Pq+fnFxkUBQWV9pm+D2XzdO8wSCAevWL6dQKI6Ozhcvnf1hzdYOHb5JSU06fvxAckqiUqlo3art3DlhNja2b+JeLQ6bBQAYO25QSEiXTRvChwzrOX7clJevnr158zLm8u2duzaIRMLwXYcBAJWVFYeO7Hn7NlYgqHR19Zg+bV6rwGCxWDws9NtJE2eMHTOZ+KcVCsWw0G8HDQydPm1enZs0GP7X67+cO/9TZWWFh4f3tClzaxfFx8cdO3EgJSWRQqH4ePtPn/69j7cfUXTz5m8Xfj5VWJhvY8MbPWpi3z6DCL+PRO6NexsrkYhtbHihw8cOHDBMJ5+4RiAcBeh0ekZmWkpq0rYt+319WxQXFy0Om0mhUveER4bvOlIlFIQtnS2Xy1v4B/6wdisAIPLI2ZXLNwAAaDTa9d9iXF3c94RHslismgpVKtXyFd+/f/9u+bJ1kYfPenv5rlg5PyMjjcPhtGsb8vDRXzVrxsY+F4lEPbr3qW8TzcnfvXuzZ+/WLp17Hj96Yfy4qYeP7Kkpys3NXrJsjqWF1cGIqAP7Txqw2UuWzi4pKQYA/P3g7o5dG/r0Hrh/34kB/Yfu2LmBOHXYsXN9Gb90y+a9P524OGzo6L37tr189Uw3H7kmIBigBqCgIG/F8vUBAa2NjU1+vX6ZQqGsWb3Z1dXd28t31YqNhYX5fz+4S6PR2GwOAMDQ0IjD4QAAKBQKi8maOWO+n19LGu2f1utV7POU1KQlYWtat2rj5OQyb+4Sa2vbmCvRAIBu3XolJb0vLS0h1vz7wV0XFzdXV3cNm2jg1u0bZmbmM2fMd3Bwat8uZMSI8TVF1369bGDAXrlig5ubh5ubx+qVm5RK5c1bvwEALl0+1ymk6+hRE708fUaEjhs9aiK/rBQAkJGZ1ia4g4+3nx3PfvCg0AP7f3Jz9dDZp14vcM4EHRycjI2Mib8TExO8vfwMuYbES2trG1tbu7S05Do39PNr+b8LExMT6HR6YEAQ8ZJKpbZs0YqooUP7b1gs1qPH9wEASqXyydMHPbr30byJBrJzMj09fTAMI176+PjXFKWkJnp6eNd4yWazHRyc0tNTAAApKYleXv9MaThzxvzhw8cAADp26HwhOurQ4T2xr18oFAofH38zM/NGf4RaA86ZIIfDrflbLBalpiX36tOhZolCoeCXlzW4YQ0SiVihUPTu27FmCY7jxKfJYrE6tP/m4cN7Q4eMfBP3qqpK0L17b82baEAiEZub/fOohgHLoL4iAACbzZFIxDKZTKFQsGqtWcOihStdXdxv3/n90uVzHA5n0MDQKd/Nrt22fR3gXwtwONwWLQLDFq2uvdDA4DN6n3I4XAaDcSzyfO2FVOrH5q1bt17rN6wQVAkePrzn69vC1obX4Cb1wWIZiMWimpcikbB2htpFhNnmZhYsFovFYkkk4v+tjUajDR8+ZvjwMeXl/Fu3b5z46ZCJienIWkeWrwP83wN8fPzz83N5PHtHR2fiPwqFYm7+z/epwWdavL395HI5juM1NTAYTAsLK6K0bZuOTCbzxYsnj5/8TRwCGtykPhzsndIzUlUqFfHyVezzmiIvT9/klESF4mPXTaFImJOT5e3tBwBwd/d69+51zZoRB3dFHNwlEolu3/lDqVQCAMzMzEePmujr26LBU1FdAN+AgQOGS6WS7TvWpaYl5+XlnD5z/LupI5OS3gMAjAyNAADPnj3KysrQUENQ67Ye7l5btq6Ni4stLCq4c/fPGTPHXvv1ElHKZDI7duzy88XTlZUV3bp+25hN6qNHjz4VFeUHD+/OyEh78PDerVu/1RQNHjyiulq2Y9eG3NzsjIy0TZtXczjc3r0GAABCh499+erZyagjSckffomJvnr1oo+3P4VC2R+xfVf4ptS05ILC/Dt3/0xJSQwMDNLGJ/p5wD8K2NjY7g6PPHp0//wFUzEMc3Z227Rxt69vCwCAp6dP27YdDx/Z08I/cHf4kfpqwDBs+7aIw5F7f1y/TCaT2tjwJkyYNiJ0XM0K3bv2WnXnjzbB7U1NzRq5SZ20CW4/d87i6J9PX7/+i4eHd1jYmhkzxxFNlB3Pfuf2g0ePR0ybMQbDsBb+gXvCI01MTAEAXTr3WLhgxcVLZy9En7K2tp3//bKePfoAALZvO3D8+IHFYTPlcrmNDe+7ybP69B6ovc+1sXzpc4P56dKnN8p7T7LTXiSSRlFWUP38RsnoJV/66CD8owAJXOAfBfSKlasXJiTE1VnUv9/QWTMXfPVEOoc04F8sWbxGrpDXWUT8QNn8IA34F7WvQhGBPA9AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQJ0vN0BtZEbXShSSz4JKAaZWWvjkv9QAcxtm9gdRI1Yk0TL8wmoaXQvjCn+pASwOxnM1EFWSg4l/bcRVCjv3Ojqgfi5aOA9o08f07rm6H+0j0RGpb6r4+TLvNkZfXpV2RpcvK6z+7WhBp6E2xhYMFgf78gpJ6qOipLogXVKSIx043bZmwrwvQWszTFTxFS9vlWe+Fxtb0CuKm8ZBQQ3UKpUaa6iTuP5gYs1QVqu82hgGdTfVVp3an3NUJlZRmshHGh8ff/To0YiICNhBGgtGp9BoWp7AQ/s9RFicJrL/AaAx1LhaxjRoMoF1AdJvngR1AzAMs7W1hZ0CMkgbgON4YWEh7BSQQdoADMMcHVGfIAtpA3Acz8nJgZ0CMkgbgGGYg4MWJmxr0iBtAI7jubm5sFNABmkDKBQKm436RGlIG6BWqyUSCewUkEHaABLUDaBSqeSZINIGqFQq8kwQaQNIUDcAwzArqwbGD2v2IG0AjuMlJSWwU0AGaQNIUDeASqUSY1ajDNIGqFQqsbiO8V6RAmkDKBSKVrrbNmmQNkCtVmu9o2yTA2kDSFA3gDwTRN0A8kwQdQNIUDeA7C2OugFkb3HUDSBB3QDyeQHUDSCfF0DdABLUDSB7i6NuANlbHHUDyDNB1A0gzwRRN4BKpZqbQ5juW69A2gCVSsXn82GngAzSBlCpVDMzM9gpIIO0ASqVqry8HHYKyCBtAPncIOoGkM8N6mRJyJ13AAAeu0lEQVRMUf1n9erVN2/eVKvVFAql5v/W1ta///477GgQQLENGDdunLW1NdFPvKa3eMuWLWHnggOKBvj6+rZq1ap248fj8caNGwc1FDRQNAAAMGHCBBsbm5qXfn5+LVq0gJoIGoga4OXlFRgYSPxta2s7ZswY2ImggagBAIDx48cTzYCPj09AQADsONDQ/ujyTQUfH5+WLVsqlcrx48fDzgKTz7sazEuRvH0oEFUqBWVNYxYRzajUapUKp2HN4WtgwWMqFSoHL3aH/p93r+szDHj/tCr5tdAzyNjclslgkZMJ6RdUKqgokQvL5c9+K/1uvQuD1djje2MNeHm7vDRP/s0wm0asSwITRbUqekfG7B1uFGqjHoxvlCn8wuri7Gpy9zcJ6Exqj7G29y+VNnL9RhlQkCFjGpDNfpPB0t4g5bWwkSs3ygCxQGnlqIXpLUm+DnQm1c6DXVnSqLP1RhkgEeJKJXI3kJo0lSXyRp7io/uLEAkBaQDqkAagDmkA6pAGoA5pAOqQBqAOaQDqkAagDmkA6pAGoA5pAOqQBuiK76aO3Ld/O+wUDUMa8JEhw3oWFhXATgEB0gAAACguLhIIKmGngIOuuslWVJQfjtz7+vULobDK0tJ62JBRw4aNJori4+P2R+zIzsnk8exnz1p09twJN1ePhQtWaCi6cvXi6TPHlixes2v3pl7f9p89a6FSqTx77sS9v24VFxdaWlqPCB03eFBog/UnJX84fvxAalqyXF7t7OQ6derc4KB2b+JeLQ6bBQAYO25QSEiXTRvCNVSugfj4uH0R27OzM21seNOmzq1dVFJSfPjIntjY51KZ1MHBacyoSd9+248o4vPLDh3e/eLlEwqFGtS67exZi6ysrAEAN36/evmX84WF+UwmK6Bl63lzlxDLtY6uDNixa0NuTtba1VvMzMzjE+LCd2+2srbpFNK1urp6zQ9hzs6uBw9EiUWig4fCKyrL3d08AQAaiuh0ukwmjbkSvXzZOkdHZwDAkch9N36/snD+Cj//gNjY5wcO7qLRaP37DdFc//IV3/v6tti18xCdRr9+I2btD2Gno2Ja+Af+sHbrho0rI4+cteM5aKhcw/sViUSr1y52d/M8cuiMQqk4diyCzy8jihQKxdLlc+l0+sYN4ebmFnfu/rFl2w9sNickpItSqVyxcj6NRlu/bicNox06vHvl6gXHIs8nJLzdFb4pbPHqVq3aCASVkUf3rd+44mDESV3sKV0ZMHdOGJVK5dnaAQAcHJyuXbv06tWzTiFdnz57WFUlWLRgpbOzKwBg/vfL5i+cRmyioYhCochkstDhY9u3CyE+7mu/Xho39rvevQcAAOztHFJTk85fiOrfb4iGSjAM2xMeaW5uYWxsAgCYMnl2TEx0wvu33bp+y2ZzAACGhkYcDkdD5Rre77Pnj4TCqvnfLyP+3RXL148c/fFb/vz545ycrKOR5zzcvQAAkyfNjH394srVn0NCuryJe5WWnnLiWLSrqzsAICxszblzP5WVlWZmpTOZzD69B9JoNDue/Y9rtxUV62oMdF0ZYMAyOB8dFRf3SiCoVKlUQmGVnZ0DACAnJ4vL4RIfEwCgRYtAYn9oLiLw9f34cGd6eopSqQwOal9TFBAQdOP3qxKJREMlNBpNoVTsj9iRlp4iEgmJbvJVVYJPkmuoXMMApNnZGSwWq+bftbS0srT8OJ9taloSk8kk2iECT0+fu3f/BACkpCQyGAxi9wMAPNy91v24HQDQKjCYQqHMXzitX9/BQUHtbG14Zma6GvNMJwYolcplK+bhOD5v7hJHB2cMw9b8EEYUVVUJ2P+e2sfIyLjBIgIOh0v8IZGIAQCLwmbWPP1P7M7yCr6GSvLycsKWzGoV2GbVyo0W5pYqlarma1obDZVrMEAilTCZrNpLDAw+riwSi1gsg9rT2nHYHOJfEQqrWKw6uuA6Ojof2H/yws+njh6LEO7e7OPjP2/uEl8f//r+9S9BJwYkJiZkZKTt23OsZctWxBJBZYWtDQ8AwGQyZTJZ7ZVrvoUaij6BUGH1qk2uLu61l1tZWmuo5N5ft3AcX7N6M5PJJM7/P7dyDW+ZxWSJxaLaS0Sij/21uRyuVCohBishloglYuJfMTExlUjEtYtqcHPzWLNqE47j8fFxJ04eWrV64aWf/6DT6Roy/Dd0cjVYLa+u/eV7//5dYVEB8U2ys3OoqhLkF+QRRfHxcTWXYRqKPsHV1YNOp1dUlDs6OhP/GRkZGxubMBgMDZUoFHImk0XsfgDA7TufjhlDJNRQuYa37OjgrFQqs7IyiJcZGWnl5R9HKvTy9JXL5SmpSTUrf3j/ztvbDwDg7u6lVCo/fIgnlmdlZcycNT4zMz0xMeH9+3fEuUtgYNCU72YLBJUVFToZ9kwnBri7eTIYjJgr0Xx+2ctXz/ZH7GgT3D43L7uiorx9u05MJvPAwV05OVnx8XGHI/eam1sQW2ko+gQulztgwLCoU5H3/rpVUJj/Ju7VkmVztu1Yp7kSH29/gaDyjz9/5fPLrl67lJT83sTEND09RSQSGRkaAQCePXuUlZWhoXINtG/fic1m74/YkZj0Pj4+bu/+baamH0cqbNu2o5OTS3j4psSk9/kFeceOH0hK/jAidBwAIKh1W1dX953hG1++ehYfHxe+Z3O1vNrBwen5iyer1y7++8Hd/IK81LTkmJhoG2vbmhML7YKtW9fAewMAZL4Xszg0c1tmIytlsQx4PPvffos5d+Fkfn7uksVrnJxdf//96qPH98eMnuTm6nnn7p8Xok+lpSXPnRP28tUzJyfXNsHtDQzY9RWlpiY9efpg4oRpVOpHZYNat5PLqy9eOnP+QlTs6+fBQe0WzF/BYDA0VOLg4CSTSX++eObK1WgGnbEkbK1KhV+9dkkoFPTrOzgp+cP1679kZaX37j2gvso1vmWWt7ffg4d3f754Ju5t7PhxU/PyckxNzdq370SlUjt26JKU/P70maOXfzkvlUoWLljRrl0IcY3Tvl2npOT30dGn/vrrlrOT66oVG42MjP39AyQS8aVLZ89fiLr/9x0rK+vlS380MTFt5OcPAEh+KfBsbWjAbfhJr0Y9OXrv5xJjK5Zna6PGJ9CAoErA+v/WWC6XDx7afcb0+UOHjNRcpJX60eHawez+U3mm1g2fN3ztR+dFItH4CYNbt2o7ccJ0CoXy86UzVCq18zfdNRdppX6SOoHQBnxITDh2LCIlNZFKobq5e86Y9n3Nhb6GIq3U/yXEx8etWrOwvtKzZ64Z//vaFS6NbwMgGNBEUSqVUpm0vlIuh6tXE9nr71Gg6UKj0Qy5hrBTaB/y7jDqkAagDmkA6pAGoA5pAOqQBqAOaQDqkAagTqMMYLIwGo10pSlhaEpv5GixjdqvLA61oljWiBVJ9IXcVImpVaM6FDXKAAt7hlKh+uJUJF8JQVm1ix9Hm+MKO3lzqsV4WlzVF2cj+Ro8uFwc1LOx3Uk+Y3T5XyMLbFzYXsHGVEyPboKR1EYiVP4VXdhpiLm9e73dmj/h82aYeHi1NP6hwMqRBfTpTuh/R61WqVRUrDkMmm1kRs9JElk7sVp3N7Vz+4xBoP/LjJP8gmqZpDmcFqSlpV25cmXp0qWwg2gHMxtGYzoGfsJ/6R9gzmtsl1E9p1SEC5XZdu5ID5tOXuWjDtIGUCgUDQ+CIQLSBqjVaolEAjsFZJA2AMMwOzs72Ckgg7QBOI7n5+fDTgEZpA3AMMzaWidDszQhkDYAx/Hi4mLYKSCDtAEkqBtApVI5/x5wBEGQNkClUonFYtgpIIO0ARiG2drawk4BGaQNwHG8sFBXo7Q1FZA2gAR1A6hUqoODA+wUkEHaAJVKlZubCzsFZJA2gAR1A8hrAdQNIK8FUDeABHUDqFSqqelnDNPYLEHaAJVKVVFRATsFZJA2gAR1A8ieoqgbQPYURd0Asg1A3QCyDUDdABLUDSCfF0DdAPJ5AdQNIEHdAAzDbGxsYKeADNIG4DheVFT3rIPogLQBZP8A1A0g+wegbgCFQtGryYGggLQBarX6Pwyk1cxA2gAS0gAStA2gUqlWVjqZzrkJgbQBKpWqpKQEdgrI/JcxRZs6kydPfvfu3SdXAWq1+vXr1/BCQQPFNmDmzJkmJiaUWqjV6qCgINi54ICiAR06dPD09Kzd+JmZmU2cOBFqKGigaABxIDA2/meqcDc3t2+++QZqImggakD79u09PT2Jv42MjMaOHQs7ETQQNQAAMGnSJENDQwCAh4dHly5dYMeBBroGdOjQwcfHh8vljhs3DnYWmDR8NZj6RliQIVPKVQK+8mul+kpIxGJ+eXmzHEaEa0wztaYHdDZhsBr4kjdgwPWjBUYWTAMuZm7LVDeHaUVQoVqG8wuqE59VDpjB0zzpjCYDbvxUaOVg4N3WRDchSb4Gd84WBPU0cfSq98GYepuI139VmFoxyd3f1Ok5nnf/UimurPd7Xq8ByS+Fdh6oj7jaPDDnMdPfieorrdsAtRoAQDGzaSYzSiGOlaNBRYmivtK6DVAq1AK+XJepSL4eFAqQVNV7HYfu7wEkBKQBqEMagDqkAahDGoA6pAGoQxqAOqQBqEMagDqkAahDGoA6pAGoQxqAOs3cgMzM9NFjB8BOodc0cwNSUhJhR9B3aFqs6/pvMefO/1RRUe7r02LRwpWTvgv9Ye3Wbl2/BQDcvXfz0qWz2TmZBgbs7t16T5s6l8ViAQDWb1gBAGjbtuP5C1F8fqmDvdOC+ct9fVsQFda31ZBhPcePm/Ly1bM3b17GXL7N5XLv3P3z4sUzefk5dDrDz6/l3Dlhdjz7qFORp04fAwB06xE8d87i0OFjKysrDh3Z8/ZtrEBQ6erqMX3avFaBwQ2+rzorBwBc+/XyyagjWzfv3X9gZ25ulpGh8fjxU/v1HQwAKC4uOhK5N+5trEQitrHhhQ4fO3DAsI2bVlVUlO8OP0JUO3HycKGw6sovt4mXGzaulEgl27bsqy9kZmb6lGmjNm/cffR4hAHL4PCh01rZa1prAxKT3u/es6Vjxy7HIs/37TNo46ZVxEA9AIBHj+5v2rw6KKjdsaMXli398cHDu+F7NhNbYTRafEJcYmLC0SPnYi7fNjY22b5zPVGkYSsajXb9txhXF/c94ZEsFisx6f3mLWvatQs5cujMtq37ZVLpj+uWAgBGj5o0bNhoKyvrqzF3Bg4YrlKplq/4/v37d8uXrYs8fNbby3fFyvkZGWkNvq86KydiiMWi02ePr/9xx/Vr93v16r9n79bS0hIAwI6d68v4pVs27/3pxMVhQ0fv3bft5atnrVu3TUxKUCqVAIDycn5JSZFarc7NzSZqexf/JjionYaQdDodAHDq9NFRIycsXfKDtnac1gy4des3U1OzubMXOzo69+rV/5tvutcUnY+OCghoPX3aPHs7h/btQqZP+/7OnT9KSoqJUplMOmf2YgMDAxaL1bNH35ycLJlMpnkrCoXCYrJmzpjv59eSRqM52DsdOXxm0sQZjo7OPt5+ocPHpqenVlSUs1gsJoNJoVCMjU2YTOar2OcpqUlLwta0btXGycll3twl1ta2MVeiNb+v+ionSpVK5djRk62srCkUSt8+g5VKZXp6CgAgIzOtTXAHH28/O5794EGhB/b/5ObqEdS6nUwmS0tPAQDEvY11c/P08vJ9F/8GAJCXn8vnlwW1bqcpJIUCAAgMDO7bZ5Crq7u2dpzWjgI5OVl+vi0xDCNeftOp28moI8QoDSkpiZMnzaxZMzAgCACQkZFqZWUNALDjORBtOwDA0NAIACAUVjEYDM1b+fm1rCnicrmFhfnHjx/Iz8+VVcuUCgVRiampWe2EiYkJdDqdqIcYQKRli1Zpacma31eDlbu6evwrvEgIAOjYofOF6CiRSNiuXUjLFq18fPyJdex49u8T3np7+b5797qFfyCbzYlPiOvfb8i7d6/NzS1cXNwePLynOWTNIVJbaM2AqiqBuYVlzUsjo49P5spkMhzHo05Fnj5zrPb6/PIy4g8G89P+qGq1usGtOBxuzcJ7f93auGnVhPFTv5+3lMPhxifEEacXnyCRiBUKRe++HWuW4DhuZmau+X01WDnzk/xqNQBg0cKVri7ut+/8funyOQ6HM2hg6JTvZtNotNat28YnxA0fPibubezM6fOZLNbNm9eJQ0BQULvGhKz9xrWC1gygMxjVMlnNS6GwiviDxWLRaLRhQ0f37zek9vom//6CfsJnbXXjxpVWgcFTvptNvKwdozYcDpfBYByLPF97IZXawHGwkZV/Ao1GGz58zPDhY8rL+bdu3zjx0yETE9ORI8a3bt32wMFdlZUVOTlZfv4BDDqjpLS4rKz03dvX302e9Z9DfglaM8De3vHdu9dqtZo4+3v46C9iOZVK9fDwLi4udHR0JpYoFIqS0mIjQyMNtX3WVnKF3ML8n+bn7r0/iYbkk9W8vf3kcjmO4y4ubsSSoqJCE5MG5htsZOW1EYlET5897Nb1WxqNZmZmPnrUxKfPHhJnc60Cg/n8sj9vXndxcSPei7ub572/bhYWFbRu3fY/h/wStCZX1849i4uLTkYdKSjMv3P3zydPH9QUjR418cHDe+cvROXmZqemJW/Zunb+gqlisVhzhY3fysfb/9WrZ4mJCUVFhXv2bjUzswAAJCd/kMlkXK4hn1/27t2boqLCoNZtPdy9tmxdGxcXW1hUcOfunzNmjr326yXNMTRUXt8mFAplf8T2XeGbUtOSiU8jJSUxMDAIAGBsbOLh7nXl6s8tW7QiVvb3D4y5Eu3q6m5ubgEA+G8hvwSttQEdO3ae8t3smCvRl385HxAQtHjRqhkzxzEZTABA52+6r1q58UJ01MmoIxwO198/YE94JIfTwANJjd9q3LgpBYV5YUtns9mcAf2HTZwwjc8v3bV7ExXDenTvc/PWb2FLZ48dM/m7ybO2b4s4HLn3x/XLZDKpjQ1vwoRpI0IbeHRcQ+X1bcLhcLZvO3D8+IHFYTPlcrmNDe+7ybP69B5IlLZu3fbni2datmxNvGzRIvDyL+dDh38cwgLDsP8Q8kuo+8lRhVx9Ym3GuFVuja9IrVaXl/MJkQEA7969WbBo+k/Hf65pzUhgkfxKIORXdxtZ98iJWjsKvH37OnRkn9Nnjufl5SQkvD10eLe3t5+zs6u26ifREVo7CgQGBq1cvv7nS2fOXzjJ5RoGBgTNnLGgSYzcvXL1woSEuDqL+vcbOmvmgq+e6KuizfsCvXr179WrvxYr/DqsWL6e+J3nf2GxNI290DzQpgFNFGMj40as1Wxp5neHSRqENAB1SANQhzQAdUgDUIc0AHVIA1CHNAB16jFApW5wPFqSpgKFCjCs3p/n697NdBZVUa2Wy3BdBiP5SogqlAaG9d7LrveLbufOqiwlhxRsDogFCku7egcHrdeAVl1NY2/zdZaK5CtRkisVVSqd/ertj6OhDTBo3d3kzrkCnWUj0TkF6ZLXd/hD5vA0rNPA/AJJL6sSXwpxBbB1M5CJyQkGmgwqhao4R8o1pQ2YZkujazqpb3iOEXm1qjS3urJMoahubgbk5+c/fPhw9OjRsINoH7YhzcKOYWbNaHDNhvsHMJhUO3cDO/fm2FciLqv07svALrNg54AJedGPOqQBqIO0AVQqtcHHFpo9SBugVquJh/JRBnUDKisrYaeADNIGAAAMDJrjNc7ngLoBUqkUdgTIoG4ACdIGYBhma2sLOwVkkDYAx/HCwkLYKSCDtAFUKpXL1fKwPE0OpA1QqVQiUb3TsSIC0gaQoG4AhmH29vawU0AGaQNwHM/Ly4OdAjJIG0CCugEYhjk6OsJOARmkDcBxPCcnB3YKyCBtAAnqBpDXAqgbQF4LoG4ACeoGYBhmY2MDOwVkkDYAx/GioiLYKSCDtAEkqBtA9hZH3QCVStXgRBfNHqQNoFAoJiYmsFNABmkDyOcFUDeABHUDyHuDqBtA3htE3QAKhcJms2GngAzSBqjVaolEAjsFZJA2gAR1A6hUqqmpDid0bRIgbYBKpaqoqICdAjJIG0ClUs3MNE2BjgJIG6BWq4VCIewUkEHdAEU9c02iQ8NjijY/hg0blp2dTfweoFKpaqbGjY2NhR0NAii2AdOnT+dyucSOp1KpxB8eHh6wc8EBRQP69u3r5ORUewmLxWqWows3BhQNAACMGTOm9u/Bjo6OQ4YMgZoIGoga0LdvXxcXF+JvOp0+YsQI2ImggagBRDPAYDAAAA4ODsOGDYMdBxroGtCnTx8nJyc6nT527FjYWWDSNK4Gq6V4YZZMWoWLhUq1Csgk2pnrIjMzMz4+ftCgQVqpDQDAZFGYbIxtiBma0W2cWNqqVqfotQEyCZ74vCo1TlxeJDe2ZlEoVCoNoxnQVUp9zaxW4wolLsfpTEpFgcTFn+PeiuPiq9fDlemvAY9/5SfHCjnmbK4Fh2PaNL5PtVHKcWGpBK+urhZWfzPUwtFLT7ui6KMBybGi2+eKbDxMLZybQ1duaVV1WUa5uS2932Rr2FnqQO8MePwrPyddbuNlWfNjbfNAXCHNfVs8drmjkZl+zWigXwY8uVFemKMyd26evTZwpSrzed64FQ4G3IYn+Ppq6JEBN88UC6swC9fmuftrSHuSGzqfZ2LZ8DxwXwd9+T3g9V8VgkpKs9/9AADXdnbnt+fCTvEPetEG5KdJnv5ZZeFmCTvIV0ImrFYKqwZM1YvBK/SiDfjrUhnH0gh2iq8Hy5ApKFelvtGL7knwDUh9I6TQaAZG9U6P3iyxdDV7dE0vpnaHb0DCU5GlmznsFPWyM2JMzPWdWq+WwaYb2XCTX8FvBiAbUF4kLy9WMAz06Oroq8FgMz+8hD+7AWQDMhJEXAtE53sztGTnp8AfwQTyl68oS26os3NAHFfe+ftkXPztispCE2Przh3HdGw7HABQXJK5M2L0rO8OPXwanZnzlkqhBvj3HNR3EYZhAICM7Lgrv+0qKck0M+X17TlbR9kIrN2Msj6InX1hjmUE2YDCDKlLW109s/HbzYjnr64OHbjMxbFlSvqLazd2Y1Rau+DBGEYDAFz7Y8/wgcu+c9yZmv4yMmqei1NgYIueUpko6txSWxuPBbOjcFxx49ZBobBMR/EAAEolqCyF3F0d5lFArVZXS3EaE9NF5VKZ6Mnzy106jW/Tqr+FuUPHtsODW/W/9/B0zQoBft2dHVsCADzc2pib2uXlJwIAElMeS6RVQwcs4dl4ONj5jh72o0RapYt4BDQGJqxU6q7+xgDTAEkVzmTrZPcDAAoKU3CV0tOtbc0SN5fW/PK86uqPj4vb2vzTPZzFMpTKhMQBgk5n2Vi5EstNjK2Mjax0lBAAQGfSRBW47upvDDCPAiqVmqIzA4k9feSnOeCfe4xqAIBQ9PEqnE771y8QaqAmtmLQ/9UXgcnU5X19CoB+BxSmAVxjmkykq28Ai8UBAIwdscHW2q32cmNja4GguL6tGHSWTPavKzSpVIeX7IpqpbmtrlrBRgLTAAqVwjTAlNU6ORWwtfHAMLpIVG7l34NYIhJXAECh0zTdlLOydMJVyqKSDOJAUFicVtNm6AJcjhuaQL5JCPlawNbNQFGt1IUBBixuhzZDb/51jMMxcbDzragsuvbHHhNjq6njd2vYytszhMlgX/1tV79ec3Fc8fvtw1yuDh8vp9OBsSXkXQD5n7d2YGSmiHV0U2BgnwUGLMMbtw5UCcsMuea+Xt/0/baB63sux2Ty2B1Xf9998PgMUxPbfj3nPHgaTZxA6ILCtCqnWZDviEK+O1xWUH39eLFLGzuIGWAhLJMohcKhc3hwY0D+VdiCxzQ2pymkKD7ELxdXewfD70gO/5aMX3vD139X2PrUe9kdfmBchaCOeSBUKhyo1VSs7rewclEMh22srZAnzi7OzH5bZxHHwFgsFdRZtGrRFTa77t+8FTJlZb7QZ5aLthL+Z/Sij9CZLTmW7pYsw7rPiisFxSpVHReNCkW1GgAGve5zCBNjGypVay1cVVWZEpfXWSSXyxiMuh9n0JCh8ENJUFeuZ5ChthL+Z/TCgJwk8eu/xSaO+ttLQLtUi+UKgYDsJfYPjt4cOxdaeXY57CBfidTH+f2n6MvTI3phAACgTS8zFhMvz23+o/1nPM8bvcRBf56H0YujQA1/x5RVlFNM7JrDw2L/i1qtznqZH7qAZ2iiR48N6UsbQNBlmIWpqaosXYe35GEhrap+fztr0Awbvdr9etcGECS+qPrrYqmtt6mpndYu5yBSLVZU5JQbm1H7TtaLU79P0EcDAABKherxNX5WkpRtyuZasJtiX3IVriKeHheWSjsNNndrCf/HnzrRUwMIhJWKxOfCtDixWKg0sjBQASqNgTEM6GqVnmZW42q5TKHCcQaDUpwpcvbjeLTieATCv+jXgF4bUIOoUlmULRVX4oJypUoJJCLIPavqw4CDcYwxrjHN0Jzm4KGnQ0Z8QtMwgER36Ne1AMnXhzQAdUgDUIc0AHVIA1CHNAB1/g8l+wfhera3HwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f14bca6ed90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_queries\", generate_queries)\n",
    "graph_builder.add_node(\"retrieve_docs\", retrieve_docs)\n",
    "graph_builder.add_node(\"aggregate_docs\", aggregate_docs)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_queries\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate_queries\", assign_queries, [\"retrieve_docs\"]\n",
    ")\n",
    "graph_builder.add_edge(\"retrieve_docs\", \"aggregate_docs\")\n",
    "graph_builder.add_edge(\"aggregate_docs\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffaa7dda-19c0-41ed-b377-1c5c8ba3d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185389/4149646339.py:9: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  (loads(doc), score)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_questions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What are the key components of task decomposition for LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'How does task decomposition enhance the efficiency of LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What are common techniques used in task decomposition for LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Can you provide examples of task decomposition in LLM applications?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What challenges are associated with task decomposition in LLM agents?'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieved_docs'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_scores'</span>: <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.09836065573770493</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08038914490527393</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04787506400409626</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04762704813108039</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04712301587301587</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03149801587301587</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015625</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015625</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents refers to the process of breaking down </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">larger, complex tasks into smaller, more manageable subgoals. This approach enables the agent to handle complicated</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks more efficiently by transforming them into a series of simpler steps, which can be addressed individually. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Task decomposition can be facilitated by various methods, such as using standard prompting techniques like \"think </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step by step,\" providing task-specific instructions, or even incorporating human input. The goal is to create a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structured approach that allows the LLM agent to navigate through tasks systematically, enhancing both execution </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency and the overall quality of the results.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_questions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'What are the key components of task decomposition for LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'How does task decomposition enhance the efficiency of LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'What are common techniques used in task decomposition for LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'Can you provide examples of task decomposition in LLM applications?'\u001b[0m,\n",
       "        \u001b[32m'What challenges are associated with task decomposition in LLM agents?'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'retrieved_docs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context_scores'\u001b[0m: \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m0.09836065573770493\u001b[0m,\n",
       "        \u001b[1;36m0.08038914490527393\u001b[0m,\n",
       "        \u001b[1;36m0.04787506400409626\u001b[0m,\n",
       "        \u001b[1;36m0.04762704813108039\u001b[0m,\n",
       "        \u001b[1;36m0.04712301587301587\u001b[0m,\n",
       "        \u001b[1;36m0.03149801587301587\u001b[0m,\n",
       "        \u001b[1;36m0.015625\u001b[0m,\n",
       "        \u001b[1;36m0.015625\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down \u001b[0m\n",
       "\u001b[32mlarger, complex tasks into smaller, more manageable subgoals. This approach enables the agent to handle complicated\u001b[0m\n",
       "\u001b[32mtasks more efficiently by transforming them into a series of simpler steps, which can be addressed individually. \u001b[0m\n",
       "\u001b[32mTask decomposition can be facilitated by various methods, such as using standard prompting techniques like \"think \u001b[0m\n",
       "\u001b[32mstep by step,\" providing task-specific instructions, or even incorporating human input. The goal is to create a \u001b[0m\n",
       "\u001b[32mstructured approach that allows the LLM agent to navigate through tasks systematically, enhancing both execution \u001b[0m\n",
       "\u001b[32mefficiency and the overall quality of the results.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents refers to the process of breaking down larger, complex    \n",
       "tasks into smaller, more manageable subgoals. This approach enables the agent to handle complicated tasks more     \n",
       "efficiently by transforming them into a series of simpler steps, which can be addressed individually. Task         \n",
       "decomposition can be facilitated by various methods, such as using standard prompting techniques like \"think step  \n",
       "by step,\" providing task-specific instructions, or even incorporating human input. The goal is to create a         \n",
       "structured approach that allows the LLM agent to navigate through tasks systematically, enhancing both execution   \n",
       "efficiency and the overall quality of the results.                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents refers to the process of breaking down larger, complex    \n",
       "tasks into smaller, more manageable subgoals. This approach enables the agent to handle complicated tasks more     \n",
       "efficiently by transforming them into a series of simpler steps, which can be addressed individually. Task         \n",
       "decomposition can be facilitated by various methods, such as using standard prompting techniques like \"think step  \n",
       "by step,\" providing task-specific instructions, or even incorporating human input. The goal is to create a         \n",
       "structured approach that allows the LLM agent to navigate through tasks systematically, enhancing both execution   \n",
       "efficiency and the overall quality of the results.                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "response = graph.invoke(\n",
    "    {\n",
    "        \"question\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7747dc13-8622-49be-a22e-9b11195fa005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_questions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What are the key principles of task decomposition for LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'How does task decomposition improve the efficiency of LLM agents?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What are some examples of task decomposition in the context of LLM applications?'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieved_docs'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_scores'</span>: <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04918032786885246</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03225806451612903</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03149801587301587</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03149801587301587</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016129032258064516</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015873015873015872</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015625</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable subgoals. This approach allows the agent to handle difficult tasks more efficiently by transforming them</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into a series of simpler steps. The chain of thought (CoT) technique is commonly used for task decomposition, where</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the model is prompted to think step by step, facilitating clearer reasoning and better decision-making. By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposing tasks, LLMs can utilize more computational resources at test time, improving their performance and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">providing insight into their thought processes.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_questions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'What are the key principles of task decomposition for LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'How does task decomposition improve the efficiency of LLM agents?'\u001b[0m,\n",
       "        \u001b[32m'What are some examples of task decomposition in the context of LLM applications?'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'retrieved_docs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context_scores'\u001b[0m: \u001b[1m(\u001b[0m\n",
       "        \u001b[1;36m0.04918032786885246\u001b[0m,\n",
       "        \u001b[1;36m0.03225806451612903\u001b[0m,\n",
       "        \u001b[1;36m0.03149801587301587\u001b[0m,\n",
       "        \u001b[1;36m0.03149801587301587\u001b[0m,\n",
       "        \u001b[1;36m0.016129032258064516\u001b[0m,\n",
       "        \u001b[1;36m0.015873015873015872\u001b[0m,\n",
       "        \u001b[1;36m0.015625\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller,\u001b[0m\n",
       "\u001b[32mmanageable subgoals. This approach allows the agent to handle difficult tasks more efficiently by transforming them\u001b[0m\n",
       "\u001b[32minto a series of simpler steps. The chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m technique is commonly used for task decomposition, where\u001b[0m\n",
       "\u001b[32mthe model is prompted to think step by step, facilitating clearer reasoning and better decision-making. By \u001b[0m\n",
       "\u001b[32mdecomposing tasks, LLMs can utilize more computational resources at test time, improving their performance and \u001b[0m\n",
       "\u001b[32mproviding insight into their thought processes.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller, manageable    \n",
       "subgoals. This approach allows the agent to handle difficult tasks more efficiently by transforming them into a    \n",
       "series of simpler steps. The chain of thought (CoT) technique is commonly used for task decomposition, where the   \n",
       "model is prompted to think step by step, facilitating clearer reasoning and better decision-making. By decomposing \n",
       "tasks, LLMs can utilize more computational resources at test time, improving their performance and providing       \n",
       "insight into their thought processes.                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller, manageable    \n",
       "subgoals. This approach allows the agent to handle difficult tasks more efficiently by transforming them into a    \n",
       "series of simpler steps. The chain of thought (CoT) technique is commonly used for task decomposition, where the   \n",
       "model is prompted to think step by step, facilitating clearer reasoning and better decision-making. By decomposing \n",
       "tasks, LLMs can utilize more computational resources at test time, improving their performance and providing       \n",
       "insight into their thought processes.                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"generated_questions_count\": 3,\n",
    "        \"include_original_question\": False,\n",
    "    }\n",
    "}\n",
    "response = graph.invoke({\"question\": query}, config=config)\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
