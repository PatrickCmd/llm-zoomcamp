{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9185900c-873b-40c8-a671-bdf5e6c6e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0309a6a1-b78c-477b-9d29-a7f17b05618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2576e0c-f570-4a57-a0f5-df782bf9daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 7-1 (Query Translation - Decomposition (Recursive))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063500a-216e-4dbe-9b45-3e6aae8442b1",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674c047-61f4-419d-a017-1470e251914f",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860bf1a-57f6-427b-9977-7604a3685902",
   "metadata": {},
   "source": [
    "![](images/query-translation-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a6c3d-e97c-496d-b583-88e72baeb4c3",
   "metadata": {},
   "source": [
    "# Part 7-1: Decomposition (Recursive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31247214-b065-4d17-a986-c8240376a110",
   "metadata": {},
   "source": [
    "![](images/07-01-decomposition-recursive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800589d2-7c6e-4aac-a83a-f0ec36049cb6",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f553f7a7-3ff3-4197-80a5-cfdf604a9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f86ab48-b98f-4543-a6c6-4c972b84b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BKNGfeKgTo7Gx5r6pOBqSywyW2ddS', 'finish_reason': 'stop', 'logprobs': None}, id='run-3738a343-c9ce-4035-8f94-6ba314ad2f3d-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dc8587-e9c0-4b5e-944c-72e7d267b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bc159-dede-4260-b2ff-100990d63dbb",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc65ba7f-09c3-4c99-9a49-2a2f6cb7ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd74a494-1b65-489c-a370-7e41049b8be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3111212-eab1-4691-ad6f-c7f6ea632155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b9af7-a2f9-45b8-854c-410b8c4e67bc",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1955089c-5fa3-43a2-a16e-3e0682fae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa35b9e-5bd5-423b-b17d-38bd60aa9060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e5f6a-3722-47c4-be2e-69601f16f637",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1600ad-ae95-4e1d-8cee-d7ce8a977d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f672034b-b010-4b4b-aae9-583a87c45803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4fa9a1-71a5-42d1-8070-8e2a4953af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bda8b-7070-443c-afbc-1eab80ad5300",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "277799eb-70ca-4d70-b93b-ac62ee4c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a77538-ddbe-4202-8e50-6184996df3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
      "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
      "Generate multiple search queries related to: {question}\n"
     ]
    }
   ],
   "source": [
    "decomposition_prompt_template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
    "Generate multiple search queries related to: {question}\"\"\"\n",
    "print(decomposition_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e05179-def7-4723-9215-ba6ef4dd65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the question you need to answer:\n",
      "<question>\n",
      "{question}\n",
      "</question>\n",
      "\n",
      "Here are any available background question + answer pairs:\n",
      "<question_answer_pairs>\n",
      "{qa_pairs}\n",
      "</question_answer_pairs>\n",
      "\n",
      "Here is additional context relevant to the question: \n",
      "<context>\n",
      "{context}\n",
      "</context>\n",
      "\n",
      "Use the above context and any background question + answer pairs to answer the question:\n",
      "<question>\n",
      "{question}\n",
      "</question>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recursive_prompt_template = \"\"\"Here is the question you need to answer:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Here are any available background question + answer pairs:\n",
    "<question_answer_pairs>\n",
    "{qa_pairs}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "print(recursive_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef22081-7982-419b-80ed-16c3ca2b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    return f\"Question: {question}  \\nAnswer:\\n{answer}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf754a56-99a7-4d87-bf7b-99f425305284",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main components of an LLM-powered autonomous agent system?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78609718-3a1a-4f11-b063-52ed7f695a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    all_questions: list[str]\n",
    "    current_question_idx: int\n",
    "    qa_pairs: list[str]\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8545d97-c61b-48bd-9659-09870773bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_questions(state: State, config: RunnableConfig) -> list[str]:\n",
    "    max_generated_sub_questions_count = config['configurable'].get(\"max_generated_sub_questions_count\", 3)\n",
    "    query = state['question']\n",
    "    \n",
    "    class SubQuestionsGenerator(BaseModel):\n",
    "        sub_questions: list[str] = Field(\n",
    "            ..., \n",
    "            description=\"List of generated sub-problems / sub-questions\",\n",
    "            max_items=max_generated_sub_questions_count\n",
    "        )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SubQuestionsGenerator, method=\"function_calling\")\n",
    "    decomposition_prompt = decomposition_prompt_template.format(\n",
    "        question=query\n",
    "    )\n",
    "    response = structured_llm.invoke([\n",
    "        HumanMessage(content=decomposition_prompt)\n",
    "    ])\n",
    "    questions = response.sub_questions + [query]\n",
    "    \n",
    "    return {\"all_questions\": questions, \"current_question_idx\": 0}\n",
    "\n",
    "\n",
    "def retrieve_docs(state: State):\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    retrieved_docs = vectorstore.similarity_search(question)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    recursive_prompt = recursive_prompt_template.format(\n",
    "        question=question,\n",
    "        qa_pairs=state.get(\"qa_pairs\", \"\"),\n",
    "        context=state[\"context\"]\n",
    "    )\n",
    "    answer = llm.invoke([\n",
    "        HumanMessage(content=recursive_prompt)\n",
    "    ])\n",
    "    qa_pair = format_qa_pair(question, answer.content)\n",
    "    qa_pairs = state.get(\"qa_pairs\", \"\") + qa_pair\n",
    "\n",
    "    if state[\"current_question_idx\"] == len(state['all_questions']) - 1:\n",
    "        return {\"answer\": answer.content}\n",
    "    else:\n",
    "        return {\"qa_pairs\": qa_pairs, \"current_question_idx\": state[\"current_question_idx\"] + 1}\n",
    "\n",
    "\n",
    "def check_answer_status(state: State) -> Literal[\"Next sub-question\", \"Final answer\"]:\n",
    "    if state.get(\"answer\"):\n",
    "        return \"Final answer\"\n",
    "    else:\n",
    "        return \"Next sub-question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f60d3431-881f-4c8e-b1e5-f1dbc827ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f919c705210>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_sub_questions\", generate_sub_questions)\n",
    "graph_builder.add_node(\"retrieve_docs\", retrieve_docs)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_sub_questions\")\n",
    "graph_builder.add_edge(\"generate_sub_questions\", \"retrieve_docs\")\n",
    "graph_builder.add_edge(\"retrieve_docs\", \"generate_answer\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate_answer\", \n",
    "    check_answer_status, \n",
    "    {\n",
    "        \"Next sub-question\": \"retrieve_docs\",\n",
    "        \"Final answer\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "822a2d07-f777-45f6-ab99-15ea783f9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_sub_questions'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_questions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the core functionalities of an LLM-powered autonomous agent?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What types of data inputs do LLM-powered autonomous agents utilize?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What roles do machine learning and natural language processing play in LLM-powered autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the main components of an LLM-powered autonomous agent system?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_sub_questions'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'all_questions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'What are the core functionalities of an LLM-powered autonomous agent?'\u001b[0m,\n",
       "            \u001b[32m'What types of data inputs do LLM-powered autonomous agents utilize?'\u001b[0m,\n",
       "            \u001b[32m'What roles do machine learning and natural language processing play in LLM-powered autonomous \u001b[0m\n",
       "\u001b[32magents?'\u001b[0m,\n",
       "            \u001b[32m'What are the main components of an LLM-powered autonomous agent system?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e1348f72-0909-4172-810d-c8426af405b3'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f6b06016-6811-438c-8247-30969b60fafe'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1a067f40-2114-4e46-9a49-a893bccf6d9f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents, I start to see a couple common limitations:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'e1348f72-0909-4172-810d-c8426af405b3'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f6b06016-6811-438c-8247-30969b60fafe'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'1a067f40-2114-4e46-9a49-a893bccf6d9f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered \u001b[0m\n",
       "\u001b[32magents, I start to see a couple common limitations:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The core functionalities of an LLM-powered autonomous agent include:\n",
      "\n",
      "1. **Planning**: The agent can break down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent utilizes techniques like chain of thought (CoT) to think step-by-step and transform large tasks into simpler ones.\n",
      "\n",
      "2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and self-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine its approaches for better outcomes in future tasks.\n",
      "\n",
      "3. **Use of Memory**: While not detailed in the provided context, memory plays a crucial role in allowing the agent to retain and utilize information from previous interactions or tasks, which aids in improving performance and decision-making.\n",
      "\n",
      "4. **Natural Language Interface**: The agent relies on natural language as the primary interface for interacting with external components, including tools and memory systems. This makes the interaction more accessible, though it also introduces challenges regarding reliability and output parsing.\n",
      "\n",
      "These functionalities enable LLM-powered autonomous agents to effectively solve complex problems and manage tasks efficiently."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What are the core functionalities of an LLM-powered autonomous agent?  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">break down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilizes techniques like chain of thought (CoT) to think step-by-step and transform large tasks into simpler </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">self-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context, memory plays a crucial role in allowing the agent to retain and utilize information from previous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interactions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: The agent relies on natural language as the primary interface for interacting with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components, including tools and memory systems. This makes the interaction more accessible, though it also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What are the core functionalities of an LLM-powered autonomous agent?  \u001b[0m\n",
       "\u001b[32m\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can \u001b[0m\n",
       "\u001b[32mbreak down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent \u001b[0m\n",
       "\u001b[32mutilizes techniques like chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to think step-by-step and transform large tasks into simpler \u001b[0m\n",
       "\u001b[32mones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and \u001b[0m\n",
       "\u001b[32mself-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine \u001b[0m\n",
       "\u001b[32mits approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided \u001b[0m\n",
       "\u001b[32mcontext, memory plays a crucial role in allowing the agent to retain and utilize information from previous \u001b[0m\n",
       "\u001b[32minteractions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: The agent relies on natural language as the primary interface for interacting with external \u001b[0m\n",
       "\u001b[32mcomponents, including tools and memory systems. This makes the interaction more accessible, though it also \u001b[0m\n",
       "\u001b[32mintroduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e1348f72-0909-4172-810d-c8426af405b3'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f6b06016-6811-438c-8247-30969b60fafe'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f1753d3a-f19b-4be6-a487-d07baa23f0ce'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'e1348f72-0909-4172-810d-c8426af405b3'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f6b06016-6811-438c-8247-30969b60fafe'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f1753d3a-f19b-4be6-a487-d07baa23f0ce'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-powered autonomous agents utilize several types of data inputs, primarily centered around natural language. The key types of data inputs include:\n",
      "\n",
      "1. **User Queries and Instructions**: Agents take direct input from users in the form of natural language queries or commands. This allows users to specify tasks or provide context for the agent's actions.\n",
      "\n",
      "2. **Memory and Contextual Information**: Agents may leverage memory to retain data from previous interactions or tasks. This information helps improve decision-making and maintain context in ongoing conversations or tasks.\n",
      "\n",
      "3. **External Data and Tools**: Depending on the design, agents can integrate data from external systems or tools to enhance their functionality. This might include accessing APIs, databases, or sensors.\n",
      "\n",
      "4. **Formatted Outputs for Parsing**: The agents may also rely on structured outputs from external components, which are parsed to facilitate clear communication and action based on the model's understanding.\n",
      "\n",
      "Overall, the agents primarily rely on natural language inputs, but they can also incorporate a variety of structured and contextual data to enhance their capabilities."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Question: What are the core functionalities of an LLM-powered autonomous agent?  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">break down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilizes techniques like chain of thought (CoT) to think step-by-step and transform large tasks into simpler </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">self-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context, memory plays a crucial role in allowing the agent to retain and utilize information from previous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interactions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: The agent relies on natural language as the primary interface for interacting with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components, including tools and memory systems. This makes the interaction more accessible, though it also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\nQuestion: What types of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data inputs do LLM-powered autonomous agents utilize?  \\nAnswer:\\nLLM-powered autonomous agents utilize several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">types of data inputs, primarily centered around natural language. The key types of data inputs include:\\n\\n1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**User Queries and Instructions**: Agents take direct input from users in the form of natural language queries or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commands. This allows users to specify tasks or provide context for the agent's actions.\\n\\n2. **Memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Contextual Information**: Agents may leverage memory to retain data from previous interactions or tasks. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information helps improve decision-making and maintain context in ongoing conversations or tasks.\\n\\n3. **External </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Data and Tools**: Depending on the design, agents can integrate data from external systems or tools to enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their functionality. This might include accessing APIs, databases, or sensors.\\n\\n4. **Formatted Outputs for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Parsing**: The agents may also rely on structured outputs from external components, which are parsed to facilitate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clear communication and action based on the model's understanding.\\n\\nOverall, the agents primarily rely on natural</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language inputs, but they can also incorporate a variety of structured and contextual data to enhance their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities.\\n\\n\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m\"Question: What are the core functionalities of an LLM-powered autonomous agent?  \u001b[0m\n",
       "\u001b[32m\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can \u001b[0m\n",
       "\u001b[32mbreak down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent \u001b[0m\n",
       "\u001b[32mutilizes techniques like chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to think step-by-step and transform large tasks into simpler \u001b[0m\n",
       "\u001b[32mones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and \u001b[0m\n",
       "\u001b[32mself-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine \u001b[0m\n",
       "\u001b[32mits approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided \u001b[0m\n",
       "\u001b[32mcontext, memory plays a crucial role in allowing the agent to retain and utilize information from previous \u001b[0m\n",
       "\u001b[32minteractions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: The agent relies on natural language as the primary interface for interacting with external \u001b[0m\n",
       "\u001b[32mcomponents, including tools and memory systems. This makes the interaction more accessible, though it also \u001b[0m\n",
       "\u001b[32mintroduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\nQuestion: What types of \u001b[0m\n",
       "\u001b[32mdata inputs do LLM-powered autonomous agents utilize?  \\nAnswer:\\nLLM-powered autonomous agents utilize several \u001b[0m\n",
       "\u001b[32mtypes of data inputs, primarily centered around natural language. The key types of data inputs include:\\n\\n1. \u001b[0m\n",
       "\u001b[32m**User Queries and Instructions**: Agents take direct input from users in the form of natural language queries or \u001b[0m\n",
       "\u001b[32mcommands. This allows users to specify tasks or provide context for the agent's actions.\\n\\n2. **Memory and \u001b[0m\n",
       "\u001b[32mContextual Information**: Agents may leverage memory to retain data from previous interactions or tasks. This \u001b[0m\n",
       "\u001b[32minformation helps improve decision-making and maintain context in ongoing conversations or tasks.\\n\\n3. **External \u001b[0m\n",
       "\u001b[32mData and Tools**: Depending on the design, agents can integrate data from external systems or tools to enhance \u001b[0m\n",
       "\u001b[32mtheir functionality. This might include accessing APIs, databases, or sensors.\\n\\n4. **Formatted Outputs for \u001b[0m\n",
       "\u001b[32mParsing**: The agents may also rely on structured outputs from external components, which are parsed to facilitate \u001b[0m\n",
       "\u001b[32mclear communication and action based on the model's understanding.\\n\\nOverall, the agents primarily rely on natural\u001b[0m\n",
       "\u001b[32mlanguage inputs, but they can also incorporate a variety of structured and contextual data to enhance their \u001b[0m\n",
       "\u001b[32mcapabilities.\\n\\n\"\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m2\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e1348f72-0909-4172-810d-c8426af405b3'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f6b06016-6811-438c-8247-30969b60fafe'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4970d8b4-3ff7-41b8-a3b0-a2e2a2c61615'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">= \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Efficient Vector Similarity Search” July 28, 2020.\\n[7] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'e1348f72-0909-4172-810d-c8426af405b3'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f6b06016-6811-438c-8247-30969b60fafe'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'4970d8b4-3ff7-41b8-a3b0-a2e2a2c61615'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Or\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  \u001b[0m\n",
       "\u001b[32m= \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \u001b[0m\n",
       "\u001b[32m\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nReferences#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wei et al. “Chain of thought prompting \u001b[0m\n",
       "\u001b[32melicits reasoning in large language models.” NeurIPS 2022\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. “Tree of Thoughts: Dliberate Problem \u001b[0m\n",
       "\u001b[32mSolving with Large Language Models.” arXiv preprint arXiv:2305.10601 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “Chain of Hindsight \u001b[0m\n",
       "\u001b[32mAligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “LLM+P: Empowering \u001b[0m\n",
       "\u001b[32mLarge Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. \u001b[0m\n",
       "\u001b[32m“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Google Blog. “Announcing ScaNN: \u001b[0m\n",
       "\u001b[32mEfficient Vector Similarity Search” July 28, 2020.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhttps://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) and natural language processing (NLP) are fundamental components that underpin the functionality of LLM-powered autonomous agents. Here's how each contributes to their operation:\n",
      "\n",
      "1. **Machine Learning**:\n",
      "   - **General Problem Solving**: LLMs are trained using machine learning techniques on vast datasets, which allows them to learn patterns and generate coherent responses to a wide range of queries. They function as powerful problem solvers, capable of executing complex tasks by applying learned knowledge to new situations.\n",
      "   - **Planning and Task Decomposition**: Machine learning algorithms enhance the agent's ability to decompose large, complex tasks into smaller, more manageable subgoals. Techniques such as Chain of Thought (CoT) prompting help agents systematically tackle challenges by breaking them down methodically.\n",
      "   - **Self-Reflection and Improvement**: Through the internalization of feedback during the learning process, LLMs can engage in self-criticism and reflection, allowing them to learn from past actions and refine their approach for future tasks.\n",
      "\n",
      "2. **Natural Language Processing**:\n",
      "   - **Interaction Interface**: NLP enables LLM-powered agents to understand and generate human language, which serves as the primary interface for users to interact with the system. This capability allows users to input queries and receive responses in a natural language format, enhancing accessibility and user experience.\n",
      "   - **Data Interpretation and Management**: NLP techniques are utilized by the agent to parse and understand structured and unstructured inputs, such as user queries, context from memory, and external tool outputs. This ability helps maintain context across conversations and tasks, making interactions seamless and coherent.\n",
      "   - **Output Reliability**: Given that the interactions are largely based on natural language, ensuring output reliability is crucial. NLP addresses challenges such as potential formatting errors and misinterpretations, allowing the agents to produce more accurate and relevant responses.\n",
      "\n",
      "Overall, the integration of machine learning and natural language processing equips LLM-powered autonomous agents with the ability to plan, reflect, and effectively communicate, enabling them to perform complex tasks efficiently in a manner that is understandable to users."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Question: What are the core functionalities of an LLM-powered autonomous agent?  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">break down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilizes techniques like chain of thought (CoT) to think step-by-step and transform large tasks into simpler </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">self-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context, memory plays a crucial role in allowing the agent to retain and utilize information from previous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interactions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: The agent relies on natural language as the primary interface for interacting with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components, including tools and memory systems. This makes the interaction more accessible, though it also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\nQuestion: What types of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data inputs do LLM-powered autonomous agents utilize?  \\nAnswer:\\nLLM-powered autonomous agents utilize several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">types of data inputs, primarily centered around natural language. The key types of data inputs include:\\n\\n1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**User Queries and Instructions**: Agents take direct input from users in the form of natural language queries or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commands. This allows users to specify tasks or provide context for the agent's actions.\\n\\n2. **Memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Contextual Information**: Agents may leverage memory to retain data from previous interactions or tasks. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information helps improve decision-making and maintain context in ongoing conversations or tasks.\\n\\n3. **External </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Data and Tools**: Depending on the design, agents can integrate data from external systems or tools to enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their functionality. This might include accessing APIs, databases, or sensors.\\n\\n4. **Formatted Outputs for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Parsing**: The agents may also rely on structured outputs from external components, which are parsed to facilitate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clear communication and action based on the model's understanding.\\n\\nOverall, the agents primarily rely on natural</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language inputs, but they can also incorporate a variety of structured and contextual data to enhance their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities.\\n\\nQuestion: What roles do machine learning and natural language processing play in LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents?  \\nAnswer:\\nMachine learning (ML) and natural language processing (NLP) are fundamental </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components that underpin the functionality of LLM-powered autonomous agents. Here's how each contributes to their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operation:\\n\\n1. **Machine Learning**:\\n   - **General Problem Solving**: LLMs are trained using machine learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques on vast datasets, which allows them to learn patterns and generate coherent responses to a wide range of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">queries. They function as powerful problem solvers, capable of executing complex tasks by applying learned </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge to new situations.\\n   - **Planning and Task Decomposition**: Machine learning algorithms enhance the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent's ability to decompose large, complex tasks into smaller, more manageable subgoals. Techniques such as Chain </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Thought (CoT) prompting help agents systematically tackle challenges by breaking them down methodically.\\n   - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Self-Reflection and Improvement**: Through the internalization of feedback during the learning process, LLMs can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engage in self-criticism and reflection, allowing them to learn from past actions and refine their approach for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">future tasks.\\n\\n2. **Natural Language Processing**:\\n   - **Interaction Interface**: NLP enables LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to understand and generate human language, which serves as the primary interface for users to interact with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the system. This capability allows users to input queries and receive responses in a natural language format, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing accessibility and user experience.\\n   - **Data Interpretation and Management**: NLP techniques are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilized by the agent to parse and understand structured and unstructured inputs, such as user queries, context </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from memory, and external tool outputs. This ability helps maintain context across conversations and tasks, making </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interactions seamless and coherent.\\n   - **Output Reliability**: Given that the interactions are largely based on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language, ensuring output reliability is crucial. NLP addresses challenges such as potential formatting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">errors and misinterpretations, allowing the agents to produce more accurate and relevant responses.\\n\\nOverall, the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">integration of machine learning and natural language processing equips LLM-powered autonomous agents with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ability to plan, reflect, and effectively communicate, enabling them to perform complex tasks efficiently in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manner that is understandable to users.\\n\\n\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m\"Question: What are the core functionalities of an LLM-powered autonomous agent?  \u001b[0m\n",
       "\u001b[32m\\nAnswer:\\nThe core functionalities of an LLM-powered autonomous agent include:\\n\\n1. **Planning**: The agent can \u001b[0m\n",
       "\u001b[32mbreak down complex tasks into smaller, manageable subgoals. This involves task decomposition, where the agent \u001b[0m\n",
       "\u001b[32mutilizes techniques like chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to think step-by-step and transform large tasks into simpler \u001b[0m\n",
       "\u001b[32mones.\\n\\n2. **Reflection and Refinement**: The agent has the ability to engage in self-criticism and \u001b[0m\n",
       "\u001b[32mself-reflection regarding its past actions. This functionality allows the agent to learn from mistakes and refine \u001b[0m\n",
       "\u001b[32mits approaches for better outcomes in future tasks.\\n\\n3. **Use of Memory**: While not detailed in the provided \u001b[0m\n",
       "\u001b[32mcontext, memory plays a crucial role in allowing the agent to retain and utilize information from previous \u001b[0m\n",
       "\u001b[32minteractions or tasks, which aids in improving performance and decision-making.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: The agent relies on natural language as the primary interface for interacting with external \u001b[0m\n",
       "\u001b[32mcomponents, including tools and memory systems. This makes the interaction more accessible, though it also \u001b[0m\n",
       "\u001b[32mintroduces challenges regarding reliability and output parsing.\\n\\nThese functionalities enable LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agents to effectively solve complex problems and manage tasks efficiently.\\n\\nQuestion: What types of \u001b[0m\n",
       "\u001b[32mdata inputs do LLM-powered autonomous agents utilize?  \\nAnswer:\\nLLM-powered autonomous agents utilize several \u001b[0m\n",
       "\u001b[32mtypes of data inputs, primarily centered around natural language. The key types of data inputs include:\\n\\n1. \u001b[0m\n",
       "\u001b[32m**User Queries and Instructions**: Agents take direct input from users in the form of natural language queries or \u001b[0m\n",
       "\u001b[32mcommands. This allows users to specify tasks or provide context for the agent's actions.\\n\\n2. **Memory and \u001b[0m\n",
       "\u001b[32mContextual Information**: Agents may leverage memory to retain data from previous interactions or tasks. This \u001b[0m\n",
       "\u001b[32minformation helps improve decision-making and maintain context in ongoing conversations or tasks.\\n\\n3. **External \u001b[0m\n",
       "\u001b[32mData and Tools**: Depending on the design, agents can integrate data from external systems or tools to enhance \u001b[0m\n",
       "\u001b[32mtheir functionality. This might include accessing APIs, databases, or sensors.\\n\\n4. **Formatted Outputs for \u001b[0m\n",
       "\u001b[32mParsing**: The agents may also rely on structured outputs from external components, which are parsed to facilitate \u001b[0m\n",
       "\u001b[32mclear communication and action based on the model's understanding.\\n\\nOverall, the agents primarily rely on natural\u001b[0m\n",
       "\u001b[32mlanguage inputs, but they can also incorporate a variety of structured and contextual data to enhance their \u001b[0m\n",
       "\u001b[32mcapabilities.\\n\\nQuestion: What roles do machine learning and natural language processing play in LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agents?  \\nAnswer:\\nMachine learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mML\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are fundamental \u001b[0m\n",
       "\u001b[32mcomponents that underpin the functionality of LLM-powered autonomous agents. Here's how each contributes to their \u001b[0m\n",
       "\u001b[32moperation:\\n\\n1. **Machine Learning**:\\n   - **General Problem Solving**: LLMs are trained using machine learning \u001b[0m\n",
       "\u001b[32mtechniques on vast datasets, which allows them to learn patterns and generate coherent responses to a wide range of\u001b[0m\n",
       "\u001b[32mqueries. They function as powerful problem solvers, capable of executing complex tasks by applying learned \u001b[0m\n",
       "\u001b[32mknowledge to new situations.\\n   - **Planning and Task Decomposition**: Machine learning algorithms enhance the \u001b[0m\n",
       "\u001b[32magent's ability to decompose large, complex tasks into smaller, more manageable subgoals. Techniques such as Chain \u001b[0m\n",
       "\u001b[32mof Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting help agents systematically tackle challenges by breaking them down methodically.\\n   - \u001b[0m\n",
       "\u001b[32m**Self-Reflection and Improvement**: Through the internalization of feedback during the learning process, LLMs can \u001b[0m\n",
       "\u001b[32mengage in self-criticism and reflection, allowing them to learn from past actions and refine their approach for \u001b[0m\n",
       "\u001b[32mfuture tasks.\\n\\n2. **Natural Language Processing**:\\n   - **Interaction Interface**: NLP enables LLM-powered \u001b[0m\n",
       "\u001b[32magents to understand and generate human language, which serves as the primary interface for users to interact with \u001b[0m\n",
       "\u001b[32mthe system. This capability allows users to input queries and receive responses in a natural language format, \u001b[0m\n",
       "\u001b[32menhancing accessibility and user experience.\\n   - **Data Interpretation and Management**: NLP techniques are \u001b[0m\n",
       "\u001b[32mutilized by the agent to parse and understand structured and unstructured inputs, such as user queries, context \u001b[0m\n",
       "\u001b[32mfrom memory, and external tool outputs. This ability helps maintain context across conversations and tasks, making \u001b[0m\n",
       "\u001b[32minteractions seamless and coherent.\\n   - **Output Reliability**: Given that the interactions are largely based on \u001b[0m\n",
       "\u001b[32mnatural language, ensuring output reliability is crucial. NLP addresses challenges such as potential formatting \u001b[0m\n",
       "\u001b[32merrors and misinterpretations, allowing the agents to produce more accurate and relevant responses.\\n\\nOverall, the\u001b[0m\n",
       "\u001b[32mintegration of machine learning and natural language processing equips LLM-powered autonomous agents with the \u001b[0m\n",
       "\u001b[32mability to plan, reflect, and effectively communicate, enabling them to perform complex tasks efficiently in a \u001b[0m\n",
       "\u001b[32mmanner that is understandable to users.\\n\\n\"\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m3\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e1348f72-0909-4172-810d-c8426af405b3'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f6b06016-6811-438c-8247-30969b60fafe'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f1753d3a-f19b-4be6-a487-d07baa23f0ce'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'e1348f72-0909-4172-810d-c8426af405b3'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8dc59e3e-032a-4b3d-bd9c-72f5b3da7115'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f6b06016-6811-438c-8247-30969b60fafe'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'f1753d3a-f19b-4be6-a487-d07baa23f0ce'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of an LLM-powered autonomous agent system include:\n",
      "\n",
      "1. **Planning**: This component enables the agent to break down complex tasks into smaller, manageable subgoals. It involves task decomposition techniques, such as Chain of Thought (CoT), which guide the agent to think step-by-step and systematically tackle challenges.\n",
      "\n",
      "2. **Reflection and Refinement**: The agent possesses the capability to conduct self-criticism and self-reflection regarding its past actions. This allows the agent to learn from mistakes, refine its strategies, and improve the quality of its future outcomes.\n",
      "\n",
      "3. **Memory**: Memory plays a crucial role by allowing the agent to retain and utilize information from prior interactions or tasks. This enhances decision-making and helps maintain context in ongoing dialogues or activities.\n",
      "\n",
      "4. **Natural Language Interface**: The agent primarily uses natural language as the interface for interaction with users and external systems. This functionality facilitates accessibility, as users can communicate with the agent in a human-like manner. However, it may also lead to challenges regarding reliability and the parsing of outputs.\n",
      "\n",
      "These components work in conjunction to empower LLM-powered autonomous agents to effectively solve complex problems and manage tasks efficiently."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Planning**: This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">component enables the agent to break down complex tasks into smaller, manageable subgoals. It involves task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition techniques, such as Chain of Thought (CoT), which guide the agent to think step-by-step and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematically tackle challenges.\\n\\n2. **Reflection and Refinement**: The agent possesses the capability to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conduct self-criticism and self-reflection regarding its past actions. This allows the agent to learn from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mistakes, refine its strategies, and improve the quality of its future outcomes.\\n\\n3. **Memory**: Memory plays a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crucial role by allowing the agent to retain and utilize information from prior interactions or tasks. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances decision-making and helps maintain context in ongoing dialogues or activities.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: The agent primarily uses natural language as the interface for interaction with users and external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systems. This functionality facilitates accessibility, as users can communicate with the agent in a human-like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manner. However, it may also lead to challenges regarding reliability and the parsing of outputs.\\n\\nThese </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components work in conjunction to empower LLM-powered autonomous agents to effectively solve complex problems and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manage tasks efficiently.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'answer'\u001b[0m: \u001b[32m'The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Planning**: This \u001b[0m\n",
       "\u001b[32mcomponent enables the agent to break down complex tasks into smaller, manageable subgoals. It involves task \u001b[0m\n",
       "\u001b[32mdecomposition techniques, such as Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which guide the agent to think step-by-step and \u001b[0m\n",
       "\u001b[32msystematically tackle challenges.\\n\\n2. **Reflection and Refinement**: The agent possesses the capability to \u001b[0m\n",
       "\u001b[32mconduct self-criticism and self-reflection regarding its past actions. This allows the agent to learn from \u001b[0m\n",
       "\u001b[32mmistakes, refine its strategies, and improve the quality of its future outcomes.\\n\\n3. **Memory**: Memory plays a \u001b[0m\n",
       "\u001b[32mcrucial role by allowing the agent to retain and utilize information from prior interactions or tasks. This \u001b[0m\n",
       "\u001b[32menhances decision-making and helps maintain context in ongoing dialogues or activities.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: The agent primarily uses natural language as the interface for interaction with users and external \u001b[0m\n",
       "\u001b[32msystems. This functionality facilitates accessibility, as users can communicate with the agent in a human-like \u001b[0m\n",
       "\u001b[32mmanner. However, it may also lead to challenges regarding reliability and the parsing of outputs.\\n\\nThese \u001b[0m\n",
       "\u001b[32mcomponents work in conjunction to empower LLM-powered autonomous agents to effectively solve complex problems and \u001b[0m\n",
       "\u001b[32mmanage tasks efficiently.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The main components of an LLM-powered autonomous agent system include:                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Planning</span>: This component enables the agent to break down complex tasks into smaller, manageable subgoals. It    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>involves task decomposition techniques, such as Chain of Thought (CoT), which guide the agent to think          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>step-by-step and systematically tackle challenges.                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: The agent possesses the capability to conduct self-criticism and self-reflection     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>regarding its past actions. This allows the agent to learn from mistakes, refine its strategies, and improve the\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>quality of its future outcomes.                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Memory</span>: Memory plays a crucial role by allowing the agent to retain and utilize information from prior          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>interactions or tasks. This enhances decision-making and helps maintain context in ongoing dialogues or         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>activities.                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Natural Language Interface</span>: The agent primarily uses natural language as the interface for interaction with     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>users and external systems. This functionality facilitates accessibility, as users can communicate with the     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>agent in a human-like manner. However, it may also lead to challenges regarding reliability and the parsing of  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>outputs.                                                                                                        \n",
       "\n",
       "These components work in conjunction to empower LLM-powered autonomous agents to effectively solve complex problems\n",
       "and manage tasks efficiently.                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The main components of an LLM-powered autonomous agent system include:                                             \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPlanning\u001b[0m: This component enables the agent to break down complex tasks into smaller, manageable subgoals. It    \n",
       "\u001b[1;33m   \u001b[0minvolves task decomposition techniques, such as Chain of Thought (CoT), which guide the agent to think          \n",
       "\u001b[1;33m   \u001b[0mstep-by-step and systematically tackle challenges.                                                              \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: The agent possesses the capability to conduct self-criticism and self-reflection     \n",
       "\u001b[1;33m   \u001b[0mregarding its past actions. This allows the agent to learn from mistakes, refine its strategies, and improve the\n",
       "\u001b[1;33m   \u001b[0mquality of its future outcomes.                                                                                 \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mMemory\u001b[0m: Memory plays a crucial role by allowing the agent to retain and utilize information from prior          \n",
       "\u001b[1;33m   \u001b[0minteractions or tasks. This enhances decision-making and helps maintain context in ongoing dialogues or         \n",
       "\u001b[1;33m   \u001b[0mactivities.                                                                                                     \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mNatural Language Interface\u001b[0m: The agent primarily uses natural language as the interface for interaction with     \n",
       "\u001b[1;33m   \u001b[0musers and external systems. This functionality facilitates accessibility, as users can communicate with the     \n",
       "\u001b[1;33m   \u001b[0magent in a human-like manner. However, it may also lead to challenges regarding reliability and the parsing of  \n",
       "\u001b[1;33m   \u001b[0moutputs.                                                                                                        \n",
       "\n",
       "These components work in conjunction to empower LLM-powered autonomous agents to effectively solve complex problems\n",
       "and manage tasks efficiently.                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"max_generated_sub_questions_count\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "for stream_mode, event in graph.stream(\n",
    "    {\"question\": query}, \n",
    "    stream_mode=[\"messages\", \"updates\"],\n",
    "    config=config\n",
    "):\n",
    "    match stream_mode:\n",
    "        case \"messages\":\n",
    "            message, metadata = event\n",
    "            print(message.content, end=\"\", flush=True)\n",
    "        case \"updates\":\n",
    "            rprint(event)\n",
    "\n",
    "display(Markdown(event['generate_answer']['answer']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
