{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345c364e-1395-499c-bd91-e4eb117fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82ea84-71c2-464f-b6f4-1fc402f4c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25bf618-9b16-4b27-bc98-4993289dd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 9 (Query Translation - HyDE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410814f2-2b92-4c20-9357-7972793284f4",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903de153-9de3-4f45-884f-3b99378cc11c",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22872f-9628-4fac-8089-3fa2edd30e51",
   "metadata": {},
   "source": [
    "# Part 9: Query Translation - HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09ffb6-8754-47f1-8b97-a821fd8e94f1",
   "metadata": {},
   "source": [
    "![](images/09-hyde.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac6d36-a13c-42ed-a8f4-6795e46475c7",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab45993b-bbd9-4bfc-a625-05bf2fe49f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7947660-1a81-4fba-8985-91cc918ca541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BKNeTP2oDtNaIUx3bmnWgmT3W7cEJ', 'finish_reason': 'stop', 'logprobs': None}, id='run-aa7ff30f-35ce-4a3a-98eb-863a918476d3-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca4c60-f492-4f5e-860b-aec63d65b28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05aeb5-c158-47f3-a2fc-4e9d4eb1511d",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e23cf80-2c23-4872-9304-323ea7697e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e97bc41-ce13-4b21-9631-d9196ddc2a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c0b94a-e7ca-4214-8343-e9f69a64a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82272c1e-903c-4afd-853c-84312c25956c",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5505d36-c430-43b4-a12d-3bda4671b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0ff5a8-9469-4c1e-bf76-f2a36a186131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb81332-a8bf-4589-b885-6c1f8bf36733",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba68874-7c1e-435e-b2fb-4f6b831b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8b5d56-91a2-4c01-a318-a7ced2c62e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7ffa-9221-444c-ba6c-5a5f1ca3320e",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a020ed11-a677-47e8-aa19-9f3cd9775647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ed185d-4a4c-4e1e-b2c2-0e95f4225237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a passage to answer the question\n",
      "Question: {question}\n",
      "Passage:\n"
     ]
    }
   ],
   "source": [
    "hyde_prompt_template = \"\"\"Please write a passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "print(hyde_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c680829-4ce4-48b9-8e2f-d069c2715e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on this context:\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3467a2-666a-4b26-a944-f5d4d4681fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e5b53d-1143-4739-bd43-7abc74fcdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition for LLM agents?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd4dd07-610a-459b-bb43-c4e9344d572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    generated_documents: list[str]\n",
    "    hyde_embeddings: np.ndarray\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abce7134-6b43-4e35-afd0-3203d8a7bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documents(state: State, config: RunnableConfig) -> list[Document]:\n",
    "    generated_documents_count = config['configurable'].get(\"generated_documents_count\", 3)\n",
    "    \n",
    "    hyde_prompt = hyde_prompt_template.format(\n",
    "        question=state[\"question\"]\n",
    "    )\n",
    "    generated_documents = llm.batch([hyde_prompt] * generated_documents_count)\n",
    "    \n",
    "    return {\"generated_documents\": [document.content for document in generated_documents]}\n",
    "\n",
    "\n",
    "def calculate_hyde_embeddings(state: State):\n",
    "    question_embeddings = np.array(embeddings.embed_query(state['question']))\n",
    "    generated_documents_embeddings = np.array(embeddings.embed_documents(state['generated_documents']))\n",
    "    hyde_embeddings = np.vstack([question_embeddings, generated_documents_embeddings]).mean(axis=0)\n",
    "    return {\"hyde_embeddings\": list(hyde_embeddings)}\n",
    "\n",
    "\n",
    "def get_relevant_documents(state: State):\n",
    "    documents = vectorstore.similarity_search_by_vector(state[\"hyde_embeddings\"])\n",
    "    return {\"context\": documents}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        context=docs_content,\n",
    "        question=state[\"question\"]\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1115f445-fbe8-43ab-91a7-c17ff26aec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7fbd44471010>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_documents\", generate_documents)\n",
    "graph_builder.add_node(\"calculate_hyde_embeddings\", calculate_hyde_embeddings)\n",
    "graph_builder.add_node(\"get_relevant_documents\", get_relevant_documents)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_documents\")\n",
    "graph_builder.add_edge(\"generate_documents\", \"calculate_hyde_embeddings\")\n",
    "graph_builder.add_edge(\"calculate_hyde_embeddings\", \"get_relevant_documents\")\n",
    "graph_builder.add_edge(\"get_relevant_documents\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9aa8516-8eae-4d29-a6aa-640bc661c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks that a language model can handle effectively. This approach allows </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs to tackle intricate problems by addressing each component step-by-step, thus enhancing their ability to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate coherent and contextually relevant responses. \\n\\nIn practice, task decomposition involves analyzing a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">given query or task to identify its core elements and dependencies. For instance, a user might ask an LLM to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate a business plan. Instead of processing the entire request at once, the model can decompose the task into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">several sub-tasks, such as market analysis, financial projections, and marketing strategies. By sequentially </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">addressing each sub-task, the LLM can produce more detailed and structured outputs.\\n\\nMoreover, task decomposition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assists in improving the overall accuracy and relevance of the responses by allowing the model to focus on one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspect at a time. It also enables the integration of various reasoning capabilities, as the LLM can apply different</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">logic patterns and knowledge areas while working through each component of the overall task. This method ultimately</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances the effectiveness and usability of LLM agents in various applications, including writing, problem-solving,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and decision-making.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, manageable components that can be more easily understood and executed by the agent. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach is particularly useful when dealing with intricate problems that require multiple steps or diverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge areas. By deconstructing a task into its fundamental parts, LLM agents can systematically address each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">component, leveraging their language understanding to generate more accurate and coherent responses.\\n\\nFor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">example, if tasked with writing a research paper, an LLM agent might first decompose the assignment into several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key stages: topic selection, research, outlining, drafting, and revision. The agent can then focus on each stage </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequentially or in parallel, ensuring that it adequately addresses each aspect of the task. This method enhances </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the efficiency and effectiveness of the agent's performance, as it allows for targeted responses and minimizes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">risk of oversight or errors.\\n\\nAdditionally, task decomposition can facilitate collaboration among multiple LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents, with each agent specializing in different parts of the overall task. This division of labor can lead to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improved outcomes, as it allows for the pooling of knowledge and capabilities. Overall, task decomposition is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">critical strategy for optimizing the problem-solving abilities of LLM agents, enabling them to take on complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenges with greater precision and clarity.\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks or components. This approach leverages the capabilities of LLMs to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handle specific, well-defined instructions, which enhances their overall efficiency and effectiveness in generating</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">responses or performing designated actions. By segmenting a larger task into simpler parts, LLM agents can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematically address each element, ensuring that all aspects are thoroughly executed and reducing the risk of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">errors.\\n\\nFor instance, if a user requires an LLM to draft a comprehensive report, the agent might first decompose</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this task into several key stages: conducting research, outlining the report structure, writing individual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sections, and finally, editing and revising the content. This step-by-step breakdown allows the agent to focus on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">one aspect at a time, making it easier to ensure the quality and coherence of the final output. \\n\\nFurthermore, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition enables LLMs to draw upon specialized knowledge or strategies relevant to each sub-task, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimizing performance and providing users with more accurate and contextually appropriate outputs. In summary, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition enhances the workflow of LLM agents, allowing for a more structured approach to problem-solving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and content creation.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0042193391473119846</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.020462385844439268</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05575017910450697</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005448649055324495</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0020930225146003067</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.004267382086254656</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025309243937954307</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.026205006521195173</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.00022766762413084507</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05446064379066229</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.020280844066292048</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0345099912956357</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.021263941656798124</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.03455075062811375</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.00790901509753894</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.03191866306588054</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.022809301037341356</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.019486550707370043</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.009033773501869291</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.050675930455327034</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span> +<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1516</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents refers to the process of breaking down </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks into smaller, manageable subgoals. This method allows the agent to systematically address each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subgoal step by step, enhancing its ability to perform complicated tasks more efficiently. The technique, known as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Chain of Thought (CoT), instructs the model to \"think step by step,\" leading to improved performance and a clearer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interpretation of the model\\'s reasoning process. By transforming larger tasks into simpler components, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition facilitates the agent\\'s planning and execution capabilities.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks that a language model can handle effectively. This approach allows \u001b[0m\n",
       "\u001b[32mLLMs to tackle intricate problems by addressing each component step-by-step, thus enhancing their ability to \u001b[0m\n",
       "\u001b[32mgenerate coherent and contextually relevant responses. \\n\\nIn practice, task decomposition involves analyzing a \u001b[0m\n",
       "\u001b[32mgiven query or task to identify its core elements and dependencies. For instance, a user might ask an LLM to \u001b[0m\n",
       "\u001b[32mgenerate a business plan. Instead of processing the entire request at once, the model can decompose the task into \u001b[0m\n",
       "\u001b[32mseveral sub-tasks, such as market analysis, financial projections, and marketing strategies. By sequentially \u001b[0m\n",
       "\u001b[32maddressing each sub-task, the LLM can produce more detailed and structured outputs.\\n\\nMoreover, task decomposition\u001b[0m\n",
       "\u001b[32massists in improving the overall accuracy and relevance of the responses by allowing the model to focus on one \u001b[0m\n",
       "\u001b[32maspect at a time. It also enables the integration of various reasoning capabilities, as the LLM can apply different\u001b[0m\n",
       "\u001b[32mlogic patterns and knowledge areas while working through each component of the overall task. This method ultimately\u001b[0m\n",
       "\u001b[32menhances the effectiveness and usability of LLM agents in various applications, including writing, problem-solving,\u001b[0m\n",
       "\u001b[32mand decision-making.'\u001b[0m,\n",
       "        \u001b[32m\"Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, manageable components that can be more easily understood and executed by the agent. This \u001b[0m\n",
       "\u001b[32mapproach is particularly useful when dealing with intricate problems that require multiple steps or diverse \u001b[0m\n",
       "\u001b[32mknowledge areas. By deconstructing a task into its fundamental parts, LLM agents can systematically address each \u001b[0m\n",
       "\u001b[32mcomponent, leveraging their language understanding to generate more accurate and coherent responses.\\n\\nFor \u001b[0m\n",
       "\u001b[32mexample, if tasked with writing a research paper, an LLM agent might first decompose the assignment into several \u001b[0m\n",
       "\u001b[32mkey stages: topic selection, research, outlining, drafting, and revision. The agent can then focus on each stage \u001b[0m\n",
       "\u001b[32msequentially or in parallel, ensuring that it adequately addresses each aspect of the task. This method enhances \u001b[0m\n",
       "\u001b[32mthe efficiency and effectiveness of the agent's performance, as it allows for targeted responses and minimizes the \u001b[0m\n",
       "\u001b[32mrisk of oversight or errors.\\n\\nAdditionally, task decomposition can facilitate collaboration among multiple LLM \u001b[0m\n",
       "\u001b[32magents, with each agent specializing in different parts of the overall task. This division of labor can lead to \u001b[0m\n",
       "\u001b[32mimproved outcomes, as it allows for the pooling of knowledge and capabilities. Overall, task decomposition is a \u001b[0m\n",
       "\u001b[32mcritical strategy for optimizing the problem-solving abilities of LLM agents, enabling them to take on complex \u001b[0m\n",
       "\u001b[32mchallenges with greater precision and clarity.\"\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks or components. This approach leverages the capabilities of LLMs to \u001b[0m\n",
       "\u001b[32mhandle specific, well-defined instructions, which enhances their overall efficiency and effectiveness in generating\u001b[0m\n",
       "\u001b[32mresponses or performing designated actions. By segmenting a larger task into simpler parts, LLM agents can \u001b[0m\n",
       "\u001b[32msystematically address each element, ensuring that all aspects are thoroughly executed and reducing the risk of \u001b[0m\n",
       "\u001b[32merrors.\\n\\nFor instance, if a user requires an LLM to draft a comprehensive report, the agent might first decompose\u001b[0m\n",
       "\u001b[32mthis task into several key stages: conducting research, outlining the report structure, writing individual \u001b[0m\n",
       "\u001b[32msections, and finally, editing and revising the content. This step-by-step breakdown allows the agent to focus on \u001b[0m\n",
       "\u001b[32mone aspect at a time, making it easier to ensure the quality and coherence of the final output. \\n\\nFurthermore, \u001b[0m\n",
       "\u001b[32mtask decomposition enables LLMs to draw upon specialized knowledge or strategies relevant to each sub-task, \u001b[0m\n",
       "\u001b[32moptimizing performance and providing users with more accurate and contextually appropriate outputs. In summary, \u001b[0m\n",
       "\u001b[32mtask decomposition enhances the workflow of LLM agents, allowing for a more structured approach to problem-solving \u001b[0m\n",
       "\u001b[32mand content creation.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;36m0.0042193391473119846\u001b[0m,\n",
       "        \u001b[1;36m0.020462385844439268\u001b[0m,\n",
       "        \u001b[1;36m0.05575017910450697\u001b[0m,\n",
       "        \u001b[1;36m0.005448649055324495\u001b[0m,\n",
       "        \u001b[1;36m-0.0020930225146003067\u001b[0m,\n",
       "        \u001b[1;36m0.004267382086254656\u001b[0m,\n",
       "        \u001b[1;36m0.025309243937954307\u001b[0m,\n",
       "        \u001b[1;36m0.026205006521195173\u001b[0m,\n",
       "        \u001b[1;36m-0.00022766762413084507\u001b[0m,\n",
       "        \u001b[1;36m0.05446064379066229\u001b[0m,\n",
       "        \u001b[1;36m0.020280844066292048\u001b[0m,\n",
       "        \u001b[1;36m-0.0345099912956357\u001b[0m,\n",
       "        \u001b[1;36m-0.021263941656798124\u001b[0m,\n",
       "        \u001b[1;36m-0.03455075062811375\u001b[0m,\n",
       "        \u001b[1;36m-0.00790901509753894\u001b[0m,\n",
       "        \u001b[1;36m-0.03191866306588054\u001b[0m,\n",
       "        \u001b[1;36m0.022809301037341356\u001b[0m,\n",
       "        \u001b[1;36m-0.019486550707370043\u001b[0m,\n",
       "        \u001b[1;36m-0.009033773501869291\u001b[0m,\n",
       "        \u001b[1;36m0.050675930455327034\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m +\u001b[1;36m1516\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down \u001b[0m\n",
       "\u001b[32mcomplex tasks into smaller, manageable subgoals. This method allows the agent to systematically address each \u001b[0m\n",
       "\u001b[32msubgoal step by step, enhancing its ability to perform complicated tasks more efficiently. The technique, known as \u001b[0m\n",
       "\u001b[32mChain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, instructs the model to \"think step by step,\" leading to improved performance and a clearer \u001b[0m\n",
       "\u001b[32minterpretation of the model\\'s reasoning process. By transforming larger tasks into simpler components, task \u001b[0m\n",
       "\u001b[32mdecomposition facilitates the agent\\'s planning and execution capabilities.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into \n",
       "smaller, manageable subgoals. This method allows the agent to systematically address each subgoal step by step,    \n",
       "enhancing its ability to perform complicated tasks more efficiently. The technique, known as Chain of Thought      \n",
       "(CoT), instructs the model to \"think step by step,\" leading to improved performance and a clearer interpretation of\n",
       "the model's reasoning process. By transforming larger tasks into simpler components, task decomposition facilitates\n",
       "the agent's planning and execution capabilities.                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into \n",
       "smaller, manageable subgoals. This method allows the agent to systematically address each subgoal step by step,    \n",
       "enhancing its ability to perform complicated tasks more efficiently. The technique, known as Chain of Thought      \n",
       "(CoT), instructs the model to \"think step by step,\" leading to improved performance and a clearer interpretation of\n",
       "the model's reasoning process. By transforming larger tasks into simpler components, task decomposition facilitates\n",
       "the agent's planning and execution capabilities.                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "\n",
    "display(Pretty(response, max_depth=2, max_length=20))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfd34b0-bb3d-43a1-9764-5708bd93ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for large language model (LLM) agents is the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable subtasks that can be processed more efficiently. This approach enables LLMs to tackle</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intricate problems by simplifying them into a series of steps that can be addressed sequentially or in parallel. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Each subtask focuses on a specific aspect of the overall task, making it easier for the LLM to generate accurate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and relevant responses.\\n\\nIn practice, task decomposition involves identifying the different components of a given</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task, such as information gathering, analysis, and synthesis. By segmenting these components, LLM agents can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operate with greater precision, allowing them to leverage their strengths in natural language understanding and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generation. Furthermore, task decomposition can facilitate better resource management, as LLMs can prioritize and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimize their processing efforts based on the requirements of each subtask.\\n\\nThis methodology not only enhances </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the efficiency and effectiveness of LLM agents but also allows them to be applied to a wider range of applications.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">By breaking down tasks, LLMs become more adept at handling diverse challenges in fields such as customer support, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">content creation, and data analysis, ultimately leading to improved user experiences and outcomes.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task into smaller, manageable sub-tasks that can be addressed sequentially or independently. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leverages the strengths of LLMs in natural language understanding and generation by allowing them to handle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific components of a larger problem more effectively. Each sub-task can be formulated as a distinct query or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instruction, enabling the LLM to focus on providing targeted responses or solutions rather than attempting to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tackle the entire task in one go. \\n\\nFor instance, in a scenario where an LLM is tasked with organizing a travel </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">itinerary, task decomposition might involve separating the process into distinct segments such as researching </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">destinations, booking accommodations, and planning activities. By addressing each of these components individually,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the LLM can optimize its performance, ensure thoroughness, and enhance the overall quality of the output. Moreover,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition facilitates better collaboration between multiple LLM agents or other AI systems, as they can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">work on different parts of the task concurrently, leading to more efficient problem-solving and project completion.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Overall, task decomposition is a valuable strategy for maximizing the potential of LLMs, allowing them to exhibit </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">greater proficiency in addressing complex, multifaceted challenges.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks or problems into smaller, more manageable sub-tasks that can be individually addressed. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facilitates more effective problem-solving and enhances the model\\'s ability to provide coherent and contextually </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant responses.\\n\\nIn practical terms, task decomposition involves analyzing a given task to identify its key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components and relationships. For instance, if the task is to \"plan a vacation,\" it can be decomposed into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sub-tasks such as \"choose a destination,\" \"budget for the trip,\" \"create an itinerary,\" and \"book accommodations.\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">By tackling these sub-tasks sequentially or in parallel, the LLM can generate more accurate and detailed outputs, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improving the overall quality of the response.\\n\\nFurthermore, task decomposition enables LLM agents to work </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through intricate scenarios more systematically. It can leverage its linguistic and contextual understanding to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">address each sub-task based on the information available. This approach not only enhances the LLM\\'s efficiency in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generating responses but also allows it to manage usersâ€™ expectations by providing clear and structured </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information.\\n\\nOverall, task decomposition is a vital technique in the development of LLM agents, allowing them to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">navigate complex inquiries more effectively, ultimately leading to a better user experience.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks that can be addressed sequentially or simultaneously. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enables LLM agents to tackle intricate problems by structuring them into simpler components, thereby enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clarity and efficiency in execution.\\n\\nIn practice, task decomposition enhances the performance of LLM agents by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allowing them to focus on specific aspects of a task without being overwhelmed by the entire scope of the problem. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">For example, if an agent is required to write a report, task decomposition would involve identifying the necessary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">steps such as gathering information, creating an outline, drafting sections, and editing the final document. By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following these smaller, structured tasks, the agent can systematically address each part, leading to a more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent and comprehensive output.\\n\\nMoreover, task decomposition can facilitate better collaboration among </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple LLM agents, each specializing in different sub-tasks. This collaborative approach not only improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency but also leverages the strengths of various models, ultimately leading to more sophisticated outcomes. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Overall, task decomposition is a critical strategy for maximizing the capabilities of LLM agents in solving complex</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenges effectively.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks that can be tackled sequentially or in parallel. This approach is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly beneficial for LLMs, which are designed to process and generate human-like text but may encounter </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">difficulties when faced with multifaceted queries or overarching objectives. By decomposing a task, an LLM agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can analyze each sub-task independently, leveraging its capabilities to generate more focused, coherent, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contextually relevant responses.\\n\\nFor example, if the overarching task is to write a research paper, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition would involve separating that goal into distinct components such as conducting a literature review, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">formulating a thesis statement, outlining sections (introduction, methodology, results, discussion), and finally </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">drafting each section. This step-by-step approach not only enhances the clarity of the responses generated by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM but also allows for iterative refinement, as feedback can be applied to individual components of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task.\\n\\nFurthermore, task decomposition can facilitate collaboration between multiple agents or systems, enabling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them to specialize in different aspects of the task at hand. Overall, effective task decomposition is crucial for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">maximizing the efficiency and output quality of LLM agents, turning complex objectives into achievable and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematic workflows.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0032838789435724416</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01873836588735382</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05309538667400678</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00811601554354032</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0010589732288887415</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0010727288123841088</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.026502825630207855</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.024004203577836353</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0019521416591790814</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.056575056786338486</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.023571028995017212</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.031626167396704354</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.023906926003595192</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.03691635808597008</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.006138603513439496</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.03126603737473488</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.016663407635254163</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.021646898239850998</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0035324182633000114</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05211928611000379</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span> +<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1516</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents is the process by which an agent breaks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">down large, complex tasks into smaller, more manageable subgoals. This method allows the agent to handle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated tasks efficiently by transforming them into a series of simpler steps. By employing techniques such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Chain of Thought (CoT), the model is encouraged to \"think step by step,\" enabling it to utilize its computational </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">power effectively and providing insights into its reasoning process. This approach enhances the overall model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance by facilitating clearer planning and execution of tasks.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents is the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable subtasks that can be processed more efficiently. This approach enables LLMs to tackle\u001b[0m\n",
       "\u001b[32mintricate problems by simplifying them into a series of steps that can be addressed sequentially or in parallel. \u001b[0m\n",
       "\u001b[32mEach subtask focuses on a specific aspect of the overall task, making it easier for the LLM to generate accurate \u001b[0m\n",
       "\u001b[32mand relevant responses.\\n\\nIn practice, task decomposition involves identifying the different components of a given\u001b[0m\n",
       "\u001b[32mtask, such as information gathering, analysis, and synthesis. By segmenting these components, LLM agents can \u001b[0m\n",
       "\u001b[32moperate with greater precision, allowing them to leverage their strengths in natural language understanding and \u001b[0m\n",
       "\u001b[32mgeneration. Furthermore, task decomposition can facilitate better resource management, as LLMs can prioritize and \u001b[0m\n",
       "\u001b[32moptimize their processing efforts based on the requirements of each subtask.\\n\\nThis methodology not only enhances \u001b[0m\n",
       "\u001b[32mthe efficiency and effectiveness of LLM agents but also allows them to be applied to a wider range of applications.\u001b[0m\n",
       "\u001b[32mBy breaking down tasks, LLMs become more adept at handling diverse challenges in fields such as customer support, \u001b[0m\n",
       "\u001b[32mcontent creation, and data analysis, ultimately leading to improved user experiences and outcomes.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down a complex \u001b[0m\n",
       "\u001b[32mtask into smaller, manageable sub-tasks that can be addressed sequentially or independently. This approach \u001b[0m\n",
       "\u001b[32mleverages the strengths of LLMs in natural language understanding and generation by allowing them to handle \u001b[0m\n",
       "\u001b[32mspecific components of a larger problem more effectively. Each sub-task can be formulated as a distinct query or \u001b[0m\n",
       "\u001b[32minstruction, enabling the LLM to focus on providing targeted responses or solutions rather than attempting to \u001b[0m\n",
       "\u001b[32mtackle the entire task in one go. \\n\\nFor instance, in a scenario where an LLM is tasked with organizing a travel \u001b[0m\n",
       "\u001b[32mitinerary, task decomposition might involve separating the process into distinct segments such as researching \u001b[0m\n",
       "\u001b[32mdestinations, booking accommodations, and planning activities. By addressing each of these components individually,\u001b[0m\n",
       "\u001b[32mthe LLM can optimize its performance, ensure thoroughness, and enhance the overall quality of the output. Moreover,\u001b[0m\n",
       "\u001b[32mtask decomposition facilitates better collaboration between multiple LLM agents or other AI systems, as they can \u001b[0m\n",
       "\u001b[32mwork on different parts of the task concurrently, leading to more efficient problem-solving and project completion.\u001b[0m\n",
       "\u001b[32mOverall, task decomposition is a valuable strategy for maximizing the potential of LLMs, allowing them to exhibit \u001b[0m\n",
       "\u001b[32mgreater proficiency in addressing complex, multifaceted challenges.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks or problems into smaller, more manageable sub-tasks that can be individually addressed. This approach \u001b[0m\n",
       "\u001b[32mfacilitates more effective problem-solving and enhances the model\\'s ability to provide coherent and contextually \u001b[0m\n",
       "\u001b[32mrelevant responses.\\n\\nIn practical terms, task decomposition involves analyzing a given task to identify its key \u001b[0m\n",
       "\u001b[32mcomponents and relationships. For instance, if the task is to \"plan a vacation,\" it can be decomposed into \u001b[0m\n",
       "\u001b[32msub-tasks such as \"choose a destination,\" \"budget for the trip,\" \"create an itinerary,\" and \"book accommodations.\" \u001b[0m\n",
       "\u001b[32mBy tackling these sub-tasks sequentially or in parallel, the LLM can generate more accurate and detailed outputs, \u001b[0m\n",
       "\u001b[32mimproving the overall quality of the response.\\n\\nFurthermore, task decomposition enables LLM agents to work \u001b[0m\n",
       "\u001b[32mthrough intricate scenarios more systematically. It can leverage its linguistic and contextual understanding to \u001b[0m\n",
       "\u001b[32maddress each sub-task based on the information available. This approach not only enhances the LLM\\'s efficiency in \u001b[0m\n",
       "\u001b[32mgenerating responses but also allows it to manage usersâ€™ expectations by providing clear and structured \u001b[0m\n",
       "\u001b[32minformation.\\n\\nOverall, task decomposition is a vital technique in the development of LLM agents, allowing them to\u001b[0m\n",
       "\u001b[32mnavigate complex inquiries more effectively, ultimately leading to a better user experience.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks that can be addressed sequentially or simultaneously. This approach \u001b[0m\n",
       "\u001b[32menables LLM agents to tackle intricate problems by structuring them into simpler components, thereby enhancing \u001b[0m\n",
       "\u001b[32mclarity and efficiency in execution.\\n\\nIn practice, task decomposition enhances the performance of LLM agents by \u001b[0m\n",
       "\u001b[32mallowing them to focus on specific aspects of a task without being overwhelmed by the entire scope of the problem. \u001b[0m\n",
       "\u001b[32mFor example, if an agent is required to write a report, task decomposition would involve identifying the necessary \u001b[0m\n",
       "\u001b[32msteps such as gathering information, creating an outline, drafting sections, and editing the final document. By \u001b[0m\n",
       "\u001b[32mfollowing these smaller, structured tasks, the agent can systematically address each part, leading to a more \u001b[0m\n",
       "\u001b[32mcoherent and comprehensive output.\\n\\nMoreover, task decomposition can facilitate better collaboration among \u001b[0m\n",
       "\u001b[32mmultiple LLM agents, each specializing in different sub-tasks. This collaborative approach not only improves \u001b[0m\n",
       "\u001b[32mefficiency but also leverages the strengths of various models, ultimately leading to more sophisticated outcomes. \u001b[0m\n",
       "\u001b[32mOverall, task decomposition is a critical strategy for maximizing the capabilities of LLM agents in solving complex\u001b[0m\n",
       "\u001b[32mchallenges effectively.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks that can be tackled sequentially or in parallel. This approach is \u001b[0m\n",
       "\u001b[32mparticularly beneficial for LLMs, which are designed to process and generate human-like text but may encounter \u001b[0m\n",
       "\u001b[32mdifficulties when faced with multifaceted queries or overarching objectives. By decomposing a task, an LLM agent \u001b[0m\n",
       "\u001b[32mcan analyze each sub-task independently, leveraging its capabilities to generate more focused, coherent, and \u001b[0m\n",
       "\u001b[32mcontextually relevant responses.\\n\\nFor example, if the overarching task is to write a research paper, task \u001b[0m\n",
       "\u001b[32mdecomposition would involve separating that goal into distinct components such as conducting a literature review, \u001b[0m\n",
       "\u001b[32mformulating a thesis statement, outlining sections \u001b[0m\u001b[32m(\u001b[0m\u001b[32mintroduction, methodology, results, discussion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and finally \u001b[0m\n",
       "\u001b[32mdrafting each section. This step-by-step approach not only enhances the clarity of the responses generated by the \u001b[0m\n",
       "\u001b[32mLLM but also allows for iterative refinement, as feedback can be applied to individual components of the \u001b[0m\n",
       "\u001b[32mtask.\\n\\nFurthermore, task decomposition can facilitate collaboration between multiple agents or systems, enabling \u001b[0m\n",
       "\u001b[32mthem to specialize in different aspects of the task at hand. Overall, effective task decomposition is crucial for \u001b[0m\n",
       "\u001b[32mmaximizing the efficiency and output quality of LLM agents, turning complex objectives into achievable and \u001b[0m\n",
       "\u001b[32msystematic workflows.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;36m0.0032838789435724416\u001b[0m,\n",
       "        \u001b[1;36m0.01873836588735382\u001b[0m,\n",
       "        \u001b[1;36m0.05309538667400678\u001b[0m,\n",
       "        \u001b[1;36m0.00811601554354032\u001b[0m,\n",
       "        \u001b[1;36m-0.0010589732288887415\u001b[0m,\n",
       "        \u001b[1;36m-0.0010727288123841088\u001b[0m,\n",
       "        \u001b[1;36m0.026502825630207855\u001b[0m,\n",
       "        \u001b[1;36m0.024004203577836353\u001b[0m,\n",
       "        \u001b[1;36m-0.0019521416591790814\u001b[0m,\n",
       "        \u001b[1;36m0.056575056786338486\u001b[0m,\n",
       "        \u001b[1;36m0.023571028995017212\u001b[0m,\n",
       "        \u001b[1;36m-0.031626167396704354\u001b[0m,\n",
       "        \u001b[1;36m-0.023906926003595192\u001b[0m,\n",
       "        \u001b[1;36m-0.03691635808597008\u001b[0m,\n",
       "        \u001b[1;36m-0.006138603513439496\u001b[0m,\n",
       "        \u001b[1;36m-0.03126603737473488\u001b[0m,\n",
       "        \u001b[1;36m0.016663407635254163\u001b[0m,\n",
       "        \u001b[1;36m-0.021646898239850998\u001b[0m,\n",
       "        \u001b[1;36m-0.0035324182633000114\u001b[0m,\n",
       "        \u001b[1;36m0.05211928611000379\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m +\u001b[1;36m1516\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents is the process by which an agent breaks \u001b[0m\n",
       "\u001b[32mdown large, complex tasks into smaller, more manageable subgoals. This method allows the agent to handle \u001b[0m\n",
       "\u001b[32mcomplicated tasks efficiently by transforming them into a series of simpler steps. By employing techniques such as \u001b[0m\n",
       "\u001b[32mChain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the model is encouraged to \"think step by step,\" enabling it to utilize its computational \u001b[0m\n",
       "\u001b[32mpower effectively and providing insights into its reasoning process. This approach enhances the overall model \u001b[0m\n",
       "\u001b[32mperformance by facilitating clearer planning and execution of tasks.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents is the process by which an agent breaks down large,       \n",
       "complex tasks into smaller, more manageable subgoals. This method allows the agent to handle complicated tasks     \n",
       "efficiently by transforming them into a series of simpler steps. By employing techniques such as Chain of Thought  \n",
       "(CoT), the model is encouraged to \"think step by step,\" enabling it to utilize its computational power effectively \n",
       "and providing insights into its reasoning process. This approach enhances the overall model performance by         \n",
       "facilitating clearer planning and execution of tasks.                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents is the process by which an agent breaks down large,       \n",
       "complex tasks into smaller, more manageable subgoals. This method allows the agent to handle complicated tasks     \n",
       "efficiently by transforming them into a series of simpler steps. By employing techniques such as Chain of Thought  \n",
       "(CoT), the model is encouraged to \"think step by step,\" enabling it to utilize its computational power effectively \n",
       "and providing insights into its reasoning process. This approach enhances the overall model performance by         \n",
       "facilitating clearer planning and execution of tasks.                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"generated_documents_count\": 5,   \n",
    "    }\n",
    "}\n",
    "response = graph.invoke({\"question\": query}, config=config)\n",
    "\n",
    "display(Pretty(response, max_depth=2, max_length=20))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
