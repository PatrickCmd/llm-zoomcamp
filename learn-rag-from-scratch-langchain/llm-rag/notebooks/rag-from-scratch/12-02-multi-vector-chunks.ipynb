{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580c951b-6b28-47a8-9708-2efc03238f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0e587b-bdfa-4552-8220-64144917eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bcb6ad-e1b8-4729-8bf3-1d871f991747",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 12-2 (Indexing - Multi-Vector (Chunks))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e806a94a-c35e-4acb-a0b3-c67091dfcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aef84c-efb9-4612-956f-e0346bcfac2b",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676051da-a5ae-4348-abc7-8364e400396c",
   "metadata": {},
   "source": [
    "![](images/indexing-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed51e36-ecac-4598-9fe6-5ba15abcbf39",
   "metadata": {},
   "source": [
    "# Part 12-2: Multi-Vector (Chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a04be8-4b40-4532-8183-67141487e2a5",
   "metadata": {},
   "source": [
    "![](images/12-02-multi-vector-chunks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f21622-04a0-45ae-aa28-71ac8cba6fbf",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451cf41e-0256-491f-b4f2-4ca0e8b82b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e39e7ab-64a8-43c7-a1d9-5d9267eb4bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BKP3nUyW5fUrDbeqNkoEN51aFxINn', 'finish_reason': 'stop', 'logprobs': None}, id='run-85c1bb5d-248c-43ef-91f1-cc30b4934713-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5353b6-5ed8-4b66-bee5-a01fbba988e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac755af1-1f44-4352-b360-cbb856aeb95b",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a129af0c-9980-4f69-921b-f292892f0d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58745065-99f8-41e9-a045-26cbfa3f32e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=articles,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4280f16-6d09-4c71-934f-e5fb029c37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5042bf-4d51-47ac-b690-bc03ab6aee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      Thinking about High-Quality Human Data\n",
      "    \n",
      "Date: February 5, 2024  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "[Special thank you to Ian Kivlichan for many useful pointers (E.g. the 100+ year old Nature paper ‚ÄúVox populi‚Äù) and nice feedback. üôè ]\n",
      "High-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection involves attention to details and careful execution. The community knows the value of high quality data, but somehow we have this subtle impression that ‚ÄúEveryone wants to do the model work, not the data work‚Äù (Sambasivan et al. 2021).\n",
      "\n",
      "Fig. 1. Two directions to approach high data quality.\n",
      "Human Raters ‚Üî Data Quality#\n",
      "Collecting human data involve a set of\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cff0076-395a-46e7-b1d2-94cecb992225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43130, 29018]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(doc.page_content) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709207dd-9132-4707-b392-848d3573aa36",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18afe469-880c-4c65-bee0-a619311a63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f11aed37-b1eb-4224-88a2-2bb9bc23c852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21fd3d-c42f-4d56-8793-a77a8b0ee8ac",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d0342f-c075-42da-8133-3f651cb10272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.stores import InMemoryByteStore\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69d0587-eb99-47c1-9977-28e90f653bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 103\n",
      "8 8\n"
     ]
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"split_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "split_ids = [str(uuid.uuid4()) for _ in splits]\n",
    "\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "all_sub_splits = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    split_id = split_ids[i]\n",
    "    sub_splits = child_text_splitter.split_documents([split])\n",
    "    \n",
    "    for sub_split in sub_splits:\n",
    "        sub_split.metadata[id_key] = split_id\n",
    "        \n",
    "    all_sub_splits.extend(sub_splits)\n",
    "\n",
    "retriever.vectorstore.add_documents(all_sub_splits)\n",
    "print(len(all_sub_splits), len(retriever.vectorstore.store))\n",
    "\n",
    "retriever.docstore.mset(list(zip(split_ids, splits)))\n",
    "print(len(split_ids), len(list(retriever.docstore.store.yield_keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8bfc48-bcdf-425c-b5a2-e06061d380fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_query = \"What is task decomposition for LLM agents?\"\n",
    "human_data_query = \"What are main steps for collecting human data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1787a2-18cf-465c-91e8-ee2324a242d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is task decomposition for LLM agents?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is task decomposition for LLM agents?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c4ce6ad2-f138-4d89-9f78-5fbfd31a5da7'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'069cc00f-92fd-41ae-a8b0-a6a0c63441a4'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'eb349b95-5398-44f4-8bc7-4c8669d9bb5e'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3d1901df-c520-4c54-8820-b5971f52380c'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples to guide LLM to do task parsing and planning.\\nInstruction:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'bcd20973-d3ab-4f4c-9c78-322f66d4f4ca'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'c4ce6ad2-f138-4d89-9f78-5fbfd31a5da7'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA \u001b[0m\n",
       "\u001b[32mcomplicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask \u001b[0m\n",
       "\u001b[32mDecomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for enhancing \u001b[0m\n",
       "\u001b[32mmodel performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time \u001b[0m\n",
       "\u001b[32mcomputation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple \u001b[0m\n",
       "\u001b[32mmanageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'069cc00f-92fd-41ae-a8b0-a6a0c63441a4'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  \u001b[0m\n",
       "\u001b[32m|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a cool \u001b[0m\n",
       "\u001b[32mconcept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. \u001b[0m\n",
       "\u001b[32mThe potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be \u001b[0m\n",
       "\u001b[32mframed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM\u001b[0m\n",
       "\u001b[32mfunctions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: \u001b[0m\n",
       "\u001b[32mThe agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex \u001b[0m\n",
       "\u001b[32mtasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn \u001b[0m\n",
       "\u001b[32mfrom mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'eb349b95-5398-44f4-8bc7-4c8669d9bb5e'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'3d1901df-c520-4c54-8820-b5971f52380c'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe system \u001b[0m\n",
       "\u001b[32mcomprises of 4 stages:\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task planning: LLM works as the brain and parses the user requests into multiple tasks.\u001b[0m\n",
       "\u001b[32mThere are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot \u001b[0m\n",
       "\u001b[32mexamples to guide LLM to do task parsing and planning.\\nInstruction:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'bcd20973-d3ab-4f4c-9c78-322f66d4f4ca'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning possibilities \u001b[0m\n",
       "\u001b[32mat each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step,\u001b[0m\n",
       "\u001b[32mcreating a tree structure. The search process can be BFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbreadth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or DFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdepth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[32meach state evaluated by a classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvia a prompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or majority vote.\\nTask decomposition can be done \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by LLM \u001b[0m\n",
       "\u001b[32mwith simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by using \u001b[0m\n",
       "\u001b[32mtask-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with human inputs.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 1:</span>\n",
       "Fig. 1. Overview of a <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span>-powered autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> system.\n",
       "Component One: Planning#\n",
       "A complicated <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span> usually involves many steps. An <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> needs to know <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">what</span> they are and plan ahead.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Task</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Decomposition</span>#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> enhancing model performance \n",
       "on complex tasks. The model <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to \n",
       "decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and \n",
       "shed lights into an interpretation of the model‚Äôs thinking process.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 1:\u001b[0m\n",
       "Fig. 1. Overview of a \u001b[4;31mLLM\u001b[0m-powered autonomous \u001b[4;31magent\u001b[0m system.\n",
       "Component One: Planning#\n",
       "A complicated \u001b[4;31mtask\u001b[0m usually involves many steps. An \u001b[4;31magent\u001b[0m needs to know \u001b[4;31mwhat\u001b[0m they are and plan ahead.\n",
       "\u001b[4;31mTask\u001b[0m \u001b[4;31mDecomposition\u001b[0m#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique \u001b[4;31mfor\u001b[0m enhancing model performance \n",
       "on complex tasks. The model \u001b[4;31mis\u001b[0m instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to \n",
       "decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and \n",
       "shed lights into an interpretation of the model‚Äôs thinking process.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 2:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> Powered Autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Agents</span>\n",
       "    \n",
       "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agents</span> with <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> (large language model) as its core controller <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Agent</span> System Overview#\n",
       "In a <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span>-powered autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> system, <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> functions as the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span>‚Äôs brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">decomposition</span>: The <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 2:\u001b[0m\n",
       "\u001b[4;31mLLM\u001b[0m Powered Autonomous \u001b[4;31mAgents\u001b[0m\n",
       "    \n",
       "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building \u001b[4;31magents\u001b[0m with \u001b[4;31mLLM\u001b[0m (large language model) as its core controller \u001b[4;31mis\u001b[0m a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of \u001b[4;31mLLM\u001b[0m extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "\u001b[4;31mAgent\u001b[0m System Overview#\n",
       "In a \u001b[4;31mLLM\u001b[0m-powered autonomous \u001b[4;31magent\u001b[0m system, \u001b[4;31mLLM\u001b[0m functions as the \u001b[4;31magent\u001b[0m‚Äôs brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and \u001b[4;31mdecomposition\u001b[0m: The \u001b[4;31magent\u001b[0m breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The \u001b[4;31magent\u001b[0m can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them \u001b[4;31mfor\u001b[0m future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 3:</span>\n",
       "Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
       "The system comprises of 4 stages:\n",
       "(1) <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Task</span> planning: <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> works as the brain and parses the user requests into multiple tasks. There are four \n",
       "attributes associated with each <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span>: <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span> type, ID, dependencies, and arguments. They use few-shot examples to \n",
       "guide <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> to do <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span> parsing and planning.\n",
       "Instruction:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 3:\u001b[0m\n",
       "Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
       "The system comprises of 4 stages:\n",
       "(1) \u001b[4;31mTask\u001b[0m planning: \u001b[4;31mLLM\u001b[0m works as the brain and parses the user requests into multiple tasks. There are four \n",
       "attributes associated with each \u001b[4;31mtask\u001b[0m: \u001b[4;31mtask\u001b[0m type, ID, dependencies, and arguments. They use few-shot examples to \n",
       "guide \u001b[4;31mLLM\u001b[0m to do \u001b[4;31mtask\u001b[0m parsing and planning.\n",
       "Instruction:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 4:</span>\n",
       "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first\n",
       "decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree \n",
       "structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state \n",
       "evaluated by a classifier (via a prompt) or majority vote.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Task</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">decomposition</span> can be done (1) by <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> with simple prompting like \"Steps <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> XYZ.\\n1.\", \"<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">What</span> are the subgoals \n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> achieving XYZ?\", (2) by using <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span>-specific instructions; e.g. \"Write a story outline.\" <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> writing a novel, or\n",
       "(3) with human inputs.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 4:\u001b[0m\n",
       "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first\n",
       "decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree \n",
       "structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state \n",
       "evaluated by a classifier (via a prompt) or majority vote.\n",
       "\u001b[4;31mTask\u001b[0m \u001b[4;31mdecomposition\u001b[0m can be done (1) by \u001b[4;31mLLM\u001b[0m with simple prompting like \"Steps \u001b[4;31mfor\u001b[0m XYZ.\\n1.\", \"\u001b[4;31mWhat\u001b[0m are the subgoals \n",
       "\u001b[4;31mfor\u001b[0m achieving XYZ?\", (2) by using \u001b[4;31mtask\u001b[0m-specific instructions; e.g. \"Write a story outline.\" \u001b[4;31mfor\u001b[0m writing a novel, or\n",
       "(3) with human inputs.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from mistakes and refine them for future steps, thereby improving the quality of final </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results.\\n\\n\\nMemory\\n\\nShort-term memory: I would co'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8746</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Memory (STM) or W'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8709</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  \u001b[0m\n",
       "\u001b[32m|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a cool \u001b[0m\n",
       "\u001b[32mconcept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. \u001b[0m\n",
       "\u001b[32mThe potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be \u001b[0m\n",
       "\u001b[32mframed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM\u001b[0m\n",
       "\u001b[32mfunctions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: \u001b[0m\n",
       "\u001b[32mThe agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex \u001b[0m\n",
       "\u001b[32mtasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn \u001b[0m\n",
       "\u001b[32mfrom mistakes and refine them for future steps, thereby improving the quality of final \u001b[0m\n",
       "\u001b[32mresults.\\n\\n\\nMemory\\n\\nShort-term memory: I would co'\u001b[0m+\u001b[1;36m8746\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and \u001b[0m\n",
       "\u001b[32mexploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and \u001b[0m\n",
       "\u001b[32mDQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for helping\u001b[0m\n",
       "\u001b[32mme draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n\\nShort-Term \u001b[0m\n",
       "\u001b[32mMemory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or W'\u001b[0m+\u001b[1;36m8709\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(agent_query)\n",
    "\n",
    "response = retriever.vectorstore.similarity_search(agent_query)\n",
    "rprint(Pretty(response, no_wrap=False))\n",
    "\n",
    "chunk_pattern = re.compile(r'^Chunk \\d+.*:$', flags=re.MULTILINE)\n",
    "terms_pattern = re.compile(rf'\\b({\"|\".join(agent_query.split())})\\b', flags=re.IGNORECASE)\n",
    "\n",
    "for chunk_id, doc in enumerate(response, start=1):\n",
    "    text = Text(f\"Chunk {chunk_id}:\\n{doc.page_content}\")\n",
    "    text.highlight_regex(chunk_pattern, \"bold green\")\n",
    "    text.highlight_regex(terms_pattern, \"underline red\")\n",
    "    rprint(text)\n",
    "\n",
    "response = retriever.invoke(agent_query)\n",
    "rprint(Pretty(response, max_string=1000, no_wrap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38a12f7-9bdf-4877-8534-c3a3183391c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are main steps for collecting human data?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are main steps for collecting human data?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'17741deb-555b-42e6-9d3c-d66395f8ef40'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e1ceb846-4f31-499b-82de-5fbb14f27d22'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Two directions to approach high data quality.\\nHuman Raters ‚Üî Data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Quality#\\nCollecting human data involve a set of operation steps and every step contributes to the data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality:\\n\\nTask design: Design task workflow to improve clarity and reduce complexity. Detailed guidelines are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helpful but very long and complicated guidelines demand a decent amount of training to be useful.\\nSelect and train</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a pool of raters: Select annotators with matched skillset and consistency. Training sessions are necessary. After </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">onboarding, regular feedback and calibration sessions are also needed.\\nCollect and aggregate data. This is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stage where more ML techniques can be applied to clean, filter and smartly aggregate data to identify the true </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">labels.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8784a472-61c6-4eb8-8475-b914a3c36e86'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e1ceb846-4f31-499b-82de-5fbb14f27d22'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated Reading </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Time: 21 min  |  Author: Lilian Weng\\n\\n\\n[Special thank you to Ian Kivlichan for many useful pointers (E.g. the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">100+ year old Nature paper ‚ÄúVox populi‚Äù) and nice feedback. üôè ]\\nHigh-quality data is the fuel for modern data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deep learning model training. Most of the task-specific labeled data comes from human annotation, such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involves attention to details and careful execution. The community knows the value of high quality data, but </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">somehow we have this subtle impression that ‚ÄúEveryone wants to do the model work, not the data work‚Äù (Sambasivan et</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al. 2021).'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'395c7e46-0ead-4407-8d94-8bb032ca72f6'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4c32dd6b-d0e0-4cee-b54b-1779b0057a5a'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Or\\n@article{weng2024humandata,\\n  title   = \"Thinking about High-Quality Human Data\",\\n  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2024\",\\n  month   = \"Feb\",\\n  url     </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">= \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\"\\n}\\nReferences#\\n[1] Francis Galton ‚ÄúVox </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">populi‚Äù  Nature 75, 450-451 (1907).\\n[2] Sambasivan et al. ‚ÄúEveryone wants to do the model work, not the data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">work‚Äù: Data Cascades in High-Stakes AI\" CHI 2021\\n[3] Chris Callison-Burch. ‚ÄúFast, Cheap, and Creative: Evaluating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Translation Quality Using Amazon‚Äôs Mechanical Turk‚Äù EMNLP 2009\\n[4] Rottger et al. ‚ÄúTwo Contrasting Data Annotation</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Paradigms for Subjective NLP Tasks‚Äù NAACL 2022.\\n[5] Aroyo &amp; Welty ‚ÄúTruth Is a Lie: Crowd Truth and the Seven Myths</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Human Annotation‚Äù AI Magazine\\xa036.1: 15-24 (2015).\\n[6] Hovy et al. ‚ÄúLearning Whom to Trust with MACE‚Äù </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NAACL-HLT 2013.\\n[7] Wang et al. ‚ÄúAll that Agrees Is Not Gold: Evaluating Ground Truth Labels and Dialogue Content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for Safety‚Äù 2023.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4200a164-5345-40c9-9b5d-829a9286fd90'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8abfe68d-5cb1-4697-9cd9-e836ee05b300'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"With the input and the inference results, the AI assistant needs to describe the process and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">straightforward manner. Then describe the task process and show your analysis and model inference results to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user in the first person. If inference results contain a file path, must tell the user the complete file path.\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'17741deb-555b-42e6-9d3c-d66395f8ef40'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'e1ceb846-4f31-499b-82de-5fbb14f27d22'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Two directions to approach high data quality.\\nHuman Raters ‚Üî Data \u001b[0m\n",
       "\u001b[32mQuality#\\nCollecting human data involve a set of operation steps and every step contributes to the data \u001b[0m\n",
       "\u001b[32mquality:\\n\\nTask design: Design task workflow to improve clarity and reduce complexity. Detailed guidelines are \u001b[0m\n",
       "\u001b[32mhelpful but very long and complicated guidelines demand a decent amount of training to be useful.\\nSelect and train\u001b[0m\n",
       "\u001b[32ma pool of raters: Select annotators with matched skillset and consistency. Training sessions are necessary. After \u001b[0m\n",
       "\u001b[32monboarding, regular feedback and calibration sessions are also needed.\\nCollect and aggregate data. This is the \u001b[0m\n",
       "\u001b[32mstage where more ML techniques can be applied to clean, filter and smartly aggregate data to identify the true \u001b[0m\n",
       "\u001b[32mlabels.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'8784a472-61c6-4eb8-8475-b914a3c36e86'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'e1ceb846-4f31-499b-82de-5fbb14f27d22'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated Reading \u001b[0m\n",
       "\u001b[32mTime: 21 min  |  Author: Lilian Weng\\n\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mSpecial thank you to Ian Kivlichan for many useful pointers \u001b[0m\u001b[32m(\u001b[0m\u001b[32mE.g. the \u001b[0m\n",
       "\u001b[32m100+ year old Nature paper ‚ÄúVox populi‚Äù\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and nice feedback. üôè \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nHigh-quality data is the fuel for modern data \u001b[0m\n",
       "\u001b[32mdeep learning model training. Most of the task-specific labeled data comes from human annotation, such as \u001b[0m\n",
       "\u001b[32mclassification task or RLHF labeling \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwhich can be constructed as classification format\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for LLM alignment \u001b[0m\n",
       "\u001b[32mtraining. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection \u001b[0m\n",
       "\u001b[32minvolves attention to details and careful execution. The community knows the value of high quality data, but \u001b[0m\n",
       "\u001b[32msomehow we have this subtle impression that ‚ÄúEveryone wants to do the model work, not the data work‚Äù \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSambasivan et\u001b[0m\n",
       "\u001b[32mal. 2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'395c7e46-0ead-4407-8d94-8bb032ca72f6'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'4c32dd6b-d0e0-4cee-b54b-1779b0057a5a'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Or\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2024humandata,\\n  title   = \"Thinking about High-Quality Human Data\",\\n  \u001b[0m\n",
       "\u001b[32mauthor  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2024\",\\n  month   = \"Feb\",\\n  url     \u001b[0m\n",
       "\u001b[32m= \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nReferences#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Francis Galton ‚ÄúVox \u001b[0m\n",
       "\u001b[32mpopuli‚Äù  Nature 75, 450-451 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1907\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Sambasivan et al. ‚ÄúEveryone wants to do the model work, not the data \u001b[0m\n",
       "\u001b[32mwork‚Äù: Data Cascades in High-Stakes AI\" CHI 2021\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Chris Callison-Burch. ‚ÄúFast, Cheap, and Creative: Evaluating \u001b[0m\n",
       "\u001b[32mTranslation Quality Using Amazon‚Äôs Mechanical Turk‚Äù EMNLP 2009\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Rottger et al. ‚ÄúTwo Contrasting Data Annotation\u001b[0m\n",
       "\u001b[32mParadigms for Subjective NLP Tasks‚Äù NAACL 2022.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Aroyo & Welty ‚ÄúTruth Is a Lie: Crowd Truth and the Seven Myths\u001b[0m\n",
       "\u001b[32mof Human Annotation‚Äù AI Magazine\\xa036.1: 15-24 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2015\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Hovy et al. ‚ÄúLearning Whom to Trust with MACE‚Äù \u001b[0m\n",
       "\u001b[32mNAACL-HLT 2013.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wang et al. ‚ÄúAll that Agrees Is Not Gold: Evaluating Ground Truth Labels and Dialogue Content \u001b[0m\n",
       "\u001b[32mfor Safety‚Äù 2023.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'4200a164-5345-40c9-9b5d-829a9286fd90'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "            \u001b[32m'split_id'\u001b[0m: \u001b[32m'8abfe68d-5cb1-4697-9cd9-e836ee05b300'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"With\u001b[0m\u001b[32m the input and the inference results, the AI assistant needs to describe the process and \u001b[0m\n",
       "\u001b[32mresults. The previous stages can be formed as - User Input: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m User Input \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Planning: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Tasks \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Model \u001b[0m\n",
       "\u001b[32mSelection: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Model Assignment \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Execution: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Predictions \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. You must first answer the user's request in a\u001b[0m\n",
       "\u001b[32mstraightforward manner. Then describe the task process and show your analysis and model inference results to the \u001b[0m\n",
       "\u001b[32muser in the first person. If inference results contain a file path, must tell the user the complete file path.\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 1:</span>\n",
       "Fig. 1. Two directions to approach high <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> quality.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Human</span> Raters ‚Üî <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Data</span> Quality#\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Collecting</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">human</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> involve a set of operation <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">steps</span> and every step contributes to the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> quality:\n",
       "\n",
       "Task design: Design task workflow to improve clarity and reduce complexity. Detailed guidelines <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">are</span> helpful but \n",
       "very long and complicated guidelines demand a decent amount of training to be useful.\n",
       "Select and train a pool of raters: Select annotators with matched skillset and consistency. Training sessions <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">are</span> \n",
       "necessary. After onboarding, regular feedback and calibration sessions <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">are</span> also needed.\n",
       "Collect and aggregate <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span>. This is the stage where more ML techniques can be applied to clean, filter and smartly \n",
       "aggregate <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> to identify the true labels.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 1:\u001b[0m\n",
       "Fig. 1. Two directions to approach high \u001b[4;31mdata\u001b[0m quality.\n",
       "\u001b[4;31mHuman\u001b[0m Raters ‚Üî \u001b[4;31mData\u001b[0m Quality#\n",
       "\u001b[4;31mCollecting\u001b[0m \u001b[4;31mhuman\u001b[0m \u001b[4;31mdata\u001b[0m involve a set of operation \u001b[4;31msteps\u001b[0m and every step contributes to the \u001b[4;31mdata\u001b[0m quality:\n",
       "\n",
       "Task design: Design task workflow to improve clarity and reduce complexity. Detailed guidelines \u001b[4;31mare\u001b[0m helpful but \n",
       "very long and complicated guidelines demand a decent amount of training to be useful.\n",
       "Select and train a pool of raters: Select annotators with matched skillset and consistency. Training sessions \u001b[4;31mare\u001b[0m \n",
       "necessary. After onboarding, regular feedback and calibration sessions \u001b[4;31mare\u001b[0m also needed.\n",
       "Collect and aggregate \u001b[4;31mdata\u001b[0m. This is the stage where more ML techniques can be applied to clean, filter and smartly \n",
       "aggregate \u001b[4;31mdata\u001b[0m to identify the true labels.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 2:</span>\n",
       "Thinking about High-Quality <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Human</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Data</span>\n",
       "    \n",
       "Date: February 5, 2024  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "[Special thank you to Ian Kivlichan <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> many useful pointers (E.g. the 100+ year old Nature paper ‚ÄúVox populi‚Äù) and\n",
       "nice feedback. üôè ]\n",
       "High-quality <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> is the fuel <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> modern <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> deep learning model training. Most of the task-specific labeled <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> \n",
       "comes from <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">human</span> annotation, such as classification task or RLHF labeling (which can be constructed as \n",
       "classification format) <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> LLM alignment training. Lots of ML techniques in the post can help with <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> quality, \n",
       "but fundamentally <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">human</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> collection involves attention to details and careful execution. The community knows \n",
       "the value of high quality <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span>, but somehow we have this subtle impression that ‚ÄúEveryone wants to do the model \n",
       "work, not the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> work‚Äù (Sambasivan et al. 2021).\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 2:\u001b[0m\n",
       "Thinking about High-Quality \u001b[4;31mHuman\u001b[0m \u001b[4;31mData\u001b[0m\n",
       "    \n",
       "Date: February 5, 2024  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "[Special thank you to Ian Kivlichan \u001b[4;31mfor\u001b[0m many useful pointers (E.g. the 100+ year old Nature paper ‚ÄúVox populi‚Äù) and\n",
       "nice feedback. üôè ]\n",
       "High-quality \u001b[4;31mdata\u001b[0m is the fuel \u001b[4;31mfor\u001b[0m modern \u001b[4;31mdata\u001b[0m deep learning model training. Most of the task-specific labeled \u001b[4;31mdata\u001b[0m \n",
       "comes from \u001b[4;31mhuman\u001b[0m annotation, such as classification task or RLHF labeling (which can be constructed as \n",
       "classification format) \u001b[4;31mfor\u001b[0m LLM alignment training. Lots of ML techniques in the post can help with \u001b[4;31mdata\u001b[0m quality, \n",
       "but fundamentally \u001b[4;31mhuman\u001b[0m \u001b[4;31mdata\u001b[0m collection involves attention to details and careful execution. The community knows \n",
       "the value of high quality \u001b[4;31mdata\u001b[0m, but somehow we have this subtle impression that ‚ÄúEveryone wants to do the model \n",
       "work, not the \u001b[4;31mdata\u001b[0m work‚Äù (Sambasivan et al. 2021).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 3:</span>\n",
       "Or\n",
       "@article{weng2024humandata,\n",
       "  title   = \"Thinking about High-Quality <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Human</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Data</span>\",\n",
       "  author  = \"Weng, Lilian\",\n",
       "  journal = \"lilianweng.github.io\",\n",
       "  year    = \"2024\",\n",
       "  month   = \"Feb\",\n",
       "  url     = \"https://lilianweng.github.io/posts/2024-02-05-<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">human</span>-<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span>-quality/\"\n",
       "}\n",
       "References#\n",
       "[1] Francis Galton ‚ÄúVox populi‚Äù  Nature 75, 450-451 (1907).\n",
       "[2] Sambasivan et al. ‚ÄúEveryone wants to do the model work, not the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">data</span> work‚Äù: <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Data</span> Cascades in High-Stakes AI\" \n",
       "CHI 2021\n",
       "[3] Chris Callison-Burch. ‚ÄúFast, Cheap, and Creative: Evaluating Translation Quality Using Amazon‚Äôs Mechanical \n",
       "Turk‚Äù EMNLP 2009\n",
       "[4] Rottger et al. ‚ÄúTwo Contrasting <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Data</span> Annotation Paradigms <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> Subjective NLP Tasks‚Äù NAACL 2022.\n",
       "[5] Aroyo &amp; Welty ‚ÄúTruth Is a Lie: Crowd Truth and the Seven Myths of <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Human</span> Annotation‚Äù AI Magazine¬†36.1: 15-24 \n",
       "(2015).\n",
       "[6] Hovy et al. ‚ÄúLearning Whom to Trust with MACE‚Äù NAACL-HLT 2013.\n",
       "[7] Wang et al. ‚ÄúAll that Agrees Is Not Gold: Evaluating Ground Truth Labels and Dialogue Content <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> Safety‚Äù 2023.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 3:\u001b[0m\n",
       "Or\n",
       "@article{weng2024humandata,\n",
       "  title   = \"Thinking about High-Quality \u001b[4;31mHuman\u001b[0m \u001b[4;31mData\u001b[0m\",\n",
       "  author  = \"Weng, Lilian\",\n",
       "  journal = \"lilianweng.github.io\",\n",
       "  year    = \"2024\",\n",
       "  month   = \"Feb\",\n",
       "  url     = \"https://lilianweng.github.io/posts/2024-02-05-\u001b[4;31mhuman\u001b[0m-\u001b[4;31mdata\u001b[0m-quality/\"\n",
       "}\n",
       "References#\n",
       "[1] Francis Galton ‚ÄúVox populi‚Äù  Nature 75, 450-451 (1907).\n",
       "[2] Sambasivan et al. ‚ÄúEveryone wants to do the model work, not the \u001b[4;31mdata\u001b[0m work‚Äù: \u001b[4;31mData\u001b[0m Cascades in High-Stakes AI\" \n",
       "CHI 2021\n",
       "[3] Chris Callison-Burch. ‚ÄúFast, Cheap, and Creative: Evaluating Translation Quality Using Amazon‚Äôs Mechanical \n",
       "Turk‚Äù EMNLP 2009\n",
       "[4] Rottger et al. ‚ÄúTwo Contrasting \u001b[4;31mData\u001b[0m Annotation Paradigms \u001b[4;31mfor\u001b[0m Subjective NLP Tasks‚Äù NAACL 2022.\n",
       "[5] Aroyo & Welty ‚ÄúTruth Is a Lie: Crowd Truth and the Seven Myths of \u001b[4;31mHuman\u001b[0m Annotation‚Äù AI Magazine¬†36.1: 15-24 \n",
       "(2015).\n",
       "[6] Hovy et al. ‚ÄúLearning Whom to Trust with MACE‚Äù NAACL-HLT 2013.\n",
       "[7] Wang et al. ‚ÄúAll that Agrees Is Not Gold: Evaluating Ground Truth Labels and Dialogue Content \u001b[4;31mfor\u001b[0m Safety‚Äù 2023.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 4:</span>\n",
       "With the input and the inference results, the AI assistant needs to describe the process and results. The previous \n",
       "stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model \n",
       "Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward \n",
       "manner. Then describe the task process and show your analysis and model inference results to the user in the first \n",
       "person. If inference results contain a file path, must tell the user the complete file path.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 4:\u001b[0m\n",
       "With the input and the inference results, the AI assistant needs to describe the process and results. The previous \n",
       "stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model \n",
       "Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward \n",
       "manner. Then describe the task process and show your analysis and model inference results to the user in the first \n",
       "person. If inference results contain a file path, must tell the user the complete file path.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from mistakes and refine them for future steps, thereby improving the quality of final </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results.\\n\\n\\nMemory\\n\\nShort-term memory: I would co'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8746</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Memory (STM) or W'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8709</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  \u001b[0m\n",
       "\u001b[32m|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a cool \u001b[0m\n",
       "\u001b[32mconcept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. \u001b[0m\n",
       "\u001b[32mThe potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be \u001b[0m\n",
       "\u001b[32mframed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM\u001b[0m\n",
       "\u001b[32mfunctions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: \u001b[0m\n",
       "\u001b[32mThe agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex \u001b[0m\n",
       "\u001b[32mtasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn \u001b[0m\n",
       "\u001b[32mfrom mistakes and refine them for future steps, thereby improving the quality of final \u001b[0m\n",
       "\u001b[32mresults.\\n\\n\\nMemory\\n\\nShort-term memory: I would co'\u001b[0m+\u001b[1;36m8746\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and \u001b[0m\n",
       "\u001b[32mexploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and \u001b[0m\n",
       "\u001b[32mDQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for helping\u001b[0m\n",
       "\u001b[32mme draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n\\nShort-Term \u001b[0m\n",
       "\u001b[32mMemory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or W'\u001b[0m+\u001b[1;36m8709\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(human_data_query)\n",
    "\n",
    "response = retriever.vectorstore.similarity_search(human_data_query)\n",
    "rprint(Pretty(response, no_wrap=False))\n",
    "\n",
    "chunk_pattern = re.compile(r'^Chunk \\d+.*:$', flags=re.MULTILINE)\n",
    "terms_pattern = re.compile(rf'\\b({\"|\".join(human_data_query.split())})\\b', flags=re.IGNORECASE)\n",
    "\n",
    "for chunk_id, doc in enumerate(response, start=1):\n",
    "    text = Text(f\"Chunk {chunk_id}:\\n{doc.page_content}\")\n",
    "    text.highlight_regex(chunk_pattern, \"bold green\")\n",
    "    text.highlight_regex(terms_pattern, \"underline red\")\n",
    "    rprint(text)\n",
    "\n",
    "response = retriever.invoke(agent_query)\n",
    "rprint(Pretty(response, max_string=1000, no_wrap=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2ceae-3823-46c3-9246-465b7655af7d",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4a5591c-8255-4d49-9a05-54700ac46b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13eca5a4-4772-4d17-a300-550ff64e17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on this context:\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c01f711-b56e-4398-8b88-20a456d7b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07d68e91-f6b2-442a-b516-08bedaf0dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    search_results: list[Document]\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9fc6edf-1a64-4a95-b4cd-435619b0ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG0AAAFNCAIAAACFQXaDAAAAAXNSR0IArs4c6QAAHw1JREFUeJztnXdYFGf+wN/tfYFdegcp0lUsRL0oUbHExAbRQz29JJfEckZjjZrTFONdLmp+XkxiNKfYY0NjOfUssSQxRkUR0AUEKStL2WV7L78/xuM42d2ZhXfZHZjPc8897s47M18+eafs274km80GCLoM2dMB9BAIj3AgPMKB8AgHwiMcCI9woEI5iqRGr1WatWqLxWQz6KxQjulWaEwylUJi8ylsHiUokkmmkLp4QFJX3h9Fd1RVD9TVJZroZI7NBthcil8Q3ajHgUc6iyxvNmqVFoPW8rRaH5HAjk3j9B3Mo1I7eYF20mPJL4qff5BGJ7Nj07gxqRwKtav/PT1LzUNN1QNNfYWu7yDeoBxBJ47gskfpU8P5PZKQGNbQV4UMFqUTp/Rmbp6V3r8qz5kdFJPKdWlH1zyK7qjuXGqd+GYIX0BzPUh8YDRYfzzS5BdId6liuuDxSZmm/I4qZ3ZwZyPEEzfPSmkMcuYoP4zlsXosutLaWGsYN6dXSET4+XSLTm0ZNSMIS2FMj6faR9pakbZXSQQADJ3oT6OT71+TYymM7lGtMN+/Lp/0ThiM2HDGi1MDpA1GcaUWtSS6x59OtiRm8iAFhj/ShvtcL2xBLYbisVlsaG00JgzovR4Dwhh+QfTyuyrnxVA8lvykGD7FH2pg+GPYq8KKoi54NBmtotuq8Dg27MBwBteXpm61NNXrnZRx5rG6RBOTynFDYM44fPjw+vXrO7HjypUrT5065YaIAAAgJo1T/UDjpIAzjw1Vuvj+rv086joPHz7s5h2xEJfBbRYbnBRw9h7+/ed12TMCAsOZ7oisqKho27ZtlZWVFoslISFhwYIFAwYMeOutt+7evYsU2L9/f2Ji4rlz5/bu3VtbW0un09PT05cuXRoeHo7UPhKJFB0dvW/fvo0bNy5ZsgTZi8vl/vjjj9CjNRutO9ZWz/usj6MCzuqjRmXm8OA0UD6HTqdbvHhxbGzsrl27CgoK4uPjFy1apFQqN2/e3Ldv35ycnIsXL8bFxZWWlq5du3bYsGF79+7dunWrTqdbvnw5cgQajVZZWfno0aOtW7empaWdPXsWALB8+fKTJ0+6I2AqnUyhkAw6i8MCTnbWqixsnltadCQSiUajmTBhQkxMDABg2bJlY8aModPpTCaTSqXS6XRfX18AQFRU1N69e+Pj46lUKgAgPz//vffek8lkAoEAAFBfX//dd9/5+PgAAAwGAwCAzWYjH90Bh0/RKC2OmrgcerRarSwOmUR2S8NiZGRkVFTU2rVrc3Nzs7KyEhMTMzMzOxbjcrlisfjLL7+sq6vT6/UmkwkAoFQqEY9RUVHus9YRJoditTi8Bzq8rslkss0GdGqHNbkrUCiUnTt3jh49urCwcNasWa+88sqZM2c6Frtw4cKqVatSU1O3bt164MCBNWvWtN/K5XbrM7C1ycjhO6x2zu6PbD5VqzS7Jyrg5+e3ePHikydPHj58ePDgwevWrev4wC0sLBw4cOC8efOio6P9/f31emdvcG7FarEZdFYW1+FdzpnH0Bim1j31USwWtz1VY2NjV69eTSaTHz9+jHzT9gphNBqRGyXCuXPn2m/tiPvGKqkV5uhkZ6/Szjz6hzEq76ndEBWQSCQrVqzYt2/fkydPampqdu7cSSaT09LSAAA8Hk8kEolEIrlcnpqaevPmzZKSkoaGho0bN/r7+wMAysrKOlZMBoPBYDDu3r0rEonMZvjXUNUDDV/g7JlMcfLjgeNDvXGipX821jZh7ISGhoaGhh47dmz37t0nT57UarWrVq1KT08HAPj4+Jw5c+b48eP9+/fPycmpqKj49ttvz549m5mZuWTJkuLi4u+//z46Orq2tlatVk+aNKntmFartbCw8Pz587m5uQwGA27Av5yWpg7zcdabYnPK+T0NTXU652V6PEa9ufDLOudlUNp7Egfyfjkjg/vfFnfcPCuLRus+RPm5EpXEuXtJLq7UhcWx7BZYuHBhSUmJ3U0Wi4VCsf+A+/DDD0eMGOH81J1m5MiRjuJBXrnsbr148SLytv8cGqW5okj9+kcxzk+K3s/VWKsvvqEYk2+/u0er1SLxdcRsNtuNDADAYrEcbeo6KpX9tkLk+ePovDye/bbqn0+3BIQy4tFasjH1Fz64oZBKDCNzA1FL9jCKr8tbm0wjpgWglsTUX5g23MdmBbfOSWHEhhsq76kr76uxSHRtHMCdS60Ws23w2M4Mf8Ed5XdVVSWacX/A2tXswvCqzFF+ZpP1/B5JZ2PDDb9dkFU9cEFiZ8ZJld9VXT3WNGScMP13vhiK44yKItXPp6Rpw/gDRrl22XVm3J7JYPn5tKzqgTp9uG9MGkcQRHf1CN6GqtVUXaJ5UqqhsyhDXxF2YhRY58eRquXm4hvy6gcaqxXEpHGoVBKHT+ULqBYcDCMFFApJJTdplRad2tJQpdNrrTGpnOQhvIDOdqJ0aTwugrzZKHmiV7WaNUozmUJSySA3E9y/fz8lJQXu+ybXl2o129h8CseXGhTJDAjr6u9xCB7dzejRo48ePdq+Ac0LIeYrwIHwCAcceExMTPR0COjgwKNIJPJ0COjgwGN3dq52Ghx4VCgUng4BHRx4DAkJ8XQI6ODAY0NDg6dDQAcHHlNSUjwdAjo48FhaWurpENDBgUdcgAOPyDAKLwcHHlta0KeveBwceCTqIxyI+tiLwIHHPn0czhLwHnDgsW18qTeDA4+4AAcek5KSPB0COjjw6NYJb7DAgUdcgAOPRHsPHIj2nl4EDjwS/a5wIPpdexE48Ej0X8OB6L+GA9HeAweivacXgQOPQUGYVmD0LDjw2NjY6OkQ0MGBx+TkZE+HgA4OPJaVlXk6BHRw4JGoj3Ag6iMckIXhvBzvnYc0YcIEZA5XS0uLQCAgk8k2m83f33/Xrl2eDs0O7lrcoOuQSKSnT58i/5ZIJMgycIsXL/Z0XPbx3uu6f//+z10rMTExo0aN8lxEzvBej7Nnzw4O/u9MchaLNXPmTI9G5Azv9ZiYmNivX7+2j3369MnJyfFoRM7wXo8AgFmzZiE/rtlsdn5+vqfDcYZXe0xKSsrIyLDZbDExMd5cGTvzvDYarC1ig17bTbP+x704p77cNDlnSlWJs2WnIUJnkIQhDCdLPdrFtffHf++XPC7WBEezyO5Z79UboLPIdSJNeBxrdH4QjYH1esXq0Wq1FX4l7pPO75PB71qc+KCxVvfr2eZpC8OYHEwVE6vHk1+L4zN9IxK7e3l7D6KWm87vFs9dF42lMKZ6W1OmYfKovUoiklYhfgC/+AakPD4AgJanRgazp6WGwwLHh9r4xFk6gDYwedRpLD4BuF/sqBP4+NONBkxvJpg8mo02i8lLm4XcitUC9NhWrPbq93AcQXiEA+ERDoRHOBAe4UB4hAPhEQ6ERzgQHuFAeIQD4REO3u5x0pRRe/bu9HQU6HjeY3X14xn5Ex1tnf/Okqys4d0bUWfw/LiU8nJn06vHjnWo2KtwV32cPHX00WMHVr6/KGfcC2q1GgBw6fL5d+bNHv/y8Km5OV9u24Tk2NpdsP2vn61vbJRkjxp49NiBwhOHp0wb89NPV6dMG/P1N188d12XVzxasXLhpCmjXn7lxQ/+skwiaQAA7Pxu28RXRyCpDREOHipwflJ34C6PVCr11OnjsTFxWzZtZzKZN278+MmGNZmZQ3Z8e3DF8nXXrl/atGUDAGDG9DlTp84IDAw6cfziKxOn0Wg0vV53vPDQyhXrJ03Ka3/AxkbJe0vfJpHJWzZt3/T5N0qVYunyeUaj8aXssRqN5s7dW20lr127lDVkOJfLdXRSd+AujyQSiclgvv3WopSUdCqVeuDQ7oyMAX96c2F4WETWkGF/evPPFy/+q6mpkclkMugMEonk4+PLYDBIJJJer8+dlp81ZFhoSFj7A/5w6iiJRFq7ZkNsbFzfxOTVqz5uaBBfvXYpNjYuMjL6xo0rSLHGRskjUdmoUeMAAHZPKpW6ZVUlNz5nUlLSkX9Yrdby8ocDM7PaNvXLyAQAVFVV2N0xOTmt45cPH5b0TUzhcZ/lJQoKCg4JCausFAEAskfm/PTzVavVCgC4dv0Sh8PJGjLc0Umrn7hlVpMbnzMczrPcYHq93mKx7C7YvmfvjvYFpDL7VaNtx/ZoNOqKSlHOuBfavjGZTMgRXsrOKdjzbUnJ/fT0/levXRo+LJvBYCAJrzqetLXVLWnbuuN5jWQRnjplxssTJrf/3tfPhdwkHA43La3f0iX/k+KVxWIDACIjo2Nj467fuBIaGl5aWjznD285OalA4JZV57rDI5lMjo/v29jYEBn5rE/dZDI1NTfyeS4MzUhKSj1/4XRoaHhbwoq6uhqh8JmU7JE55y+cDg+P9PMTDOg/yMlJ3ZRdt5vew2dM/8O165cPHNxdV1dTUSn6dOMHi959Q6PRAAC4XJ5U2lJcXIS8xzjilYnTdDrt3z5bX1Epqq+v3bN35x/feO3Ro2dLgGRn59TX1546fWzkyDFtmfXsnlSr1brjD+wmjy/+7qXV73986fK519+cvnzFApPZtGXTdg6HAwAY9dK40NDwpcvn/eucs1TqwcEhmzdtl8mki9594535s2/99vMnH29ueyKFhYYnxPd9/Lhi9EvjnJ+UzWa74w/ENL7nxyPNXD964iAczMuHS1Ot/t7llmnvok888fzv654B4REOhEc4EB7hQHiEA+ERDoRHOBAe4UB4hAPhEQ6ERzgQHuFAeIQDJo8sHoVM7bETCp1iwzjhBZNHvh+1qUbX5ZjwR1O9nsnBpAhTofBEllYJOas1LlA0GaOTMbX7YvLI86X1Hcy78j0O8ghC5NezzXwhNTwek0cX5l9X3lPfOi9LHOQjDGUy2T12uqHFZG0W6xuqtMIQ+uCxWHs0XZvHLm0w3L+mkDeblFIThuJwMBgMdDqdROqmB50ghMFkkxMGcKKTXehZ9N71pNog8tr3IgiPcMCBRyJvChyIvClwINZhhwOxDjsc+vbt6+kQ0MGBx0ePHnk6BHRw4JG4P8KBuD/2InDgMT4+3tMhoIMDjxUV9qeHeBU48IgLcOCRyWR6OgR0cODRfZMrIYIDj3w+DlZAxYFHpVLp6RDQwYFHXIADj2FhYRhKeRgceBSLxZ4OAR0ceMQFOPBItPfAgWjv6UXgwCPR7woHot+1F4EDj8TzGg7E8xoOXj5iDwEHHuVyTJlLPAsOPOICHHhMTEz0dAjo4MCjSCTydAjo4MBjUlKSp0NABwceHz50tvCrl4ADj8S4PTgQ4/bggIv7o/fOQ8rLy2MymWQyuby8PDw8HPk3k8ncvn27p0Ozg+fXD3fE48ePyeRnl0t1dTUAgEKhEHntXWbw4MHPfRMRETFjxgwPhYOC93qcO3du+xEpZDJ56tSp3TZb01W812NWVlZCQkLb7Ts8PHz69OmeDsoh3usRqZI+Pj7InTEvL69t4VsvxKs9ZmVlJSYm2my20NBQb66MWJ/XZpNVp+6mRPbPMSP3jzWPm/KmzNIorAB4IAYanYxlqQ+U98eHt5TF1xUyiZHF9d5ryq0w2BSjzpLyAn/gGGdrLDjzeOuCrOWpqd8IAU9Ac0+Q+EAtN1XdV6lajePmBDsq49Djr+dkSqk5a2KgOyPEE2U35bIG/fi59lXav/Jbm4wtYgMhsT3JWb50FuVJmcbuVvseW8QGm81L33g9CJ1JaayxP+jfvke1whIQgYPZFt2MMJSh19p/Z7D/3mMyWE04mGzR3VjNNkfrk3n1eziOIDzCgfAIB8IjHAiPcCA8woHwCAfCIxwIj3AgPMKB8AgHwiMcerjH9R+uPHf+VDecqId7LC/vprGT9vsVbp2XGfUgY6QL+YBbWpo3bdlQVPQbl8vLnZav0aivXb9csOsoAMBsNu/b/93lKxcaGxsCAoLycmdOejUXAFBTUz339bzNm745dvzggwf3yGRy9sgxC+YvRfqp5fLWr77Zcv/+HYVCHhsb/6c3F/bvNxAAUHji8J69O5a9t/bzzZ/kjHl53juLW1tlX2//4u7dWyqVMiAgaOrk6VOnzgAAZI8aiMTG5XJPnfwRSXN/5Mi+mtpqFov9UvbYN99Y4NKiNjVl6rpHqvF/DOm4Cdo4qc83f1JZKfr4o00CP+HOf26rrX1Cpz/L8PDN9v87c7Zw8aJVKakZd+78+uW2z6lU6ssTJlOoVADAtq82LXn3/U8+2nTn7q1ly+enpfXPHjnGarWuXPVntUa9csV6ocD/5A9HVr2/6Otte2Jj42g0ml6vO154aOWK9Ugu4c8+/6iu9skHaz4VCIQPSu5t2rwhMCh4+LCRhw+dfW3GhD8vXI6kZ0fS3Of/fu7atZ/W19du3rJBoZSvef9jKH8+nOtaJpPeuvXzrJlvDBqY1adP/NrVG5SKZ5Ne1Gr1yR+OTH9t9tixE8PDIia9mjs2Z+KBg7vb9h3x4mgkc3vmgMGhIWEiURkA4PadX8srHi1bunZA/0FRUTELFywLCgo5XngIAEAikfR6fe60/Kwhw0JDwgAAC+Yv/eyzbRkZAyIioiaMnxTXJ+H27ZsAAD7fBwDAZrN9+D6O0tw3NTVCMQCnPorFdTabLTUlA/nI4XAyM4fU1FYDAB4/Ljebze3zy2dkZJ45e6Itf3Kf2P8uA8fl8tRqFZLFnkajIZnokUFS6Wn9kSz2CG2ZhgEALCbrwKHd9+7dVijkVqtVpVKGhUU8FyGS5n7unLfbvkEOXlVVERgY1HUDcDwqFHIAAKtdSmSkLgAAtFoNAGDJ0rfbhoohd2RZqxT5SGcw2h8K2arVakwm09jxQ9u+t1gsAoGw7SOH82zRfrPZvGLVQovFsnDBssiIaAqFsvYvSztGqNfr7aa5l8paYAiA5BFxYWi3gJZK9WzxIuQPXrP6k9iYuPa7BAYENTU7vKY4HC6dTt+x/UD7L9uGlbbn4cOSqqrK/9uyIz29P/KNQt4aEhz6XDFHae59/Vx4ljoBjkfkOnokKo2NjQMAaDSaO3d+FfoHAABiY+NpNFprqyxyxLP88nJ5K4lEansK2aVv3xSj0WixWGJink0alkgafH39OpY0GA3tq39paXGD5GliYnJbAaSCO0pzz+fBWfQLznMGSYe+f/8/S0uLa2ufbPzbX/z+cw1yudyJE6fuLth++cqFpw3ionu3l62Y/9fP1js/YOaAwfFxiZ9u/ODevTsNkqcXL5176+38kz8c6Vgyrk8CnU4/XnhIKm357fbNrf/4bNDArLr6mtZWGYPBYDAY94vvVlSKzGaz3TT3Go39fn1Xgfbes3bNhr9v+njJ0rf9hQEzZ74uFPg/evRsPYT57yzhcXnf7tgqlbYIBMKhL7z4xusLnB+NQqH87a//+Hr7F+s+XKHX64KDQ2fPfjMvd2bHkr6+fiuWr9u588sL/z6TkJC0csX65pamjz95/71l7+z67vDvZ8w99H3BL79c37f3BJLm/uCh3bt2f8PhcFNTM7Zs2s7hcKD8+dDew/V6vcls4nF5yMf3lr7D5/usX/c3KFF6Cd3xHr56zWJZq3TpkjV+foJfbl4vund744YvYB3c+4F5XX/19eYP1i0zGPShoeGrVqzPyhoO6+DeDzSPAoFw7ZoNsI6GO3p4e0+3QXiEA+ERDoRHOBAe4UB4hAPhEQ6ERzgQHuFAeISD/d+FdCbJCoj5M89DppA4PvaN2a+PPD9ac69MZO+cFrHe0XxV+x4DIxjeuoCBJzHqLcEx9scNOKyPYXHMa8ckbg4MTxRdlpJIIMJBmntn84ZLf1FU3FNnjBD6BdEp1N77RJI26B/fV9JopBenBjgqgzKPvbpUc++qXFKtp1A9dp1brBYymeKp07M4FBqTnDqUlzrU2fKyWNeTMug8s64CAGDy5MkFBQXIgh/dD51JxvKowNoezmB57Lo2WbR0JsmDAWDBq4PDETjwSKzDDgdiHXY4EPk+4EDk+4ADUR/hQNRHOBB5SeFA5CXtReDAI/GcgQPxnOlF4MBjVFSUp0NABwcea2pqPB0COjjwiAtw4NFTLeEugQOPCoXC0yGggwOPdqcVehs4CNFq9VgXG3Zw4BEX4MAjkZcUDkRe0l4EDjwS/a5wIPpdexE48Ei048KBaMftReDAI4/H83QI6ODAo0ql8nQI6ODAI/GcgQPxnIFDWFiYp0NABwcexWKxp0NABwceQ0OfXzzPC8GBx6dPn3o6BHRw4DE5ORlDKQ+DA49lZWWeDgEdrPO5up/MzEybzUYmk61WK/L/FAplzpw5Cxcu9HRodvDe+hgXF4csqYv0u5LJ5PDw8Pz8fE/HZR/v9Th79uznFkkfN26cQABnOVvoeK/HiRMnxsTEtH2MiIjIy8vzaETO8F6PAICZM2ey/7OW9tixY722Mnq7x/HjxyNVMjo6+rXXXvN0OM7wao8AgOnTpzOZzPHjx3tzZYT23mM2WqtLNXUVBmmDQae2UOlkpdQIIzwAADCbTFQqFUBaeMQvkKHXmFlcqm8QLSSaEZfOdbQEikt01WNdubboirK+QsMLZPMDOGQqicagUhkUEtlL11shAZtRbzEbLBazVd2iVbdoffzp/Ub69B3YpVb3znuU1OivFUp1Gpt/tC9HwOpKEJ5FI9fL65UWo+l3U/xjku0vh4JKZzzabOD6D611Ip1PKJ8rxLHB9uhUBmm13C+QOn5OYCcGXHbG49ldEqWSHJwgxFAWZ8jqlEalZsaycFd3dNnjvw82K5UUYSQOxmx3DrVUp5Mp8xa51ujpWg0+v6dRperJEgEAXCGLJeAd/LzOpb1c8HjnUqtcThJE9GSJCFwhm+nDvbC/CfsuWD3KGg1lv6mD4nvgPdEufuF8WZO16gHWrnOsHq8XSn1Cen5NbI9fhM/1QhnGwpg8Sp7oW5st/EA4qVrwAoNDp3MZZTcxzd7B5LHoR7k33xaPn/r73//xe3cc2S/Cp/gnTJc2Jo/VJRqufw9533YJJpeuajUrZSbUkugea0VanpBBpnh7y5Cb4Pmzqx6g5/BCX2+vqUbPEbrxzlhUfOHqTwcam6sZDHb/tJzxo+fR6UwAwJ5Dq0kkkBj/wpVrexSq5kD/qCkTl0VFpAEAFMrmIyc2VFbfYTK5Lwya6r7YAAAcIatZjL5UMHota5GYSG5bxbKk7Or+Ix8kxA1eumDf9CkfFJdePvrDRmQThUKtrrlfW1e6eP6e9SvPsdk+3x//BNl08Nh6SVPVG7O3zPvjVxqN/EHZFTeFBwCg0CgtYgNqMXSPGoWZxoCWNuk5Ll/fExs9YMKY+f7CiKSEoS/nLLh7/5xc8Sw/pNGoe3X8YgadRaczB6SPa2p5YjTq5Yqmyqrb2b/7Q3zswKDAmCkTlzEZbrxcaAyKVmVGLYbukUIlURkQWjo7YrVa658+TIgb3PZNbPQAAECDpBL56C+MQK5xAACbxQcAaHXKpuYnAIDI8GeDLEgkUkS4GwdcUBkUJpeK2gqBXtEMOivN5JYZpyaT3mq1XLi8499Xvmv/vVL1LOcqlcrosJPNYNQ+t4lB72SjIRYsJqtGbiKhtcaje+T4UM0G9IrdCWg0JoVCHZ41fUjmq+2/53KcdcXQ6SwAgF6vbvtGp3fjwGezwcLioltCv655fhSTwQIpqv89N5kcFtK3Vd4QGBCN/E/gF0YmU9lsZwuaBQgjAQBPJRXIR4vF/Lj6rjvCQzAbLWw++m0N3WNwJNOkRX9gdY6Rw2c9KLty+VpBU3ON+KnowNF123a+pdc7e18T+IVERaRdvlYgqvxV/FR05MSnVCrNTeEBAHQKQ3BUx9vL86B7jEnlyCVaSFE9T3pK9u+nfVhUfGHTl/nfFiyyWEzzXv+KyUR5/s7M+yjAP/Kf+5bu2POur2/wgIzxNretGaCVaePSuajFMLWHf7+5nhvsx/Gzn1qgB2M2WKpvif/0aQxqSUy/9tKH81XNcPIb4wtFozplKKbVJzG9YCcN5v96rtWgMTI49pN/37x94vT5f9jdZDYZqDT795cZU9elJr2IJQAsVNfc+26fnYz2AACz2Uil0OyOJMh9dVW/tDGOjtnwSDbt7ThHW9uDtZ/r8QP1L/9ShqcF2d2q12u0OvvtdFqdis2y38XO5QjaXrO7jslkUKmlDsJT0+lsu+vXcDh+DLr9pqzGCllsEmXQGEzjYVzoL/xXgcRMZvP8e0Vrrl5jVNRKp7+HtQPWhdaw8XOCpVUygwa9Ma4HUPmT+LXFLsx/cq1VcfaaqMbyJrPRLa/l3kPtvYZZqyNdGqLkmkcKlZS/LLzqZr1a1jOzdxl1poeXn0x+O9A3wP4T1RGdHCd15It6MosljMTBCkXYkdUr5fWKWe9H0pkuN/53frzZbxdkt87LguMFwijv7QLDiLxB3fxYFtePm53nMHOUc7o0/tFitl073lIj0lIZNK6QwwtgUWhuaal0B1aLVS3VqZq1WrkuNJY1Yqo/17fzzdUQxuOajNaaMm15kVrVamkR6xgsKlfINOnd0tTWdZg8mrJJZ9RZeP50Lo+SmMmNTmFjaRlzDuT5XBazTaM0a1UWi8lLp4mRySQWj8zhU2kMmD2g3jsvDl/00l5p6BAe4UB4hAPhEQ6ERzgQHuHw/6dv5ct5mp8JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f23581e3ed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve(state: State):\n",
    "    search_results = retriever.vectorstore.similarity_search(state[\"question\"])\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\n",
    "        \"search_results\": search_results,\n",
    "        \"context\": retrieved_docs\n",
    "    }\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        question=state[\"question\"],\n",
    "        context=docs_content\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07cd5e8-dd99-4539-b1f6-1beeefb656ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'search_results'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c4ce6ad2-f138-4d89-9f78-5fbfd31a5da7'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated ta'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">506</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'069cc00f-92fd-41ae-a8b0-a6a0c63441a4'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">min  |  Author'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">869</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'eb349b95-5398-44f4-8bc7-4c8669d9bb5e'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3d1901df-c520-4c54-8820-b5971f52380c'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system comprises'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">288</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'bcd20973-d3ab-4f4c-9c78-322f66d4f4ca'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7cb07ff1-7542-400a-859c-053b6e43479c'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">possibilities at each'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">min  |  Author'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9646</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and explora'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9609</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">s'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1189</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'search_results'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'c4ce6ad2-f138-4d89-9f78-5fbfd31a5da7'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA \u001b[0m\n",
       "\u001b[32mcomplicated ta'\u001b[0m+\u001b[1;36m506\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'069cc00f-92fd-41ae-a8b0-a6a0c63441a4'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 \u001b[0m\n",
       "\u001b[32mmin  |  Author'\u001b[0m+\u001b[1;36m869\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'eb349b95-5398-44f4-8bc7-4c8669d9bb5e'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'3d1901df-c520-4c54-8820-b5971f52380c'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe \u001b[0m\n",
       "\u001b[32msystem comprises'\u001b[0m+\u001b[1;36m288\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'bcd20973-d3ab-4f4c-9c78-322f66d4f4ca'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'7cb07ff1-7542-400a-859c-053b6e43479c'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning \u001b[0m\n",
       "\u001b[32mpossibilities at each'\u001b[0m+\u001b[1;36m544\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 \u001b[0m\n",
       "\u001b[32mmin  |  Author'\u001b[0m+\u001b[1;36m9646\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory \u001b[0m\n",
       "\u001b[32mand explora'\u001b[0m+\u001b[1;36m9609\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents involves breaking down complex tasks into \u001b[0m\n",
       "\u001b[32ms'\u001b[0m+\u001b[1;36m1189\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller,        \n",
       "manageable subgoals. This process enables the agents to handle intricate problems more effectively by transforming \n",
       "them into simpler steps. There are different approaches to task decomposition:                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Chain of Thought (CoT)</span>: This method prompts the model to \"think step by step,\" enhancing its performance on     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>complex tasks by guiding it to break down larger tasks into manageable components.                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Tree of Thoughts</span>: This approach extends the CoT by exploring multiple reasoning possibilities at each step,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>generating a tree-like structure of potential paths the agent could take.                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">LLM+P</span>: This method involves using an external classical planner to do long-horizon planning. The LLM translates \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>a problem into a Planning Domain Definition Language (PDDL) format, interacts with the planner to generate a    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>plan, and then translates that back into natural language.                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Human Input</span>: Task decomposition can also be guided through task-specific instructions or human input to define  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>the necessary subgoals for achieving the main task.                                                             \n",
       "\n",
       "Overall, task decomposition is crucial as it allows LLM agents to plan effectively and manage complex tasks through\n",
       "a structured approach.                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller,        \n",
       "manageable subgoals. This process enables the agents to handle intricate problems more effectively by transforming \n",
       "them into simpler steps. There are different approaches to task decomposition:                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mChain of Thought (CoT)\u001b[0m: This method prompts the model to \"think step by step,\" enhancing its performance on     \n",
       "\u001b[1;33m   \u001b[0mcomplex tasks by guiding it to break down larger tasks into manageable components.                              \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mTree of Thoughts\u001b[0m: This approach extends the CoT by exploring multiple reasoning possibilities at each step,     \n",
       "\u001b[1;33m   \u001b[0mgenerating a tree-like structure of potential paths the agent could take.                                       \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mLLM+P\u001b[0m: This method involves using an external classical planner to do long-horizon planning. The LLM translates \n",
       "\u001b[1;33m   \u001b[0ma problem into a Planning Domain Definition Language (PDDL) format, interacts with the planner to generate a    \n",
       "\u001b[1;33m   \u001b[0mplan, and then translates that back into natural language.                                                      \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mHuman Input\u001b[0m: Task decomposition can also be guided through task-specific instructions or human input to define  \n",
       "\u001b[1;33m   \u001b[0mthe necessary subgoals for achieving the main task.                                                             \n",
       "\n",
       "Overall, task decomposition is crucial as it allows LLM agents to plan effectively and manage complex tasks through\n",
       "a structured approach.                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(agent_query)\n",
    "response = graph.invoke({\"question\": agent_query})\n",
    "rprint(Pretty(response, max_string=100, no_wrap=False))\n",
    "rprint(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c7b0b5-8c2c-4432-8b6e-70939306b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are main steps for collecting human data?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What are main steps for collecting human data?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'search_results'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'17741deb-555b-42e6-9d3c-d66395f8ef40'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e1ceb846-4f31-499b-82de-5fbb14f27d22'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Two directions to approach high data quality.\\nHuman Raters ‚Üî Data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Quality#\\nCollecting human '</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">645</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8784a472-61c6-4eb8-8475-b914a3c36e86'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e1ceb846-4f31-499b-82de-5fbb14f27d22'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reading Time: 21 mi'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">769</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'395c7e46-0ead-4407-8d94-8bb032ca72f6'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4c32dd6b-d0e0-4cee-b54b-1779b0057a5a'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Or\\n@article{weng2024humandata,\\n  title   = \"Thinking about High-Quality Human Data\",\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">author  = \"We'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">894</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4200a164-5345-40c9-9b5d-829a9286fd90'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'split_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8abfe68d-5cb1-4697-9cd9-e836ee05b300'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'With the input and the inference results, the AI assistant needs to describe the process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and results'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reading Time: 21 mi'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9715</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 10. Influence functions values match leave-one-out training results on 10-class </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MNIST. (Image s'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9320</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'With the input and the inference results, the AI assistant needs to describe the process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and results'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8583</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The main steps for collecting high-quality human data include:\\n\\n1. **Task Design**: Create a clear</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1063</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What are main steps for collecting human data?'\u001b[0m,\n",
       "    \u001b[32m'search_results'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'17741deb-555b-42e6-9d3c-d66395f8ef40'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'e1ceb846-4f31-499b-82de-5fbb14f27d22'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Two directions to approach high data quality.\\nHuman Raters ‚Üî Data \u001b[0m\n",
       "\u001b[32mQuality#\\nCollecting human '\u001b[0m+\u001b[1;36m645\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'8784a472-61c6-4eb8-8475-b914a3c36e86'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'e1ceb846-4f31-499b-82de-5fbb14f27d22'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated \u001b[0m\n",
       "\u001b[32mReading Time: 21 mi'\u001b[0m+\u001b[1;36m769\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'395c7e46-0ead-4407-8d94-8bb032ca72f6'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'4c32dd6b-d0e0-4cee-b54b-1779b0057a5a'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Or\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2024humandata,\\n  title   = \"Thinking about High-Quality Human Data\",\\n \u001b[0m\n",
       "\u001b[32mauthor  = \"We'\u001b[0m+\u001b[1;36m894\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'4200a164-5345-40c9-9b5d-829a9286fd90'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m,\n",
       "                \u001b[32m'split_id'\u001b[0m: \u001b[32m'8abfe68d-5cb1-4697-9cd9-e836ee05b300'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'With the input and the inference results, the AI assistant needs to describe the process \u001b[0m\n",
       "\u001b[32mand results'\u001b[0m+\u001b[1;36m444\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Thinking about High-Quality Human Data\\n    \\nDate: February 5, 2024  |  Estimated \u001b[0m\n",
       "\u001b[32mReading Time: 21 mi'\u001b[0m+\u001b[1;36m9715\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 10. Influence functions values match leave-one-out training results on 10-class \u001b[0m\n",
       "\u001b[32mMNIST. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage s'\u001b[0m+\u001b[1;36m9320\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'With the input and the inference results, the AI assistant needs to describe the process \u001b[0m\n",
       "\u001b[32mand results'\u001b[0m+\u001b[1;36m8583\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'The main steps for collecting high-quality human data include:\\n\\n1. **Task Design**: Create a clear\u001b[0m\n",
       "\u001b[32ma'\u001b[0m+\u001b[1;36m1063\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The main steps for collecting high-quality human data include:                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Task Design</span>: Create a clear and manageable task workflow that enhances understanding and reduces complexity.    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>This may involve developing detailed guidelines, although care should be taken to avoid making them overly      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>complex, as this can require extensive training for annotators.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Select and Train Raters</span>: Identify a pool of annotators with the appropriate skill set and ensure consistency in \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>their performance. This step includes conducting training sessions for the annotators and providing regular     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>feedback and calibration sessions after onboarding.                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Collect and Aggregate Data</span>: This stage involves the actual collection of labeled data. Machine learning         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>techniques can be employed here to clean and filter the data effectively and to smartly aggregate it to identify\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>true labels.                                                                                                    \n",
       "\n",
       "These steps collectively ensure the quality and reliability of the human-annotated data, which serves as a         \n",
       "foundation for training machine learning models, especially in tasks such as classification or reinforcement       \n",
       "learning from human feedback (RLHF) for large language model (LLM) alignment.                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The main steps for collecting high-quality human data include:                                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mTask Design\u001b[0m: Create a clear and manageable task workflow that enhances understanding and reduces complexity.    \n",
       "\u001b[1;33m   \u001b[0mThis may involve developing detailed guidelines, although care should be taken to avoid making them overly      \n",
       "\u001b[1;33m   \u001b[0mcomplex, as this can require extensive training for annotators.                                                 \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mSelect and Train Raters\u001b[0m: Identify a pool of annotators with the appropriate skill set and ensure consistency in \n",
       "\u001b[1;33m   \u001b[0mtheir performance. This step includes conducting training sessions for the annotators and providing regular     \n",
       "\u001b[1;33m   \u001b[0mfeedback and calibration sessions after onboarding.                                                             \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mCollect and Aggregate Data\u001b[0m: This stage involves the actual collection of labeled data. Machine learning         \n",
       "\u001b[1;33m   \u001b[0mtechniques can be employed here to clean and filter the data effectively and to smartly aggregate it to identify\n",
       "\u001b[1;33m   \u001b[0mtrue labels.                                                                                                    \n",
       "\n",
       "These steps collectively ensure the quality and reliability of the human-annotated data, which serves as a         \n",
       "foundation for training machine learning models, especially in tasks such as classification or reinforcement       \n",
       "learning from human feedback (RLHF) for large language model (LLM) alignment.                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(human_data_query)\n",
    "response = graph.invoke({\"question\": human_data_query})\n",
    "rprint(Pretty(response, max_string=100, no_wrap=False))\n",
    "rprint(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
