{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro dlt -> LanceDB Homework"
      ],
      "metadata": {
        "id": "Y2-47Y87jwW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Homework](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/workshops/dlt.md#homework)"
      ],
      "metadata": {
        "id": "hjkkr8_UH0K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "K3VvFlhSbRYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a json -> lancedb pipeline, we need to install:\n",
        "1. dlt with lancedb extras\n",
        "2. sentence-transformers: we need to use an embedding model to vectorize and store data inside LanceDB. For this we choose the open-source model \"sentence-transformers/all-MiniLM-L6-v2\"."
      ],
      "metadata": {
        "id": "OSlHmqELbQHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install dlt[lancedb]==0.5.1a0\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "vcQ6QseXKSHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all for this intro example! The DB could now be used as a basis for a RAG."
      ],
      "metadata": {
        "id": "L4yyirj_kI7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an up-to-date RAG with dlt and LanceDB"
      ],
      "metadata": {
        "id": "-OEpbMGNZexo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will be creating an LLM chat bot that has the latest knowledge of the employee handbook of a fictional company. We will be able to chat to it about specific policies like PTO, work from home etc.\n",
        "\n",
        "To build this, we would need to do three things:\n",
        "1. The company policies exist in a [Notion Page](https://dlthub.notion.site/Employee-handbook-669c2a1e04044465811c8ca22977685d). We will need to first extract the text from these pages.\n",
        "2. Once extracted, we will want to embed them into vectors and then store them in a vector database.\n",
        "3. This will allow us to create our RAG: a function that would accept a user question, match it to the information stored in the vector database, and then send the question + relevant information as input to the LLM."
      ],
      "metadata": {
        "id": "Jh5v8-J8DcfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the following OSS tools for this:\n",
        "1. dlt for data ingestion:  \n",
        "  1. dlt can easily connect to any REST API source (like Notion)\n",
        "  2. It also has integrations with vector databases, like LanceDB.\n",
        "  3. It also allows to easily plug in functionality like incremental loading.\n",
        "2. LanceDB as a vector database:\n",
        "  1. LanceDB is an open-source vector database that is very easy to use and integrate into python workflows\n",
        "  2. It is in-process and serverless (like DuckDB), which makes querying and retreival very efficient\n",
        "3. Ollama for RAG:\n",
        "  1. Ollama is open-source and allows you to easily run LLMs locally"
      ],
      "metadata": {
        "id": "ZcObJq25L8o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note on running this notebook**: We are going to download and use a local Ollama instance for the RAG, so preferably select the **T4 GPU** in the runtime when starting this notebook (Runtime > Change runtime type > Hardware accelerator > T4 GPU).\n",
        "\n",
        "You can also use the default CPU in case you're facing technical issues, but then your LLM responses might be slower (~2 mins/response)"
      ],
      "metadata": {
        "id": "zQUsxggP0tje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Create a Notion -> LanceDB pipeline using dlt"
      ],
      "metadata": {
        "id": "pAGJAVLzZCDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install requirements"
      ],
      "metadata": {
        "id": "b5zDmfFcwS5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a notion -> lancedb pipeline, we need to install:\n",
        "1. dlt with lancedb extras\n",
        "2. sentence-transformers: we need to use an embedding model to vectorize and store data inside LanceDB. For this we choose the open-source model \"sentence-transformers/all-MiniLM-L6-v2\"."
      ],
      "metadata": {
        "id": "aOUpcKhnwggh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install dlt[lancedb]==0.5.1a0\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "4AVm0h1rjv8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create a dlt project with rest_api source and lancedb destination"
      ],
      "metadata": {
        "id": "_aqwtE-Owslg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a dlt project using the command `dlt init <source> <destination>`."
      ],
      "metadata": {
        "id": "sS6gu1f_cO7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This downloads all the modules required for the dlt source (rest api, in this case) into the local directory. See the side panel for the directory structure created."
      ],
      "metadata": {
        "id": "WFaBpJwzhkdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the dlt rest api source?\n",
        "\n",
        "It is a dlt source that allows you to connect to any REST API endpoint using a declarative configuration. You can:\n",
        "- pass the endpoints that you want to connect to,\n",
        "- define the relation between the endpoints\n",
        "- define how you want to handle pagination and authentication"
      ],
      "metadata": {
        "id": "LD-Mfzl4hmsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yes | dlt init rest_api lancedb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn5QwziOjqT9",
        "outputId": "49af563c-3100-434b-823f-f78d2ac676bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking up the init scripts in \u001b[1mhttps://github.com/dlt-hub/verified-sources.git\u001b[0m...\n",
            "Cloning and configuring a verified source \u001b[1mrest_api\u001b[0m (Generic API Source)\n",
            "Do you want to proceed? [Y/n]: \n",
            "Verified source \u001b[1mrest_api\u001b[0m was added to your project!\n",
            "* See the usage examples and code snippets to copy from \u001b[1mrest_api_pipeline.py\u001b[0m\n",
            "* Add credentials for \u001b[1mlancedb\u001b[0m and other secrets in \u001b[1m./.dlt/secrets.toml\u001b[0m\n",
            "* \u001b[1mrequirements.txt\u001b[0m was created. Install it with:\n",
            "pip3 install -r requirements.txt\n",
            "* Read \u001b[1mhttps://dlthub.com/docs/walkthroughs/create-a-pipeline\u001b[0m for more information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Add API credentials"
      ],
      "metadata": {
        "id": "NqjfumInhWLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access APIs, databases, or any third-party applications, one might need to specify relevant credentials.\n",
        "\n",
        "With dlt, we can do it in two ways:\n",
        "1. Pass the credentials and any other sensitive information inside `.dlt/secrets.toml`\n",
        "  ```toml\n",
        "  [sources.rest_api.notion]\n",
        "  api_key = \"notion api key\"\n",
        "\n",
        "  [destination.lancedb]\n",
        "  embedding_model_provider = \"sentence-transformers\"\n",
        "  embedding_model = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "  [destination.lancedb.credentials]\n",
        "  uri = \".lancedb\"\n",
        "  api_key = \"api_key\"\n",
        "  embedding_model_provider_api_key = \"embedding_model_provider_api_key\"\n",
        "  ```\n",
        "2. Pass them as environment variables\n",
        "  ```python\n",
        "  import os\n",
        "  \n",
        "  os.environ[\"SOURCES__REST_API__NOTION__API_KEY\"] = \"notion api key\"\n",
        "\n",
        "  os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__API_KEY\"] = \"api_key\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__EMBEDDING_MODEL_PROVIDER_API_KEY\"] = \"embedding_model_provider_api_key\"\n",
        "  ```"
      ],
      "metadata": {
        "id": "LGO2s0xwlOMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to be using option 2. It's not advisable to paste sensitive information like API keys inside the code, so instead we're going to include them inside the secrets tab in the side panel of the notebook. This will allow us to access the secret values from the notebook.\n",
        "\n",
        "Since we are using the OSS version of LanceDB and OSS embedding models, we only need to specify the API key for Notion.\n",
        "\n",
        "**Note**: You will need to copy the [notion API key](https://share.1password.com/s#da9KgMwPaZUaey3WCaD7ICJoyHDGd3Xos2EZ29WrSWQ) into the secrets tab under the name `SOURCES__REST_API__NOTION__API_KEY`. Make sure to enable notebook access after pasting the key."
      ],
      "metadata": {
        "id": "J1nF956xoqyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"SOURCES__REST_API__NOTION__API_KEY\"] = userdata.get(\"SOURCES__REST_API__NOTION__API_KEY\")\n",
        "\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\""
      ],
      "metadata": {
        "id": "vSLP6qhNqafV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Write the pipeline code"
      ],
      "metadata": {
        "id": "Eg9ySPDHtYLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: We first go over the code step by step before putting it into runnable cells\n",
        "\n",
        "1. Import necessary modules (run this cell)"
      ],
      "metadata": {
        "id": "0PuHEBIVtl-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlt\n",
        "from rest_api import RESTAPIConfig, rest_api_source\n",
        "\n",
        "from dlt.sources.helpers.rest_client.paginators import BasePaginator, JSONResponsePaginator\n",
        "from dlt.sources.helpers.requests import Response, Request\n",
        "\n",
        "from dlt.destinations.adapters import lancedb_adapter"
      ],
      "metadata": {
        "id": "BiA7UEAmtoFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Configure the dlt rest api source to connect to and extract the relevant data out from the Notion REST API.\n",
        "\n",
        "  Our notion space has multiple pages and each page has multiple paragraphs (called blocks). To extract all this data from the Notion API, we would first need to get a list of all the page_ids (each page has a unique page_id), and then use the page_id to request the contents from the individual pages. Specifically:\n",
        "  1. We will first request the page_ids from the `/search` endpoint\n",
        "  2. And then using the returned page_ids, we will request the contents from the `/blocks/{page_id}/children` endpoint\n",
        "\n",
        "  With this in mind, we can configure the dlt notion rest api source as follows:\n",
        "  ```python\n",
        "  RESTAPIConfig = {\n",
        "        \"client\": {\n",
        "            \"base_url\": \"https://api.notion.com/v1/\",\n",
        "            \"auth\": {\n",
        "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
        "            },\n",
        "            \"headers\":{\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Notion-Version\": \"2022-06-28\"\n",
        "            }\n",
        "        },\n",
        "        \"resources\": [\n",
        "            {\n",
        "                \"name\": \"search\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"search\",\n",
        "                    \"method\": \"POST\",\n",
        "                    \"paginator\": PostBodyPaginator(),\n",
        "                    \"json\": {\n",
        "                        \"query\": \"workshop\",\n",
        "                        \"sort\": {\n",
        "                            \"direction\": \"ascending\",\n",
        "                            \"timestamp\": \"last_edited_time\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"data_selector\": \"results\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"page_content\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"blocks/{page_id}/children\",\n",
        "                    \"paginator\": JSONResponsePaginator(),\n",
        "                    \"params\": {\n",
        "                        \"page_id\": {\n",
        "                            \"type\": \"resolve\",\n",
        "                            \"resource\": \"search\",\n",
        "                            \"field\": \"id\"\n",
        "                        }\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    ```\n",
        "    Explanation:\n",
        "    1. `client`: Here we added our base url, headers, and authentication\n",
        "    2. `resources`: This is a list of endpoints that we wish to request data from (here: `/search` and `/blocks/{page_id}/children`)\n",
        "    3. [`/search`](https://developers.notion.com/reference/post-search) endpoint:\n",
        "      - The Notion API search endpoint allows us to filter pages based on the title. We can specify which pages we want returned based on the parameter \"query\". For example, if we'd like to return only those pages which has the word \"workshop\" in the title, then we would set `\"query\": \"workshop\"` in the json body.    \n",
        "      - As a response, it returns only page metadata (like page_id). Example response:\n",
        "      ```json\n",
        "          {\n",
        "            \"object\": \"list\",\n",
        "            \"results\": [\n",
        "              {\n",
        "                \"object\": \"page\",\n",
        "                \"id\": \"954b67f9-3f87-41db-8874-23b92bbd31ee\",\n",
        "                \"created_time\": \"2022-07-06T19:30:00.000Z\",\n",
        "                \"last_edited_time\": \"2022-07-06T19:30:00.000Z\",\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "            ],\n",
        "            \"next_cursor\": null,\n",
        "            \"has_more\": false,\n",
        "            \"type\": \"page_or_database\",\n",
        "            \"page_or_database\": {}\n",
        "          }\n",
        "      ```\n",
        "      - This is how we would define our endpoint configuration for `/search`:\n",
        "      ```python\n",
        "           {\n",
        "             \"name\": \"search\",\n",
        "             \"endpoint\": {\n",
        "                 \"path\": \"search\",\n",
        "                 \"method\": \"POST\",\n",
        "                 \"paginator\": PostBodyPaginator(),\n",
        "                 \"json\": {\n",
        "                     \"query\": \"workshop\",\n",
        "                     \"sort\": {\n",
        "                         \"direction\": \"ascending\",\n",
        "                         \"timestamp\": \"last_edited_time\"\n",
        "                     }\n",
        "                 },\n",
        "                 \"data_selector\": \"results\"\n",
        "             }\n",
        "         },\n",
        "      ```\n",
        "      - `paginator` allows us to specify the pagination strategy relevant for the API and the endpoint. (More on this later)\n",
        "      - Since `/search` is a POST endpoint, we can include the json body inside the key `json`.\n",
        "      - We don't need the whole JSON response, but only the contents inside the field \"results\". We filter this out by specifying `\"data_selector\": \"results\"`.\n",
        "    4. [`blocks/{page_id}/children`](https://developers.notion.com/reference/get-block-children) endpoint:\n",
        "      - This is a GET point that returns a list of block objects (in our case, paragraphs) from a specific page.\n",
        "      - Since it accepts page_id as a parameter, we can pass this inside the key `params`\n",
        "      - We would like to be able to automatically fetch the page_ids returned from the `/search` endpoint and pass it as parameter into the endpoint `blocks/{page_id}/children`. We can do this by linking the two resources as follows:\n",
        "      ```python\n",
        "      {\n",
        "            \"name\": \"page_content\",\n",
        "            \"endpoint\": {\n",
        "                \"path\": \"blocks/{page_id}/children\",\n",
        "                \"paginator\": JSONResponsePaginator(),\n",
        "                \"params\": {\n",
        "                    \"page_id\": {\n",
        "                        \"type\": \"resolve\",\n",
        "                        \"resource\": \"search\",\n",
        "                        \"field\": \"id\"\n",
        "                    }\n",
        "                },\n",
        "            }\n",
        "      }\n",
        "      ```\n",
        "      - By specifying `\"type\":\"resolve\"`, we are letting dlt know that this parameter needs to be resolved from the parent resource `\"search\"` using the field `\"id\"`, which corresponds to the page id in the response of `/search`."
      ],
      "metadata": {
        "id": "-xcvRa42rZoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Note on pagination:\n",
        "\n",
        "  Different REST APIs might use different strategies to handle paginated responses. dlt has built-in support for [most common pagination mechanisms](https://dlthub.com/docs/general-usage/http/rest-client#paginators), and these can be explicity passed inside the configuration like shown above.\n",
        "\n",
        "  However in most cases, it won't be necessary to explicity specify the pagination strategy, since dlt detects it automatically.\n",
        "\n",
        "  In case the specific pagination is not supported by dlt yet, then you can also implement a custom paginator. For example, dlt does not have a built-in paginator for POST methods, so we write our own paginator. We take the [code provided in the docs for it](https://dlthub.com/docs/general-usage/http/rest-client#example-2-creating-a-paginator-for-post-requests), and make small modifications to it based on the [notion API documentation](https://developers.notion.com/reference/intro#parameters-for-paginated-requests).\n",
        "\n",
        "  ```python\n",
        "  class PostBodyPaginator(BasePaginator):\n",
        "      def __init__(self):\n",
        "          super().__init__()\n",
        "          self.cursor = None\n",
        "\n",
        "      def update_state(self, response: Response) -> None:\n",
        "          # Assuming the API returns an empty list when no more data is available\n",
        "          if not response.json():\n",
        "              self._has_next_page = False\n",
        "          else:\n",
        "              self.cursor = response.json().get(\"next_cursor\")\n",
        "              if self.cursor is None:\n",
        "                  self._has_next_page = False\n",
        "\n",
        "      def update_request(self, request: Request) -> None:\n",
        "          if request.json is None:\n",
        "              request.json = {}\n",
        "\n",
        "          # Add the cursor to the request body\n",
        "          request.json[\"start_cursor\"] = self.cursor\n",
        "  ```"
      ],
      "metadata": {
        "id": "LcJenlTNsBKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Extract relevant content from the response body\n",
        "\n",
        "  The response returned from the API is a nested JSON which we need to pre-process before using it anywhere. dlt can unnest json automatically, but since the Notion API is a little tricky it's better to pre-process this first so we have a more structured DB as a result.\n",
        "  \n",
        "  One way to do this is to pass the JSON response through a transformation function that will extract only the relevant data from the JSON body (we later add this as a mapping to the resource):\n",
        "\n",
        "  ```python\n",
        "  def extract_page_content(response):\n",
        "      block_id = response[\"id\"]\n",
        "      last_edited_time = response[\"last_edited_time\"]\n",
        "      block_type = response.get(\"type\", \"Not paragraph\")\n",
        "      if block_type != \"paragraph\":\n",
        "          content = \"\"\n",
        "      else:\n",
        "          try:\n",
        "              content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
        "          except IndexError:\n",
        "              content = \"\"\n",
        "      return {\n",
        "          \"block_id\": block_id,\n",
        "          \"block_type\": block_type,\n",
        "          \"content\": content,\n",
        "          \"last_edited_time\": last_edited_time,\n",
        "          \"inserted_at_time\": datetime.now(timezone.utc)\n",
        "      }\n",
        "  ```\n",
        "  This is also where you could implement some sort of chunking strategy, but we will omit this in this example as the Notion text is already pre-chunked into paragraphs. Any data pre-processing can also happen here.\n",
        "\n",
        "  **Note**: If you want to include the parent page in the returned data, you can do so by including `response[\"parent\"][\"page_id\"]`. See 200 response example in the [Notion docs](https://developers.notion.com/reference/get-block-children).\n",
        "  \n",
        "  JSON response before the function:\n",
        "  ```\n",
        "  {\n",
        "      \"object\": \"list\",\n",
        "      \"results\": [\n",
        "        {\n",
        "          \"object\": \"block\",\n",
        "          \"id\": \"c02fc1d3-db8b-45c5-a222-27595b15aea7\",\n",
        "          \"created_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "          \"last_edited_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "          .\n",
        "          .\n",
        "          .\n",
        "          \"type\": \"paragraph\",\n",
        "          \"paragraph\": {\n",
        "            \"rich_text\": [\n",
        "              {\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "                \"annotations\": {\n",
        "                  .\n",
        "                  .\n",
        "                  .\n",
        "\n",
        "                },\n",
        "                \"plain_text\": \"Lacinato kale is a variety of kale with a long tradition in Italian cuisine, especially that of Tuscany. It is also known as Tuscan kale, Italian kale, dinosaur kale, kale, flat back kale, palm tree kale, or black Tuscan palm.\",\n",
        "                \"href\": \"https://en.wikipedia.org/wiki/Lacinato_kale\"\n",
        "              }\n",
        "            ],\n",
        "            \"color\": \"default\"\n",
        "          }\n",
        "        }\n",
        "      ],\n",
        "      \"next_cursor\": null,\n",
        "      \"has_more\": false,\n",
        "      \"type\": \"block\",\n",
        "      \"block\": {}\n",
        "  }\n",
        "  ```\n",
        "  After passing it through the transformation function:\n",
        "\n",
        "  ```\n",
        "  {\n",
        "      \"block_id\": \"c02fc1d3-db8b-45c5-a222-27595b15aea7\",\n",
        "      \"block_type\": \"paragraph\",\n",
        "      \"content\": \"Lacinato kale is a variety of kale with a long tradition in Italian cuisine, especially that of Tuscany. It is also known as Tuscan kale, Italian kale, dinosaur kale, kale, flat back kale, palm tree kale, or black Tuscan palm.\",\n",
        "      \"last_edited_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "  }\n",
        "\n",
        "    ```"
      ],
      "metadata": {
        "id": "tCeKKPz6spg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Load the data incrementally\n",
        "\n",
        "  Incremental loading is a very important aspect of building scalable data pipelines. It is the technique of loading only the new or changed data since the last run of the pipeline.\n",
        "\n",
        "  In our case, when we first run the pipeline, all paragraphs from the employee handbook will get loaded as separate rows inside a lancedb table. Now if we change the content of one of the paragraphs and re-run the pipeline to update the table, then without doing incremental loading, one of two things may happen depending on the option we choose:\n",
        "  - If we choose the option \"replace\", then the existing data in lancedb will be dropped, and all of the paragraphs will be reloaded.\n",
        "  - If we choose the option \"append\", then the existing rows would remain and all of the paragraphs would be loaded again as new rows resulting in twice as many rows\n",
        "\n",
        "  To ensure that only the new/changed rows are loaded we would need the following pieces:\n",
        "  - A column that can keep track of changes in the row (Example: only load rows where `last_edited_time` is greater than the current maximum `last_edited_time`)\n",
        "  - A primary_key column that uniquely identify a row, so it's possible to track when the row changes\n",
        "  - A strategy to resolve changes in a single row (example: drop current and load the changed row)\n",
        "\n",
        "  This behaviour can be configured easily into a dlt rersource:\n",
        "  - Pass the incremental column as a parameter inside the resource\n",
        "    ```python\n",
        "    def rest_api_notion_incremental(\n",
        "      last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "    ):\n",
        "    ```\n",
        "    We choose the column `last_edited_time` since it keeps track of whenever a paragraph changes.\n",
        "  - Pass the following arguments inside `@dlt.resource` to define the strategy for dealing with duplicate rows:\n",
        "    - `write_disposition=\"merge\"`: ensures that any duplicate rows are merged on the primary key\n",
        "    - `primary_key=\"block_id\"`: specifies the primary key that we'd like to merge on. In our case, this is `block_id`, which is a unique id corresponding to each block (paragraph).\n",
        "    - `columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}`: this specifies the deduplication strategy (how we would like to resolve duplicate rows). Here we chose to keep the row with the largest value of `last_edited_time`.\n",
        "\n",
        "    Putting it together:\n",
        "\n",
        "    ```python\n",
        "    @dlt.resource(\n",
        "        name=\"employee_handbook\",\n",
        "        write_disposition=\"merge\",\n",
        "        primary_key=\"block_id\",\n",
        "        columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
        "    )\n",
        "    def rest_api_notion_incremental(\n",
        "        last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "    ):\n",
        "        for block in rest_api_notion_resource.add_map(extract_page_content):   \n",
        "            if not(len(block[\"content\"])):\n",
        "                continue\n",
        "            yield block\n",
        "  ```\n",
        "  Here, `rest_api_notion_resoure` yields the JSON response from the Notion REST API and `extract_page_content` is the transformation function that we pass the JSON response through."
      ],
      "metadata": {
        "id": "eTGdAXpKs8Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create the pipeline and run it\n",
        "\n",
        "  With our source configured, we can now define the pipeline and run it.\n",
        "\n",
        "  Normally, to do this we would run  \n",
        "  ```python\n",
        "  pipeline.run(\n",
        "    rest_api_notion_incremental,\n",
        "    table_name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\"\n",
        "  )\n",
        "  ```\n",
        "  and this would load the data into lancedb normally, without creating any embeddings.\n",
        "\n",
        "  However, we can have lancedb automatically create embeddings and load it along with the normal data using dlt's native adapter for lancedb: `lancedb_adapter`. It will use the embedding model that we specified in the credentials.   \n",
        "    \n",
        "  ```python\n",
        "  pipeline.run(\n",
        "    lancedb_adapter(\n",
        "      rest_api_notion_incremental,\n",
        "      embed=\"content\" # The column that we'd like to embed\n",
        "    )\n",
        "    table_name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\"\n",
        "  )\n",
        "  ```"
      ],
      "metadata": {
        "id": "-dJlkDX0tSvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Run the pipeline"
      ],
      "metadata": {
        "id": "Ll95duMkuKDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this block:"
      ],
      "metadata": {
        "id": "66l6khvmpDAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "class PostBodyPaginator(BasePaginator):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cursor = None\n",
        "\n",
        "    def update_state(self, response: Response) -> None:\n",
        "        # Assuming the API returns an empty list when no more data is available\n",
        "        if not response.json():\n",
        "            self._has_next_page = False\n",
        "        else:\n",
        "            self.cursor = response.json().get(\"next_cursor\")\n",
        "            if self.cursor is None:\n",
        "                self._has_next_page = False\n",
        "\n",
        "    def update_request(self, request: Request) -> None:\n",
        "        if request.json is None:\n",
        "            request.json = {}\n",
        "\n",
        "        # Add the cursor to the request body\n",
        "        request.json[\"start_cursor\"] = self.cursor\n",
        "\n",
        "@dlt.resource(name=\"employee_handbook\")\n",
        "def rest_api_notion_resource():\n",
        "    notion_config: RESTAPIConfig = {\n",
        "        \"client\": {\n",
        "            \"base_url\": \"https://api.notion.com/v1/\",\n",
        "            \"auth\": {\n",
        "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
        "            },\n",
        "            \"headers\":{\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Notion-Version\": \"2022-06-28\"\n",
        "            }\n",
        "        },\n",
        "        \"resources\": [\n",
        "            {\n",
        "                \"name\": \"search\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"search\",\n",
        "                    \"method\": \"POST\",\n",
        "                    \"paginator\": PostBodyPaginator(),\n",
        "                    \"json\": {\n",
        "                        \"query\": \"homework\",\n",
        "                        \"sort\": {\n",
        "                            \"direction\": \"ascending\",\n",
        "                            \"timestamp\": \"last_edited_time\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"data_selector\": \"results\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"page_content\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"blocks/{page_id}/children\",\n",
        "                    \"paginator\": JSONResponsePaginator(),\n",
        "                    \"params\": {\n",
        "                        \"page_id\": {\n",
        "                            \"type\": \"resolve\",\n",
        "                            \"resource\": \"search\",\n",
        "                            \"field\": \"id\"\n",
        "                        }\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    yield from rest_api_source(notion_config,name=\"employee_handbook\")\n",
        "\n",
        "def extract_page_content(response):\n",
        "    block_id = response[\"id\"]\n",
        "    last_edited_time = response[\"last_edited_time\"]\n",
        "    block_type = response.get(\"type\", \"Not paragraph\")\n",
        "    if block_type != \"paragraph\":\n",
        "        content = \"\"\n",
        "    else:\n",
        "        try:\n",
        "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
        "        except IndexError:\n",
        "            content = \"\"\n",
        "    return {\n",
        "        \"block_id\": block_id,\n",
        "        \"block_type\": block_type,\n",
        "        \"content\": content,\n",
        "        \"last_edited_time\": last_edited_time,\n",
        "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
        "    }\n",
        "\n",
        "@dlt.resource(\n",
        "    name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\",\n",
        "    primary_key=\"block_id\",\n",
        "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
        "    )\n",
        "def rest_api_notion_incremental(\n",
        "    last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "):\n",
        "    # last_value = last_edited_time.last_value\n",
        "    # print(last_value)\n",
        "\n",
        "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
        "        if not(len(block[\"content\"])):\n",
        "            continue\n",
        "        yield block\n",
        "\n",
        "def load_notion() -> None:\n",
        "    pipeline = dlt.pipeline(\n",
        "        pipeline_name=\"company_policies\",\n",
        "        destination=\"lancedb\",\n",
        "        dataset_name=\"notion_pages\",\n",
        "        # full_refresh=True\n",
        "    )\n",
        "\n",
        "    load_info = pipeline.run(\n",
        "        lancedb_adapter(\n",
        "            rest_api_notion_incremental,\n",
        "            embed=\"content\"\n",
        "        ),\n",
        "        table_name=\"homework\",\n",
        "        write_disposition=\"merge\"\n",
        "    )\n",
        "    print(load_info)\n",
        "\n",
        "load_notion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RzeKOoNUsyL",
        "outputId": "23812085-d204-4c2a-d9b7-22aa8580e04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline company_policies load step completed in ---\n",
            "0 load package(s) were loaded to destination LanceDB and into dataset None\n",
            "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7fb0d3fcbb80> location to store data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Visualize the output"
      ],
      "metadata": {
        "id": "ps09cty1uN9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lancedb\n",
        "\n",
        "db = lancedb.connect(\"./.lancedb\")\n",
        "print(db.table_names())"
      ],
      "metadata": {
        "id": "amkwwbdk6OS7",
        "outputId": "c72109d4-904e-4be9-9c20-ec08c61a7282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['notion_pages____dlt_loads', 'notion_pages____dlt_pipeline_state', 'notion_pages____dlt_version', 'notion_pages___dltSentinelTable', 'notion_pages___homework']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lancedb\n",
        "\n",
        "db = lancedb.connect(\".lancedb\")\n",
        "dbtable = db.open_table(\"notion_pages___homework\")\n",
        "\n",
        "dbtable.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B7hsT5i8Y24S",
        "outputId": "b8e69e18-430c-4595-d8b5-dd628ad1fbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    id__  \\\n",
              "0   c69f1ecf-7b02-5810-8286-3f42659ae9d4   \n",
              "1   f2c18ac0-50f5-5b72-a871-dc5a46780353   \n",
              "2   4553193e-c655-54df-9a33-cfc570bf34d0   \n",
              "3   791be1a1-6c67-530d-87ab-bd9912500ea5   \n",
              "4   a83497f4-922c-5d62-bab1-53804e93c811   \n",
              "5   434b71e9-a11a-519d-a9fe-e3ade78d47d6   \n",
              "6   17816363-54b7-5ba7-b8d5-06d871a25414   \n",
              "7   2a434cf9-09d9-5514-a88b-02977f2f953e   \n",
              "8   5f9384fa-7f98-5f52-a06e-05b05f42f69a   \n",
              "9   42af72f6-9db7-54a2-87b2-d466169078ff   \n",
              "10  8bfc36ce-cdb0-5792-bd70-d12ff22fc227   \n",
              "11  b1737a97-6dca-564c-a169-78e306a5e124   \n",
              "12  896f7ed8-e918-54f3-a7b8-565d53d6d22b   \n",
              "13  3557e3dd-de5b-51b9-bdee-b53ba588ed60   \n",
              "14  c51f99bf-5057-572e-bf9e-25dc03014c79   \n",
              "15  0317522c-a6db-59e8-ba5f-5ff0dc960d2e   \n",
              "16  4d0eb4d7-f0ad-517c-8165-7eb7932ea0ed   \n",
              "\n",
              "                                             vector__  \\\n",
              "0   [-0.024265623, 0.04746083, -0.011796438, 0.063...   \n",
              "1   [-0.049661573, 0.10853516, -0.0097625945, -0.0...   \n",
              "2   [-0.06316319, 0.17331506, 0.025351718, -0.0191...   \n",
              "3   [-0.10974315, 0.10586075, 0.0032906067, -0.021...   \n",
              "4   [0.052423306, -0.06457594, 0.065863, 0.0145438...   \n",
              "5   [0.0005233448, -0.054883398, 0.043573365, -0.0...   \n",
              "6   [0.03802632, -0.021509668, 0.0475278, 0.064706...   \n",
              "7   [-0.058588073, -0.07540443, 0.033775173, 0.009...   \n",
              "8   [-0.01359926, 0.004753031, 0.024835143, 0.0159...   \n",
              "9   [0.032060914, 0.02424462, 0.008471355, 0.03179...   \n",
              "10  [-0.013155272, 0.008382475, 0.017044408, 0.051...   \n",
              "11  [0.027987445, 0.06734361, 0.039806426, 0.00774...   \n",
              "12  [0.03252609, 0.008159482, 0.084435634, 0.05564...   \n",
              "13  [-0.0073140753, 0.01471069, -0.019091198, 0.02...   \n",
              "14  [-0.031538416, 0.034259938, -0.027282655, 0.02...   \n",
              "15  [-0.017366918, 0.06079061, 0.015769996, -0.014...   \n",
              "16  [0.033655427, 0.035742376, 0.039310906, 0.0037...   \n",
              "\n",
              "                                block_id block_type  \\\n",
              "0   a8196881-ae94-4767-8767-92fe1a327d24  paragraph   \n",
              "1   31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8  paragraph   \n",
              "2   da7721fd-3d0f-4c04-bc5e-825ad60bed1c  paragraph   \n",
              "3   ff36dcf3-5faa-40b4-ad8e-92fdc952201e  paragraph   \n",
              "4   a1ff9697-4bb6-4f1e-b464-dda296dbd307  paragraph   \n",
              "5   e4ec9f4d-b687-4c28-a80d-985bfabcc2ba  paragraph   \n",
              "6   e6e550dc-b59e-4928-abd7-07eace948681  paragraph   \n",
              "7   a269d0ca-ce14-481b-a5f4-9192d6840d6e  paragraph   \n",
              "8   5b65f3e7-0a37-429a-818d-f99b53755ebd  paragraph   \n",
              "9   b27f7d80-f2f1-460e-aa0c-b8e770cf050a  paragraph   \n",
              "10  cf2c7276-9d6d-4611-97ef-e7707a668176  paragraph   \n",
              "11  79fd88bb-894c-4db3-961e-f2e9fa571399  paragraph   \n",
              "12  0b5f3660-7867-41ea-ae25-95585c3bb34e  paragraph   \n",
              "13  3153e9cf-44bf-4ec1-b835-67d37731f9bc  paragraph   \n",
              "14  b9d67165-1028-4edc-841b-fe2fd4cf0cf7  paragraph   \n",
              "15  72d2f585-a1b4-461e-ad88-45d9e3346425  paragraph   \n",
              "16  b1a9a976-eef2-4c99-9f57-3e5adb873d1f  paragraph   \n",
              "\n",
              "                                              content  \\\n",
              "0   We owe our success to our employees. To show o...   \n",
              "1   We want to ensure that private information abo...   \n",
              "2   Employee health is important to us. We don’t d...   \n",
              "3   Our company is dedicated to maintaining a safe...   \n",
              "4   If your job doesn’t require you to be present ...   \n",
              "5   Remote working refers to working from a non-of...   \n",
              "6   There are some expenses that we will pay direc...   \n",
              "7   Our company operates between 9 a.m. to 7 p.m. ...   \n",
              "8   In this section, we are going to be covering i...   \n",
              "9   Our company observes the following holidays: N...   \n",
              "10  These holidays are considered “off-days” for m...   \n",
              "11  Employees who are unable to work due to illnes...   \n",
              "12  Losing a loved one is traumatizing. If this ha...   \n",
              "13  In accordance with German law, we offer a comp...   \n",
              "14  We recognize the vital role that fathers and p...   \n",
              "15  Our company’s official dress code is Business ...   \n",
              "16  If you want to invite a visitor to our offices...   \n",
              "\n",
              "            last_edited_time                 inserted_at_time  \\\n",
              "0  2024-07-05 22:34:00+00:00 2024-07-21 10:43:05.060918+00:00   \n",
              "1  2024-07-05 22:38:00+00:00 2024-07-21 10:43:05.065262+00:00   \n",
              "2  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.065569+00:00   \n",
              "3  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.065791+00:00   \n",
              "4  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.065981+00:00   \n",
              "5  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.066171+00:00   \n",
              "6  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.066367+00:00   \n",
              "7  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.066627+00:00   \n",
              "8  2024-07-05 23:33:00+00:00 2024-07-21 10:43:05.066841+00:00   \n",
              "9  2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067012+00:00   \n",
              "10 2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067180+00:00   \n",
              "11 2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067352+00:00   \n",
              "12 2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067508+00:00   \n",
              "13 2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067722+00:00   \n",
              "14 2024-07-05 22:52:00+00:00 2024-07-21 10:43:05.067879+00:00   \n",
              "15 2024-07-05 22:54:00+00:00 2024-07-21 10:43:05.068035+00:00   \n",
              "16 2024-07-05 22:56:00+00:00 2024-07-21 10:43:05.068215+00:00   \n",
              "\n",
              "          _dlt_load_id         _dlt_id  \n",
              "0   1721558583.8761644  tl3dhTtbCp9NPw  \n",
              "1   1721558583.8761644  58ioty7WYvD07w  \n",
              "2   1721558583.8761644  hO5DTnhAhaaMbw  \n",
              "3   1721558583.8761644  moII/39WSveMyA  \n",
              "4   1721558583.8761644  rFsNpM6igE2SMQ  \n",
              "5   1721558583.8761644  yJOQ15t++4Ro/Q  \n",
              "6   1721558583.8761644  rxR+mm/QbjOWPA  \n",
              "7   1721558583.8761644  37mwN1my3uGsdg  \n",
              "8   1721558583.8761644  fP0Hz2jGjezd4w  \n",
              "9   1721558583.8761644  1AM/USyy6+56Yg  \n",
              "10  1721558583.8761644  XM0EEEF8nyiFZA  \n",
              "11  1721558583.8761644  VsKSXPyZ67wIfQ  \n",
              "12  1721558583.8761644  OKcT1jmX5nHjCQ  \n",
              "13  1721558583.8761644  NALmVckz4ymE+w  \n",
              "14  1721558583.8761644  j4RxikbP56HFMA  \n",
              "15  1721558583.8761644  niav/YzwjJNT9A  \n",
              "16  1721558583.8761644  EKnVyAvxMmPmMQ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7391fc0-0a17-406b-9c5e-f4ea269caf04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id__</th>\n",
              "      <th>vector__</th>\n",
              "      <th>block_id</th>\n",
              "      <th>block_type</th>\n",
              "      <th>content</th>\n",
              "      <th>last_edited_time</th>\n",
              "      <th>inserted_at_time</th>\n",
              "      <th>_dlt_load_id</th>\n",
              "      <th>_dlt_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c69f1ecf-7b02-5810-8286-3f42659ae9d4</td>\n",
              "      <td>[-0.024265623, 0.04746083, -0.011796438, 0.063...</td>\n",
              "      <td>a8196881-ae94-4767-8767-92fe1a327d24</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We owe our success to our employees. To show o...</td>\n",
              "      <td>2024-07-05 22:34:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.060918+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>tl3dhTtbCp9NPw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f2c18ac0-50f5-5b72-a871-dc5a46780353</td>\n",
              "      <td>[-0.049661573, 0.10853516, -0.0097625945, -0.0...</td>\n",
              "      <td>31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We want to ensure that private information abo...</td>\n",
              "      <td>2024-07-05 22:38:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.065262+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>58ioty7WYvD07w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4553193e-c655-54df-9a33-cfc570bf34d0</td>\n",
              "      <td>[-0.06316319, 0.17331506, 0.025351718, -0.0191...</td>\n",
              "      <td>da7721fd-3d0f-4c04-bc5e-825ad60bed1c</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Employee health is important to us. We don’t d...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.065569+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>hO5DTnhAhaaMbw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>791be1a1-6c67-530d-87ab-bd9912500ea5</td>\n",
              "      <td>[-0.10974315, 0.10586075, 0.0032906067, -0.021...</td>\n",
              "      <td>ff36dcf3-5faa-40b4-ad8e-92fdc952201e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company is dedicated to maintaining a safe...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.065791+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>moII/39WSveMyA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a83497f4-922c-5d62-bab1-53804e93c811</td>\n",
              "      <td>[0.052423306, -0.06457594, 0.065863, 0.0145438...</td>\n",
              "      <td>a1ff9697-4bb6-4f1e-b464-dda296dbd307</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>If your job doesn’t require you to be present ...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.065981+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>rFsNpM6igE2SMQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>434b71e9-a11a-519d-a9fe-e3ade78d47d6</td>\n",
              "      <td>[0.0005233448, -0.054883398, 0.043573365, -0.0...</td>\n",
              "      <td>e4ec9f4d-b687-4c28-a80d-985bfabcc2ba</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Remote working refers to working from a non-of...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.066171+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>yJOQ15t++4Ro/Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17816363-54b7-5ba7-b8d5-06d871a25414</td>\n",
              "      <td>[0.03802632, -0.021509668, 0.0475278, 0.064706...</td>\n",
              "      <td>e6e550dc-b59e-4928-abd7-07eace948681</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>There are some expenses that we will pay direc...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.066367+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>rxR+mm/QbjOWPA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2a434cf9-09d9-5514-a88b-02977f2f953e</td>\n",
              "      <td>[-0.058588073, -0.07540443, 0.033775173, 0.009...</td>\n",
              "      <td>a269d0ca-ce14-481b-a5f4-9192d6840d6e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company operates between 9 a.m. to 7 p.m. ...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.066627+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>37mwN1my3uGsdg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5f9384fa-7f98-5f52-a06e-05b05f42f69a</td>\n",
              "      <td>[-0.01359926, 0.004753031, 0.024835143, 0.0159...</td>\n",
              "      <td>5b65f3e7-0a37-429a-818d-f99b53755ebd</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>In this section, we are going to be covering i...</td>\n",
              "      <td>2024-07-05 23:33:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.066841+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>fP0Hz2jGjezd4w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42af72f6-9db7-54a2-87b2-d466169078ff</td>\n",
              "      <td>[0.032060914, 0.02424462, 0.008471355, 0.03179...</td>\n",
              "      <td>b27f7d80-f2f1-460e-aa0c-b8e770cf050a</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company observes the following holidays: N...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067012+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>1AM/USyy6+56Yg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8bfc36ce-cdb0-5792-bd70-d12ff22fc227</td>\n",
              "      <td>[-0.013155272, 0.008382475, 0.017044408, 0.051...</td>\n",
              "      <td>cf2c7276-9d6d-4611-97ef-e7707a668176</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>These holidays are considered “off-days” for m...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067180+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>XM0EEEF8nyiFZA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>b1737a97-6dca-564c-a169-78e306a5e124</td>\n",
              "      <td>[0.027987445, 0.06734361, 0.039806426, 0.00774...</td>\n",
              "      <td>79fd88bb-894c-4db3-961e-f2e9fa571399</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Employees who are unable to work due to illnes...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067352+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>VsKSXPyZ67wIfQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>896f7ed8-e918-54f3-a7b8-565d53d6d22b</td>\n",
              "      <td>[0.03252609, 0.008159482, 0.084435634, 0.05564...</td>\n",
              "      <td>0b5f3660-7867-41ea-ae25-95585c3bb34e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Losing a loved one is traumatizing. If this ha...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067508+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>OKcT1jmX5nHjCQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3557e3dd-de5b-51b9-bdee-b53ba588ed60</td>\n",
              "      <td>[-0.0073140753, 0.01471069, -0.019091198, 0.02...</td>\n",
              "      <td>3153e9cf-44bf-4ec1-b835-67d37731f9bc</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>In accordance with German law, we offer a comp...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067722+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>NALmVckz4ymE+w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>c51f99bf-5057-572e-bf9e-25dc03014c79</td>\n",
              "      <td>[-0.031538416, 0.034259938, -0.027282655, 0.02...</td>\n",
              "      <td>b9d67165-1028-4edc-841b-fe2fd4cf0cf7</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We recognize the vital role that fathers and p...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.067879+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>j4RxikbP56HFMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0317522c-a6db-59e8-ba5f-5ff0dc960d2e</td>\n",
              "      <td>[-0.017366918, 0.06079061, 0.015769996, -0.014...</td>\n",
              "      <td>72d2f585-a1b4-461e-ad88-45d9e3346425</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company’s official dress code is Business ...</td>\n",
              "      <td>2024-07-05 22:54:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.068035+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>niav/YzwjJNT9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4d0eb4d7-f0ad-517c-8165-7eb7932ea0ed</td>\n",
              "      <td>[0.033655427, 0.035742376, 0.039310906, 0.0037...</td>\n",
              "      <td>b1a9a976-eef2-4c99-9f57-3e5adb873d1f</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>If you want to invite a visitor to our offices...</td>\n",
              "      <td>2024-07-05 22:56:00+00:00</td>\n",
              "      <td>2024-07-21 10:43:05.068215+00:00</td>\n",
              "      <td>1721558583.8761644</td>\n",
              "      <td>EKnVyAvxMmPmMQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7391fc0-0a17-406b-9c5e-f4ea269caf04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e7391fc0-0a17-406b-9c5e-f4ea269caf04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e7391fc0-0a17-406b-9c5e-f4ea269caf04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0ae0e24-04b3-4c1f-9dc3-f2ad3ff1e02a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0ae0e24-04b3-4c1f-9dc3-f2ad3ff1e02a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0ae0e24-04b3-4c1f-9dc3-f2ad3ff1e02a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dbtable\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"id__\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"c69f1ecf-7b02-5810-8286-3f42659ae9d4\",\n          \"f2c18ac0-50f5-5b72-a871-dc5a46780353\",\n          \"434b71e9-a11a-519d-a9fe-e3ade78d47d6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector__\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"a8196881-ae94-4767-8767-92fe1a327d24\",\n          \"31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8\",\n          \"e4ec9f4d-b687-4c28-a80d-985bfabcc2ba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"paragraph\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"We owe our success to our employees. To show our gratitude, we will invest in our employees professional development. We want employees to feel confident about improving their efficiency and productivity. We also want to help our employees achieve personal growth and success. Each employee has $1,000 annually to spend on educational activities or material. Subscriptions and books are included in this budget, unless they are necessary for you to complete your everyday duties. Send your expenses to HR by email. Apart from online courses, we offer these training opportunities: formal training sessions (individual or corporate, employee coaching and mentoring, seats at industry conferences, on-the-job training, job shadowing, job rotation. Development is a collective process. Team members and managers should regularly discuss learning needs and opportunities. And it\\u2019s HR\\u2019s responsibility to facilitate any development activities and processes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_edited_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-07-05 22:34:00+00:00\",\n        \"max\": \"2024-07-05 23:33:00+00:00\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2024-07-05 22:34:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inserted_at_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-07-21 10:43:05.060918+00:00\",\n        \"max\": \"2024-07-21 10:43:05.068215+00:00\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"2024-07-21 10:43:05.060918+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_load_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1721558583.8761644\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"tl3dhTtbCp9NPw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---"
      ],
      "metadata": {
        "id": "-4e3NR7a06eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Create a RAG bot using Ollama"
      ],
      "metadata": {
        "id": "WuG395sV1rqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the contents from the employee handbook vectorized and stored in LanceDB, we're now ready to create our RAG with Ollama.\n"
      ],
      "metadata": {
        "id": "IDzsT3Ms2KgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is RAG?\n",
        "\n",
        "Retrieval Automated Generation (RAG) is the framework of retrieving relevant documents from a database and passing it along with a query into an LLM so that the LLM can generate context-aware responses.\n",
        "\n",
        "In our case, if we were to ask an LLM questions about our specific employee policies, then we would not get useful responses because the LLM has never seen these policies. A solution to this could be to paste all of the policies into the prompt and then ask our questions. However, this would not be feasible given the limitations on the size of the context window.\n",
        "\n",
        "We can bypass this limitation using RAG:\n",
        "1. Given a user question, we would first embed this question into a vector\n",
        "2. Then we would do a vector search on our LanceDB table and retrieve top k results - which would be the most relevant paragraphs corresponding to the question\n",
        "3. Finally, we would pass the original question along with the retrieved paragraphs as a prompt into the LLM\n"
      ],
      "metadata": {
        "id": "Zln7JnrO11NQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install Ollama into the notebook's local runtime"
      ],
      "metadata": {
        "id": "Fqvsji-Vuilq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kITCoZv85Ag5",
        "outputId": "ab740874-1eed-442d-fb4e-16726fda6cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Start Ollama using `ollama serve`. This needs to run in the backgound - so we run it using `nohup` (to see the output log, open nohup.out)."
      ],
      "metadata": {
        "id": "5KrkKX5JuoiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > nohup.out 2>&1 &"
      ],
      "metadata": {
        "id": "Yp1cSSPn5FUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Pull the desired model. We're going to be using `llama1-uncensored` (takes about 1m to download)"
      ],
      "metadata": {
        "id": "HNqBkxbVu4af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!ollama pull llama2-uncensored"
      ],
      "metadata": {
        "id": "S8HKNK7k5Xze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this next part we're going to be writing functions that accept user question, retrieve the relevant paragraphs from lancedb, and the pass the question and the retrieved pages as input into the ollama chat assistant"
      ],
      "metadata": {
        "id": "YxgV6a4O8J7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. pip install ollama and import it"
      ],
      "metadata": {
        "id": "K5FCqdt-vCAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQhykrlGZoId",
        "outputId": "cde9adca-7e23-4a7b-9868-80df81da5d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
            "Installing collected packages: h11, httpcore, httpx, ollama\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 ollama-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama"
      ],
      "metadata": {
        "id": "2M4T3gF0bQQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a function that can retrieve content from lancedb relevant to the user query\n",
        "  \n",
        "  With LanceDB, you don't have to explicity embed the question. LanceDB stores information on the embedding model used and automatically embeds the question.\n",
        "\n",
        "  We use the `db_table.search()` function to query the DB and then limit it to the top 2 most similar results and return that as the context to pass to the RAG.\n",
        "\n",
        "  Limiting results is important because otherwise there might be too much confusing information. Similarly only picking the top choice might not give enough information."
      ],
      "metadata": {
        "id": "Nd2AzTLnvIuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_from_lancedb(dbtable, question, top_k=2):\n",
        "\n",
        "    query_results = dbtable.search(query=question).to_list()\n",
        "    context = \"\\n\".join([result[\"content\"] for result in query_results[:top_k]])\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "c1rSQm33qx2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Finally we define a very basic RAG. We define a simple system prompt, retrieve the relevant context for the user query with the function defined above and then send the user question and the context to the `llama2-uncensored` model."
      ],
      "metadata": {
        "id": "MLiwo22GsVSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Connect to the lancedb table\n",
        "  db = lancedb.connect(\".lancedb\")\n",
        "  dbtable = db.open_table(\"notion_pages___homework\")\n",
        "\n",
        "  # A system prompt telling ollama to accept input in the form of \"Question: ... ; Context: ...\"\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps users understand policies inside a company's employee handbook. The user will first ask you a question and then provide you relevant paragraphs from the handbook as context. Please answer the question based on the provided context. For any details missing in the paragraph, encourage the employee to contact the HR for that information. Please keep the responses conversational.\"}\n",
        "  ]\n",
        "\n",
        "  while True:\n",
        "    # Accept user question\n",
        "    question = input(\"You: \")\n",
        "\n",
        "    # Retrieve the relevant paragraphs on the question\n",
        "    context = retrieve_context_from_lancedb(dbtable,question,top_k=2)\n",
        "\n",
        "    # Create a user prompt using the question and retrieved context\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": f\"Question: '{question}'; Context:'{context}'\"}\n",
        "    )\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = ollama.chat(\n",
        "        model=\"llama2-uncensored\",\n",
        "        messages=messages\n",
        "    )\n",
        "    response_content = response['message']['content']\n",
        "    print(f\"Assistant: {response_content}\")\n",
        "\n",
        "    # Add the response into the context window\n",
        "    messages.append(\n",
        "        {\"role\": \"assistant\", \"content\":response_content}\n",
        "    )"
      ],
      "metadata": {
        "id": "2OvqfvFU_h3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we run the RAG! Some example questions you can ask:\n",
        "\n",
        "* How many vacation days do I get?\n",
        "* Can I get maternity leave?\n",
        "\n",
        "**Note**: This is a very basic implementation of a RAG, since this workshop is mainly about data ingestion. So expect some weird answers. If you do stop and restart the cell, you will need to rerun the cell containing `ollama serve` first."
      ],
      "metadata": {
        "id": "OLlMA3pcq4RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "lCcHrjymfdgE",
        "outputId": "5d61dda9-3e4c-49d7-f88e-9f7ae43843a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: how many PTO days are the employees entitled to in a year?\n",
            "Assistant: Based on the information provided in the handbook, employees are entitled to 30 days of Paid Time Off (PTO) per year. If they haven't accrued enough PTO, they can use time off that they haven't accrued yet. After their first year with the company, they will earn an additional day of PTO every year, up to a maximum of 25 days overall. Additionally, employees are allowed to take their leave at any time after their first week with the company and can use it for any reason without having to specify a reason for requesting PTO. The company may compensate accrued PTO with final paycheck according to local law or provide an additional day of PTO within 12 months for exempt employees if they work on a holiday.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-0dc58a88b370>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Accept user question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Retrieve the relevant paragraphs on the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a lot more to learn and do with dlt and LanceDB, find more info the [dlt docs](https://dlthub.com/docs/) and the [LanceDB docs](https://lancedb.github.io/lancedb/)\n",
        "\n",
        "If you have questions about this workshop or dlt, feel free to join our [community on Slack](https://dlthub.com/community).\n",
        "\n",
        "If you're at EuroPython in Prague this week, come see us at our booth!"
      ],
      "metadata": {
        "id": "umpLwREgwyDi"
      }
    }
  ]
}